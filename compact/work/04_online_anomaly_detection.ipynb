{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHM North America challenge '23\n",
    "\n",
    "# 04 - Online anomaly detection\n",
    "\n",
    "This notebook utilizes the [previously constructed](03_offline_vibration_fingerprint_extraction.ipynb) for detecting anomalies in a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from conscious_engie_icare.data.phm_data_handler import fetch_and_unzip_data, load_data, BASE_PATH_HEALTHY, BASE_PATHS_TEST, PITTING_LEVELS, \\\n",
    "                                                        FPATH_DF_ORDERS_TEST_FOLDS, FPATH_META_DATA_TEST_FOLDS, FPATH_DATA_HEALTHY_TEST_FOLDS, \\\n",
    "                                                        FPATH_DF_V_TRAIN_FOLDS, FPATH_META_DATA_TRAIN_FOLDS, FPATH_UNIQUE_NAME_MAPPING_FOLDS, \\\n",
    "                                                        FPATH_FINGERPRINTS_FOLDS, FPATH_MODEL_FOLDS, FPATH_DISTANCES\n",
    "from conscious_engie_icare.nmf_profiling import derive_df_vib, derive_df_orders\n",
    "from conscious_engie_icare import distance_metrics\n",
    "from conscious_engie_icare.normalization import normalize_1\n",
    "from conscious_engie_icare.util import calculate_roc_characteristics, calc_tpr_at_fpr_threshold, calc_fpr_at_tpr_threshold\n",
    "import matplotlib.patches as patches\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the previously cached data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_and_unzip_data()\n",
    "\n",
    "# load healthy data test folds from 02 - data preprocessing\n",
    "with open(FPATH_DATA_HEALTHY_TEST_FOLDS, 'rb') as file:\n",
    "    data_healthy_test_folds = pickle.load(file)   # TODO: load indices instead or change to other method\n",
    "\n",
    "with open(FPATH_DF_V_TRAIN_FOLDS, 'rb') as file:\n",
    "    df_V_train_folds = pickle.load(file)\n",
    "\n",
    "with open(FPATH_META_DATA_TRAIN_FOLDS, 'rb') as file:\n",
    "    meta_data_train_folds = pickle.load(file)\n",
    "\n",
    "# load unique name mappings from 03 - offline vibration fingerprint extraction\n",
    "with open(FPATH_UNIQUE_NAME_MAPPING_FOLDS, 'rb') as file:\n",
    "    cluster_label_unique_name_mapping_folds = pickle.load(file)\n",
    "\n",
    "# load fingerprints from 03 - offline vibration fingerprint extraction\n",
    "with open(FPATH_FINGERPRINTS_FOLDS, 'rb') as file:\n",
    "    fingerprints_folds = pickle.load(file)\n",
    "\n",
    "# load nmf models from 03 - offline vibration fingerprint extraction\n",
    "with open(FPATH_MODEL_FOLDS, 'rb') as file:\n",
    "    model_folds = pickle.load(file)\n",
    "\n",
    "# extract list of frequency band columns for later usage\n",
    "cols_ = df_V_train_folds[0].columns\n",
    "BAND_COLS = cols_[cols_.str.contains('band')].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `CACHE_RESULTS` to `True` to cache the results of the feature extraction process. This will speed up the notebook execution time in subsequent executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_RESULTS = True\n",
    "LOAD_CACHED_RESULTS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and preprocessing test data\n",
    "\n",
    "In order to create a balanced test set, we first load the process and vibration data of the test set that exhibit a high level of pitting and merge it with the healthy data which was not used in the training set.\n",
    "\n",
    "The test data consists of two different conditions:\n",
    "1. **Anomaly condition**: Pitting level 1-8. For each level of pitting, there are between 267 and 304 samples in the test set that were recorded at different speeds and torques.\n",
    "2. **Normal condition**: Healthy data\n",
    "\n",
    "The test data is preprocessed in the same way as the training data, including\n",
    "1. Conversion from time to frequency domain\n",
    "2. Order transformation and binning\n",
    "3. Frequency-band normalization\n",
    "\n",
    "As these steps were all already explained in the [previous notebook on data preprocessing](02_data_processing.ipynb), we will not further go into detail again.\n",
    "The cell below preprocesses the test data in the same way.\n",
    "As a result, two lists of dataframes are constructed: \n",
    "1. `df_orders_test_folds`, where each dataframe contains the frequency transformed measurements, \n",
    "2. `meta_data_test_folds`, where each dataframe contains the process data and some additional information on the measurements.\n",
    "An excerpt is shown below or the first fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert test samples to orders per fold:   0%|                                                                                                                                                                                                          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m df_orders_test_healthy_folds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_healthy_test_ \u001b[38;5;129;01min\u001b[39;00m tqdm(data_healthy_test_folds, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconvert test samples to orders per fold\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     df_vib_test_healthy_ \u001b[38;5;241m=\u001b[39m derive_df_vib(data_healthy_test_, \u001b[43mf\u001b[49m)\n\u001b[1;32m     15\u001b[0m     df_orders_test_healthy_, meta_data_test_healthy_ \u001b[38;5;241m=\u001b[39m derive_df_orders(df_vib_test_healthy_, setup, f, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m     meta_data_test_healthy_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_sample_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m meta_data_test_healthy_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_sample_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_healthy\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "# load transformed data (if possible)\n",
    "if os.path.exists(FPATH_DF_ORDERS_TEST_FOLDS) and os.path.exists(FPATH_META_DATA_TEST_FOLDS):\n",
    "    with open(FPATH_DF_ORDERS_TEST_FOLDS, 'rb') as file:\n",
    "        df_orders_test_folds = pickle.load(file)\n",
    "    with open(FPATH_META_DATA_TEST_FOLDS, 'rb') as file:\n",
    "        meta_data_test_folds = pickle.load(file)\n",
    "\n",
    "# transform test data to orders\n",
    "else:\n",
    "    # convert healthy test samples to orders\n",
    "    meta_data_test_healthy_folds = []\n",
    "    df_orders_test_healthy_folds = []\n",
    "    for data_healthy_test_ in tqdm(data_healthy_test_folds, desc='convert test samples to orders per fold'):\n",
    "        df_vib_test_healthy_ = derive_df_vib(data_healthy_test_, f)\n",
    "        df_orders_test_healthy_, meta_data_test_healthy_ = derive_df_orders(df_vib_test_healthy_, setup, f, verbose=False)\n",
    "        meta_data_test_healthy_['unique_sample_id'] = meta_data_test_healthy_['unique_sample_id'] + '_healthy'\n",
    "        df_orders_test_healthy_['unique_sample_id'] = meta_data_test_healthy_['unique_sample_id']\n",
    "        meta_data_test_healthy_folds.append(meta_data_test_healthy_)\n",
    "        df_orders_test_healthy_folds.append(df_orders_test_healthy_)\n",
    "\n",
    "    # convert pitting test samples to orders\n",
    "    df_orders_test_pitting_dict = {}\n",
    "    meta_data_test_pitting_dict = {}\n",
    "    for lvl, path in tqdm(list(zip(PITTING_LEVELS, BASE_PATHS_TEST)), desc='Extracting and order-transforming test data'):\n",
    "        # load data for each level of pitting\n",
    "        fnames = glob.glob(os.path.join(path, '*.txt'))\n",
    "        nperseg = 10240\n",
    "        noverlap = nperseg // 2\n",
    "        nfft = None\n",
    "        fs = 20480\n",
    "        data_test, f = load_data(fnames, nperseg=nperseg, noverlap=noverlap, nfft=nfft, fs=fs, base_path=path, use_train_data_for_validation=True)\n",
    "\n",
    "        # extract vibration data\n",
    "        df_vib_test_unhealthy = derive_df_vib(data_test, f)\n",
    "\n",
    "        # convert to orders and derive meta data\n",
    "        setup = {'start': 0.5, 'stop': 100.5, 'n_windows': 50, 'window_steps': 2, 'window_size': 2}  # also used in 02 - data preprocessing\n",
    "        df_orders_test_pitting_, meta_data_test_pitting_ = derive_df_orders(df_vib_test_unhealthy, setup, f, verbose=False)\n",
    "        rpm = meta_data_test_pitting_['rotational speed [RPM]']\n",
    "        torque = meta_data_test_pitting_['torque [Nm]']\n",
    "        run = meta_data_test_pitting_['sample_id']\n",
    "        meta_data_test_pitting_['unique_sample_id'] = rpm.astype(str) + '_' + torque.astype(str) + '_' + run.astype(str) + f'_pitting_level_{lvl}'\n",
    "        df_orders_test_pitting_['unique_sample_id'] = meta_data_test_pitting_['unique_sample_id']\n",
    "        df_orders_test_pitting_dict[lvl] = df_orders_test_pitting_\n",
    "        meta_data_test_pitting_dict[lvl] = meta_data_test_pitting_\n",
    "\n",
    "    # concat all pitting levels samples\n",
    "    df_orders_test_pitting = pd.concat(list(df_orders_test_pitting_dict.values()))\n",
    "    meta_data_test_pitting = pd.concat(list(meta_data_test_pitting_dict.values()))\n",
    "\n",
    "    # merge healthy and unhealthy samples for each fold\n",
    "    df_orders_test_folds = []\n",
    "    meta_data_test_folds = []\n",
    "    for i, (df_orders_test_healthy_, meta_data_test_healthy_) in enumerate(zip(df_orders_test_healthy_folds, meta_data_test_healthy_folds)):\n",
    "        # only use operating modes in the test set that are also in the training set\n",
    "        om_test_healthy = meta_data_test_healthy_['rotational speed [RPM]'].astype(str) + '_' + meta_data_test_healthy_['torque [Nm]'].astype(str)\n",
    "        om_test_pitting = meta_data_test_pitting['rotational speed [RPM]'].astype(str) + '_' + meta_data_test_pitting['torque [Nm]'].astype(str)\n",
    "        new_meta_data_test_pitting_without_missing_oms = meta_data_test_pitting[om_test_pitting.isin(om_test_healthy)]\n",
    "        new_df_orders_test_pitting_without_missing_oms = df_orders_test_pitting[om_test_pitting.isin(om_test_healthy)]\n",
    "\n",
    "        # sample equal amount of samples from healthy and faulty data\n",
    "        om_test_pitting_with_run = new_meta_data_test_pitting_without_missing_oms['rotational speed [RPM]'].astype(str) + '_' + new_meta_data_test_pitting_without_missing_oms['torque [Nm]'].astype(str) + '_' + new_meta_data_test_pitting_without_missing_oms['sample_id'].astype(str)\n",
    "        om_test_healthy_with_run = meta_data_test_healthy_['rotational speed [RPM]'].astype(str) + '_' + meta_data_test_healthy_['torque [Nm]'].astype(str) + '_' + meta_data_test_healthy_['sample_id'].astype(str)\n",
    "        n_samples = len(om_test_healthy_with_run.unique())\n",
    "        samples = new_df_orders_test_pitting_without_missing_oms['unique_sample_id'].sample(n_samples, random_state=i, replace=False)\n",
    "        new_meta_data_test_pitting = new_meta_data_test_pitting_without_missing_oms[new_meta_data_test_pitting_without_missing_oms['unique_sample_id'].isin(samples)]\n",
    "        new_df_orders_test_pitting = new_df_orders_test_pitting_without_missing_oms[new_df_orders_test_pitting_without_missing_oms['unique_sample_id'].isin(samples)]\n",
    "        df_orders_test_folds.append(pd.concat([df_orders_test_healthy_, new_df_orders_test_pitting]).reset_index(drop=True))\n",
    "        meta_data_test_folds.append(pd.concat([meta_data_test_healthy_, new_meta_data_test_pitting]).reset_index(drop=True))\n",
    "\n",
    "    if CACHE_RESULTS:\n",
    "        # cache train data\n",
    "        with open(FPATH_DF_ORDERS_TEST_FOLDS, 'wb') as file:\n",
    "            pickle.dump(df_orders_test_folds, file)\n",
    "        # cache test data\n",
    "        with open(FPATH_META_DATA_TEST_FOLDS, 'wb') as file:\n",
    "            pickle.dump(meta_data_test_folds, file)\n",
    "\n",
    "print('All samples from the test set are processed for all folds. Below, we show an excerpt of the first fold.')\n",
    "print('(1) `df_orders_test_folds` contains the preprocessed and order-transformed vibration bands:')\n",
    "display(df_orders_test_folds[0].head())\n",
    "print('(2) `meta_data_test_folds` contains the process data (rpm, torque) and some additional information (measurement direction):')\n",
    "display(meta_data_test_folds[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive vibration weights\n",
    "\n",
    "After the vibration data of the test set was preprocessed in the same way as the training data, the weight matrix $\\mathbf{W}$ is extracted in this section.\n",
    "In the subsequent anomaly detection, $\\mathbf{W}$ will be compared to the context-sensitive fingerprint of the same operating mode.\n",
    "The cell below calculates the weight matrices for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract df_W_offline and df_W_online\n",
    "def extract_vibration_weights_per_measurement_period(measurement_periods, col_names, band_cols, normalization, model, verbose=False):\n",
    "    Ws = []\n",
    "    for period in tqdm(measurement_periods, disable=not verbose, desc='Extracting vibration weights per measurement period'):\n",
    "        assert len(period) == 3, 'should have exactly 3 directions per measurement period'\n",
    "        band_column_names = period.columns[period.columns.str.contains('band_')]\n",
    "        V = period.set_index(['direction'])[band_column_names]  # already normalized\n",
    "        W = model.nmf.transform(V.to_numpy())\n",
    "        W = pd.DataFrame(W, columns=col_names)\n",
    "        Ws.append({\n",
    "            'unique_sample_id': period.unique_sample_id.unique()[0],\n",
    "            'V_normalized': V,\n",
    "            'W': W\n",
    "        })\n",
    "    return pd.DataFrame(Ws)\n",
    "\n",
    "# extract train vibration measurement periods\n",
    "train_vibration_measurement_periods_folds = []\n",
    "for df_, meta_data_train_ in zip(df_V_train_folds, meta_data_train_folds):\n",
    "    df_[['unique_sample_id', 'direction']] = meta_data_train_[['unique_sample_id', 'direction']]\n",
    "    train_vibration_measurement_periods = []\n",
    "    for sample_id, group in df_.groupby('unique_sample_id'):\n",
    "        measurement_period = {\n",
    "            'start': 'unknown', \n",
    "            'stop': 'unknown',\n",
    "            'group': group,\n",
    "            'sample_id': sample_id,\n",
    "        }\n",
    "        train_vibration_measurement_periods.append(group)\n",
    "    train_vibration_measurement_periods_folds.append(train_vibration_measurement_periods)\n",
    "\n",
    "# extract test vibration measurement periods\n",
    "test_vibration_measurement_periods_folds = []\n",
    "test_vibration_measurement_periods_meta_data_folds = []\n",
    "for df_orders_test_, meta_data_test_, cluster_label_unique_name_mapping_ in tqdm(zip(df_orders_test_folds, meta_data_test_folds, cluster_label_unique_name_mapping_folds), \n",
    "                                                                                 total=len(df_orders_test_folds)):\n",
    "    df_V_test_normalized = normalize_1(df_orders_test_, BAND_COLS)\n",
    "    df_ = df_V_test_normalized\n",
    "    df_[['sample_id', 'unique_sample_id', 'direction']] = meta_data_test_[['sample_id', 'unique_sample_id', 'direction']]\n",
    "    test_vibration_measurement_periods_ = []\n",
    "    test_vibration_measurement_periods_meta_data_ = []\n",
    "    n_index_errors = 0\n",
    "    for unique_sample_id, group in df_.groupby('unique_sample_id'):\n",
    "        rpm = meta_data_test_[meta_data_test_['unique_sample_id'] == unique_sample_id]['rotational speed [RPM]'].unique()[0]\n",
    "        torque = meta_data_test_[meta_data_test_['unique_sample_id'] == unique_sample_id]['torque [Nm]'].unique()[0]\n",
    "        try:\n",
    "            om = cluster_label_unique_name_mapping_[\n",
    "                (cluster_label_unique_name_mapping_['rotational speed [RPM]'] == rpm) & \n",
    "                (cluster_label_unique_name_mapping_['torque [Nm]'] == torque)\n",
    "            ]['cluster_label_unique'].iloc[0]\n",
    "        except IndexError:\n",
    "            n_index_errors += 1\n",
    "            om = -1\n",
    "        measurement_period = {\n",
    "            'start': 'unknown', \n",
    "            'stop': 'unknown',\n",
    "            'group': group,\n",
    "            'unique_sample_id': unique_sample_id,\n",
    "            'rpm': rpm,\n",
    "            'torque': torque,\n",
    "            'unique_cluster_label': om\n",
    "        }\n",
    "        test_vibration_measurement_periods_.append(group)\n",
    "        test_vibration_measurement_periods_meta_data_.append(measurement_period)\n",
    "    test_vibration_measurement_periods_folds.append(test_vibration_measurement_periods_)\n",
    "    test_vibration_measurement_periods_meta_data_folds.append(test_vibration_measurement_periods_meta_data_)\n",
    "    n_total = len(test_vibration_measurement_periods_)\n",
    "\n",
    "df_W_offline_folds = []\n",
    "df_W_online_folds = []\n",
    "for train_vibration_measurement_periods_, test_vibration_measurement_periods_, fingerprints_, model_ in tqdm(\n",
    "    zip(train_vibration_measurement_periods_folds,\n",
    "        test_vibration_measurement_periods_folds,\n",
    "        fingerprints_folds,\n",
    "        model_folds),\n",
    "    total=len(fingerprints_folds)):\n",
    "    df_W_offline_ = extract_vibration_weights_per_measurement_period(train_vibration_measurement_periods_, fingerprints_[0].columns, BAND_COLS, normalize_1, model_)\n",
    "    df_W_online_ = extract_vibration_weights_per_measurement_period(test_vibration_measurement_periods_, fingerprints_[0].columns, BAND_COLS, normalize_1, model_)\n",
    "    df_W_offline_folds.append(df_W_offline_)\n",
    "    df_W_online_folds.append(df_W_online_)\n",
    "\n",
    "fold = 0\n",
    "df_W_online_folds[fold].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We illustrate the derived weights for a single measurements below. The format of the weights is the same as of the fingerprint shown in the [previous notebook](03_offline_vibration_fingerprint_extraction.ipynb#Offline-vibration-fingerprint-extraction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = 5\n",
    "period = 10\n",
    "df_W_online_ = df_W_online_folds[fold]\n",
    "usid = df_W_online_['unique_sample_id'][period]\n",
    "df_ = meta_data_test_folds[fold][meta_data_test_folds[fold]['unique_sample_id']==usid]\n",
    "rpm = df_['rotational speed [RPM]'].iloc[0]\n",
    "torque = df_['torque [Nm]'].iloc[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.heatmap(df_W_online_['W'][period], annot=True, fmt=\".6f\", ax=ax, cmap='Blues', vmin=0, vmax=0.05, cbar=False)\n",
    "ax.set_title(f'Derived weights for measurement {period} @ {rpm} rpm, {torque} Nm');\n",
    "ax.set_yticklabels(['x', 'y', 'z'], rotation=0)\n",
    "ax.set_ylabel('Measurement direction')\n",
    "ax.set_xlabel('Component');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection \n",
    "\n",
    "Because the measurements are not timestamped, it is not possible to order the measurements in time and calculate a cumulative anomaly score.\n",
    "Therefore, we perform only the measurement-wise anomaly detection in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to fingerprints\n",
    "\n",
    "Per operating mode, we calculate the distances of the derived weights to the corresponding fingerprint below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell takes around 60 minutes to run (!) --> going to cache the results\n",
    "SHOW_DISTANCES = False\n",
    "\n",
    "def calculate_distances_per_measurement_period(measurement_period, fingerprints, verbose=False):\n",
    "    # pointwise Mahalanobis distance\n",
    "    fingerprint_matrix = np.array([fingerprints[om].to_numpy().flatten() for om in fingerprints])\n",
    "    # calculate covariance matrix\n",
    "    fingerprint_S = np.cov(fingerprint_matrix.T)\n",
    "    # calculate inverse\n",
    "    fingerprint_SI = np.linalg.inv(fingerprint_S)\n",
    "    # calculate mu\n",
    "    fingerprint_mu = fingerprint_matrix.mean(axis=0)\n",
    "    df_dist_ = []\n",
    "    for idx, row in tqdm(measurement_period.iterrows(), total=len(measurement_period), disable=not verbose):\n",
    "        for om in fingerprints:\n",
    "            weights = row['W']\n",
    "            fingerprint = fingerprints[om]\n",
    "            tmp = {\n",
    "                'idx': idx,\n",
    "                'data': row, \n",
    "                'om': om, \n",
    "                #'frobenius_norm': distance_metrics.frobenius_norm(weights, fingerprint),\n",
    "                #'frobenius_norm_pow2': distance_metrics.frobenius_norm_v2(weights, fingerprint),\n",
    "                #'frobenius_norm_sqrt': distance_metrics.frobenius_norm_v3(weights, fingerprint),\n",
    "                'cosine_distance': distance_metrics.cosine_distance(weights, fingerprint),\n",
    "                'manhattan_distance': distance_metrics.manhattan_distance(weights, fingerprint),\n",
    "            }\n",
    "            df_dist_.append(tmp)\n",
    "    df_dist_ = pd.DataFrame(df_dist_)\n",
    "    return df_dist_\n",
    "\n",
    "# calculate/load distances for the different folds\n",
    "df_dist_offline_folds = []\n",
    "df_dist_online_folds = []\n",
    "for i, (df_W_offline_, df_W_online_, fingerprints_) in tqdm(enumerate(zip(df_W_offline_folds,\n",
    "                                                                     df_W_online_folds,\n",
    "                                                                     fingerprints_folds)),\n",
    "                                                                     desc='Calculating distances per fold'):\n",
    "    fpath_offline = os.path.join(FPATH_DISTANCES, f'df_dist_offline_fold_{i}.pkl')\n",
    "    os.makedirs(os.path.dirname(fpath_offline), exist_ok=True)\n",
    "    fpath_online = os.path.join(FPATH_DISTANCES, f'df_dist_online_fold_{i}.pkl')\n",
    "    os.makedirs(os.path.dirname(fpath_online), exist_ok=True)\n",
    "    try:\n",
    "        # load cached distances\n",
    "        df_dist_offline_folds.append(pickle.load(open(fpath_offline, 'rb')))\n",
    "        df_dist_online_folds.append(pickle.load(open(fpath_online, 'rb')))\n",
    "    except FileNotFoundError:\n",
    "        # calculate distances and cache results\n",
    "        df_dist_offline_ = calculate_distances_per_measurement_period(df_W_offline_, fingerprints=fingerprints_)\n",
    "        if CACHE_RESULTS:\n",
    "            pickle.dump(df_dist_offline_, open(fpath_offline, 'wb'))\n",
    "        df_dist_online_ = calculate_distances_per_measurement_period(df_W_online_, fingerprints=fingerprints_)\n",
    "        if CACHE_RESULTS:\n",
    "            pickle.dump(df_dist_online_, open(fpath_online, 'wb'))\n",
    "        df_dist_offline_folds.append(df_dist_offline_)\n",
    "        df_dist_online_folds.append(df_dist_online_)\n",
    "\n",
    "# pivot cosine distance:\n",
    "# for each measurement period (row), get the distance to each operating mode (column)\n",
    "df_cosine_folds = []\n",
    "for df_dist_online_, test_vibration_measurement_periods_meta_data_ in zip(df_dist_online_folds, test_vibration_measurement_periods_meta_data_folds):\n",
    "    df_cosine_ = df_dist_online_[['idx', 'om', 'cosine_distance']].pivot(index='idx', columns='om', values='cosine_distance')\n",
    "    # assign the corresponding operating mode to the given row (if known), else, assign -1\n",
    "    df_cosine_[['rpm', 'torque', 'unique_cluster_label']] = pd.DataFrame(test_vibration_measurement_periods_meta_data_)[['rpm', 'torque', 'unique_cluster_label']]\n",
    "    df_cosine_folds.append(df_cosine_)\n",
    "\n",
    "if SHOW_DISTANCES:\n",
    "    g = sns.displot(data=df_dist_offline_folds[fold], \n",
    "                    x=\"cosine_distance\", col=\"om\", col_wrap=10, height=1, aspect=2, bins=20, kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the cosine distance as appropriate metric.\n",
    "Below, we create a pivot table of the cosine distance and compare distances between measurements and their corresponding fingerprints (left) and other fingerprints (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (df_cosine_, df_W_online_) in enumerate(zip(df_cosine_folds, df_W_online_folds)):\n",
    "    distance_to_own_cluster_center_ = []\n",
    "    for idx, row in df_cosine_.iterrows():\n",
    "        om = row['unique_cluster_label']\n",
    "        if om != -1:\n",
    "            distance_to_own_cluster_center_.append(row[om])\n",
    "        else:\n",
    "            distance_to_own_cluster_center_.append(np.nan)\n",
    "    df_cosine_['distance_to_own_cluster_center'] = distance_to_own_cluster_center_\n",
    "    df_cosine_['pitting'] = df_W_online_['unique_sample_id'].str.contains(f'pitting_level_')\n",
    "    df_cosine_['pitting_level'] = df_W_online_['unique_sample_id'].str.extract(r'pitting_level_(\\d)')\n",
    "    df_cosine_['pitting_level'] = df_cosine_['pitting_level'].fillna(0).astype(int)\n",
    "    df_cosine_folds[i] = df_cosine_\n",
    "\n",
    "print('Pivot table with distances to all fingerprints (0 - 72), corresponding rpm and torque values, and additional information on the anomaly condition:')\n",
    "df_cosine_ = df_cosine_folds[fold]\n",
    "display(df_cosine_.head())\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(16, 8), ncols=2)\n",
    "\n",
    "ax = df_cosine_['distance_to_own_cluster_center'].plot(kind='hist', bins=20, ax=axes[0], alpha=0.5, legend=False)\n",
    "ax.set_title('Distance to own cluster centers')\n",
    "ax.set_xlabel('Cosine distance')\n",
    "\n",
    "# plot distance to other cluster centers\n",
    "ax = df_cosine_.drop(columns=['rpm', 'torque', 'unique_cluster_label', 'distance_to_own_cluster_center', 'pitting', 'pitting_level']).melt()['value'].plot(kind='hist', bins=20, ax=axes[1], alpha=0.5, legend=False)\n",
    "ax.set_title('Distance to other cluster centers')\n",
    "ax.set_xlabel('Cosine distance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine distance to the context-sensitive fingerprint is typically higher, when pitting is present.\n",
    "This is expected, as the context-sensitive fingerprint is derived from healthy data without pitting and data with pitting is likely to have vibration patterns not present in the healthy data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(data=df_cosine_, y='distance_to_own_cluster_center', x='pitting_level')\n",
    "ax.set_ylabel('Distance to context sensitive fingerprint')\n",
    "ax.set_title(f'Distance to own cluster center per pitting level (Fold {fold})');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-curves\n",
    "\n",
    "Whether a datapoint is labelled as anomalous depends on a predefined distance threshold.\n",
    "In this section, we caclulate ROC-curves by varying this distance threshold.\n",
    "\n",
    "An ROC-curve is calculated per fold. Below, we visualize the ROC curve for the first fold.\n",
    "It can be observed that the anomaly detection generally performs well with a area under the curve (AUC) of $0.962$.\n",
    "Operators aim for a high true positive rate (TPR) while minimizing false alarms (keeping the false positive rate (FPR) low). We track the TPR at a stable FPR of 0.1 (TPR@FPR=0.1), which represents the TPR when there are 10% false positives. In this scenario, the TPR is 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "threshold = 0.1\n",
    "\n",
    "df_cosine_ = df_cosine_folds[fold]\n",
    "df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # removed unknown cluster labels\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot the general ROC curve\n",
    "fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "tpr_at_fpr = calc_tpr_at_fpr_threshold(tpr, fpr, threshold=threshold)\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.plot([0, threshold], [tpr_at_fpr, tpr_at_fpr], color='red', lw=2, linestyle='--', label=f'TPR@FPR={threshold:.2f} = {tpr_at_fpr:.2f}')\n",
    "ax.plot([threshold, threshold], [0, tpr_at_fpr], color='red', lw=2, linestyle='--')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {fold})')\n",
    "n_total = len(df_cosine_)\n",
    "n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy)\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text)\n",
    "\n",
    "ax.legend(loc='lower right', title='Pitting severity level');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternatve objective criterium is to keep the FPR as low as possible at a high TPR.\n",
    "The plot below illustrates the FPR@TPR=0.1. In the shown fold, FPR@TPR=0.1 is 0.07."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "df_cosine_ = df_cosine_folds[fold]\n",
    "df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # removed unknown cluster labels\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "threshold = 0.90\n",
    "\n",
    "# Plot the general ROC curve\n",
    "fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=threshold)\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.plot([fpr_at_tpr, fpr_at_tpr], [0, threshold], color='green', lw=2, linestyle='--', label=f'FPR@TPR={threshold:.2f} = {fpr_at_tpr:.2f}')\n",
    "ax.plot([0, fpr_at_tpr], [threshold, threshold], color='green', lw=2, linestyle='--')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {fold})')\n",
    "n_total = len(df_cosine_)\n",
    "n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy)\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text)\n",
    "\n",
    "ax.legend(loc='lower right', title='Pitting severity level');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last cell, we illustrate the ROC-curves of multiple folds, where trial 20 is the fold with the worst FPR@TPR=0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20]\n",
    "zoom = {'x': (-0.01, 0.2), 'y': (0.8, 1.01)}\n",
    "cmap = plt.get_cmap('tab20').colors\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(7, 3), ncols=2)\n",
    "threshold = 0.90\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "rect = patches.Rectangle((zoom['x'][0], zoom['y'][0]), zoom['x'][1], zoom['y'][1], linewidth=5, edgecolor='r', facecolor='none', label='zoomed area')\n",
    "ax.add_patch(rect)\n",
    "for i, fold in enumerate(tqdm(trials)):\n",
    "    df_cosine_ = df_cosine_folds[fold]\n",
    "    df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]\n",
    "\n",
    "    # Plot the general ROC curve\n",
    "    fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "    fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=threshold)\n",
    "    label=f'trial {fold}'\n",
    "    ax.plot(fpr, tpr, color=cmap[i], lw=4, label=label, alpha=0.2)\n",
    "    ax.plot([fpr_at_tpr, fpr_at_tpr], [0, threshold], color=cmap[i], lw=2, linestyle='dotted', alpha=0.2)\n",
    "    ax.plot([0, fpr_at_tpr], [threshold, threshold], color=cmap[i], lw=2, linestyle='dotted', alpha=0.2)\n",
    "    ax.set_xlim(-0.05, 1.0)\n",
    "    ax.set_ylim(0.0, 1.05)\n",
    "    ax.set_xlabel('False Positive Rate [FPR]')\n",
    "    ax.set_ylabel('True Positive Rate [TPR]')\n",
    "    ax.set_title(f'ROC Curves')\n",
    "    n_total = len(df_cosine_)\n",
    "    n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "    n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])\n",
    "\n",
    "ax = axes[1]\n",
    "for i, fold in enumerate(tqdm(trials)):\n",
    "    df_cosine_ = df_cosine_folds[fold]\n",
    "    df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # removed unknown cluster labels\n",
    "\n",
    "    # Plot the general ROC curve\n",
    "    fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "    fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=threshold)\n",
    "    ax.plot(fpr, tpr, color=cmap[i], lw=4, label=None, alpha=0.25)\n",
    "    ax.plot([fpr_at_tpr, fpr_at_tpr], [0, threshold], color=cmap[i], lw=2, linestyle='dotted', label=None, alpha=0.25)\n",
    "    ax.plot([0, fpr_at_tpr], [threshold, threshold], color=cmap[i], lw=2, linestyle='dotted', alpha=0.25)\n",
    "    ax.set_xlim(zoom['x'])\n",
    "    ax.set_ylim(zoom['y'])\n",
    "    ax.set_xlabel('False Positive Rate [FPR]')\n",
    "    ax.set_ylabel('True Positive Rate [TPR]')\n",
    "    ax.set_title(f'ROC Curves (zoomed in)')\n",
    "    n_total = len(df_cosine_)\n",
    "    n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "    n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])\n",
    "\n",
    "fig.legend(ncol=6, fontsize=9.5, loc='lower center', bbox_to_anchor=(0.5, -0.15))\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join('figs', 'roc_curves.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook-series we illustrated our contextual anomaly detection method on the example of a gearbox that is subject to pitting.\n",
    "We illustrated the use case [[1]](01_data_exploration.ipynb), which preprocessing steps have to be taken on the vibration data [[2]](02_data_processing.ipynb), how to construct context-sensitive fingerprints [[3]](03_offline_vibration_fingerprint_extraction.ipynb), and how to utilize the fingerprints for anomaly detection [[4]](04_online_anomaly_detection.ipynb).\n",
    "We showed that our method is capable to detect anomalies in the test set while keeping the amount of false positives low.\n",
    "In a real-world setting, additional steps have to be taken to estimate the underlying operating mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â©, 2023, Sirris"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compact",
   "language": "python",
   "name": "compact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
