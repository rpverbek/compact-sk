{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHM North America challenge '23\n",
    "\n",
    "# 02 - Data processing\n",
    "\n",
    "This notebook preprocesses the vibration data from the PHM North America challenge '23, with the goal to construct a decomposition matrix of the vibration data.\n",
    "\n",
    "The preprocessing consists of the following steps:\n",
    "1. [domain-conversion](#(1)-Conversion-from-time-to-frequency-domain): Convert the vibration data into the frequency domain using the Fast Fourier Transform (FFT).\n",
    "2. [order-conversion](#2-order-transformation-and-binning): Convert the frequency domain data into constant orders and bin the resulting data.\n",
    "3. [normalization](#3-frequency-band-normalization): Normalize the order converted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from conscious_engie_icare.normalization import normalize_1\n",
    "from conscious_engie_icare.nmf_profiling import derive_df_orders, derive_df_vib\n",
    "from conscious_engie_icare.data.phm_data_handler import BASE_PATH_HEALTHY, FILE_NAMES_HEALTHY, CACHING_FOLDER_NAME, fetch_and_unzip_data, \\\n",
    "                                                        load_data, load_cached_data, FPATH_DF_ORDERS_TRAIN_FOLDS, FPATH_META_DATA_TRAIN_FOLDS, FPATH_DF_V_TRAIN_FOLDS, \\\n",
    "                                                        FPATH_DATA_HEALTHY_TEST_FOLDS\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_and_unzip_data()\n",
    "\n",
    "CACHE_RESULTS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Conversion from time to frequency domain\n",
    "\n",
    "As described in the [data exploration notebook](01_data_exploration.ipymb), the data is given in the time domain.\n",
    "We transform it to the frequency domain.\n",
    "\n",
    "Each individual measurement is transformed to a frequency spectrum with a short-term Fourier transform (STFT) and Welch's method.\n",
    "- **Short-term Fourier transform (STFT)**: Let $x(t)$ represent the original vibration signal in the time domain with the time index $t$.\n",
    "The **STFT** is applied to $x(t)$ to obtain a representation $X(f,\\tau)$ in the frequency domain, where $f$ is the frequency index and $\\tau$ is the time window index.\n",
    "- **Welch's method**: Welch's method (also called the periodogram method) for estimating power spectra is carried out by dividing the time signal into successive blocks, forming the periodogram for each block, and averaging [source](https://ccrma.stanford.edu/~jos/sasp/Welch_s_Method.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nperseg = 10240\n",
    "noverlap = nperseg // 2\n",
    "nfft = None\n",
    "fs = 20480\n",
    "data_healthy, f = load_data(FILE_NAMES_HEALTHY, nperseg=nperseg, noverlap=noverlap, nfft=nfft, fs=fs)\n",
    "len(data_healthy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use most of the healthy data for training. Different train-test splits have been used in the past. In this latest version, we sample an equal amount of samples from the heathy and faulty data.\n",
    "\n",
    "Methods tried in the past:\n",
    "1. randomly shuffle the data and split into train and test set once\n",
    "2. 4 different independent splits\n",
    "3. repeat N times: Sample equal amount of samples from healthy and faulty data\n",
    "\n",
    "We sample the data according to (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 0.75\n",
    "N = 100\n",
    "\n",
    "data_healthy_train_folds = []\n",
    "data_healthy_test_folds = []\n",
    "for i in range(N):\n",
    "    # randomly sample equal amount of samples from healthy and faulty data\n",
    "    split_id = int(len(data_healthy) * SPLIT)\n",
    "    random.Random(i).shuffle(data_healthy)\n",
    "    data_healthy_train_ = data_healthy[:split_id]\n",
    "    data_healthy_test_ = data_healthy[split_id:]\n",
    "    data_healthy_train_folds.append(data_healthy_train_)\n",
    "    data_healthy_test_folds.append(data_healthy_test_)\n",
    "\n",
    "# save data_healthy_test_folds for usage in 04_online_anomaly_detection.ipynb\n",
    "if CACHE_RESULTS:\n",
    "    with open(FPATH_DATA_HEALTHY_TEST_FOLDS, 'wb') as file:  # TODO: store indices instead of complete file\n",
    "        pickle.dump(data_healthy_test_folds, file)\n",
    "\n",
    "print(f'There are {len(data_healthy_train_folds[0])} healthy samples in the first training fold.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Order transformation and binning\n",
    "\n",
    "In the order-transformed domain, the frequency components are transformed according to the number of rotations per minute (RPM) of the gears.\n",
    "The measurements are transformed to orders by dividing the frequency by the gear's rotational speed, which is given in the process conditions.\n",
    "We then bin the data into 50 bins, starting from 0.5 orders up to 100.5 orders. The bins are equally spaced and non-overlapping with a window size of 2.\n",
    "\n",
    "Below we load/calculate said order transformation.\n",
    "We cache this process, because it takes around 15 minutes to calculate.\n",
    "The plot illustrates the frequency band values for all measurements for the x-, y- and z-axis from top to bottom. \n",
    "The unique_sample_id is described by `<rpm>_<torque>_<run>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_RESULTS = True   # If True, cache the results locally\n",
    "setup = {'start': 0.5, 'stop': 100.5, 'n_windows': 50, 'window_steps': 2, 'window_size': 2}\n",
    "\n",
    "# load transformed data (if specified)\n",
    "try:\n",
    "    df_orders_train_folds, meta_data_train_folds = load_cached_data(\n",
    "            fpath_df_orders_train_folds=FPATH_DF_ORDERS_TRAIN_FOLDS,\n",
    "            fpath_meta_data_train_folds=FPATH_META_DATA_TRAIN_FOLDS\n",
    "        )\n",
    "\n",
    "# load train data and transform to orders\n",
    "except FileNotFoundError:\n",
    "    print('Constructing the train folds...')\n",
    "    df_vib_train_folds = []\n",
    "    df_orders_train_folds = []\n",
    "    meta_data_train_folds = []\n",
    "    for fold, data_healthy_train_ in enumerate(tqdm(data_healthy_train_folds, desc='Deriving orders on training set per fold')):\n",
    "        df_vib_train_folds.append(derive_df_vib(data_healthy_train_, f)) # f!!!\n",
    "        df_orders_train_, meta_data_train_ = derive_df_orders(df_vib_train_folds[-1], setup, f, verbose=False)\n",
    "        df_orders_train_[meta_data_train_.columns] = meta_data_train_\n",
    "        df_orders_train_folds.append(df_orders_train_)\n",
    "        meta_data_train_folds.append(meta_data_train_)\n",
    "    if CACHE_RESULTS:\n",
    "        # cache train data\n",
    "        os.makedirs(os.path.dirname(FPATH_DF_ORDERS_TRAIN_FOLDS), exist_ok=True)\n",
    "        with open(FPATH_DF_ORDERS_TRAIN_FOLDS, 'wb') as file:\n",
    "            pickle.dump(df_orders_train_folds, file)\n",
    "        # cache test data\n",
    "        os.makedirs(os.path.dirname(FPATH_META_DATA_TRAIN_FOLDS), exist_ok=True)\n",
    "        with open(FPATH_META_DATA_TRAIN_FOLDS, 'wb') as file:\n",
    "            pickle.dump(meta_data_train_folds, file)\n",
    "\n",
    "# plot effect of orders\n",
    "cols = df_orders_train_folds[-1].columns\n",
    "BAND_COLS = cols[cols.str.contains('band')].tolist()\n",
    "idx_cols = ['index', 'rotational speed [RPM]', 'torque [Nm]', 'direction',\n",
    "            'unique_sample_id', 'sample_id']\n",
    "cols = BAND_COLS + idx_cols\n",
    "df_ = df_orders_train_folds[-1].reset_index()[cols]\n",
    "df_ = pd.melt(df_, id_vars=idx_cols, var_name='frequency band', value_name='frequency band value')\n",
    "fig = px.line(df_, x='frequency band', y='frequency band value',\n",
    "              facet_row='direction', color='unique_sample_id',\n",
    "              hover_data=['rotational speed [RPM]', 'torque [Nm]'],\n",
    "              title='Frequency bands for healthy samples, after order-converion, before normalisation',\n",
    "              markers=True, width=1200, height=600)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe **major peaks at 40 and 80 orders**, highlighting the necessity of order transformation, to make different running conditions comparable.\n",
    "40 orders corresponds to the number of teeth of the driving gear (= **gear mesh frequency**), 80 orders corresponds to a **harmonic frequency**.\n",
    "The driven gear has 72 teeth which are not visible in the order spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Frequency-band normalization\n",
    "\n",
    "We further normalize the frequency bands to the same range. Given the $i\\text{th}$ measurement vector $\\mathbf{v}_i$, each order transformed bin $\\mathbf{v}_{ij}$ is normalized by the sum of all bins, specifically:\n",
    "\n",
    "$$\\mathbf{v}_{ij}' = \\mathbf{v}_{ij} / \\sum_j\\mathbf{v}_{ij}$$\n",
    "\n",
    ", where \n",
    "\n",
    "- $\\mathbf{v}_{ij}$ is the $j\\text{th}$ bin of the $i\\text{th}$ measurement vector $\\mathbf{v}_i$.\n",
    "- $\\mathbf{v}_{ij}'$ is the normalized $j\\text{th}$ bin of the $i\\text{th}$ measurement vector.\n",
    "- $\\sum_j\\mathbf{v}_{ij}$ is the sum of all bins of the $i\\text{th}$ measurement vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V_train_normalized_folds = [normalize_1(df_orders_train_, BAND_COLS) for df_orders_train_ in df_orders_train_folds]\n",
    "idx_vars = ['rotational speed [RPM]', 'torque [Nm]', 'direction', 'unique_sample_id', 'sample_id']\n",
    "df_ = df_V_train_normalized_folds[-1].reset_index()\n",
    "df_[idx_vars] = df_orders_train_folds[-1][idx_vars]\n",
    "df_ = pd.melt(df_, id_vars=['index'] + idx_vars, \n",
    "    var_name='frequency band', value_name='frequency band value'\n",
    "    )\n",
    "\n",
    "# plot effect of normalization\n",
    "fig = px.line(df_, x='frequency band', y='frequency band value',\n",
    "              facet_row='direction', color='unique_sample_id',\n",
    "            # hover_data=['rotational speed [RPM]', 'torque [Nm]'], \n",
    "              title='Frequency bands for healthy samples, after normalisation',\n",
    "              markers=True, width=1200, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order-transformed and normalized vibration measurements will be further used in the following notebook for the construction of the context-sensitive vibration fingerprints.\n",
    "They are cached below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CACHE_RESULTS:\n",
    "    with open(FPATH_DF_V_TRAIN_FOLDS, 'wb') as file:\n",
    "        pickle.dump(df_V_train_normalized_folds, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â©, 2023, Sirris"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
