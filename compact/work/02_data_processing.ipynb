{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHM North America challenge '23\n",
    "\n",
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from conscious_engie_icare import distance_metrics\n",
    "from conscious_engie_icare.normalization import normalize_1\n",
    "from conscious_engie_icare.nmf_profiling import derive_df_orders, derive_df_vib, extract_nmf_per_number_of_component\n",
    "from conscious_engie_icare.util import calc_tpr_at_fpr_threshold, calc_fpr_at_tpr_threshold, calculate_roc_characteristics\n",
    "from conscious_engie_icare.viz.viz import illustrate_nmf_components_for_paper\n",
    "from conscious_engie_icare.viz.spectrogram import plot_stft, plot_periodogram, plot_welch\n",
    "from conscious_engie_icare.data.phm_data_handler import BASE_PATH_HEALTHY, FILE_NAMES_HEALTHY, fetch_and_unzip_data, load_data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "import string\n",
    "import pickle\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from matplotlib.colors import LogNorm\n",
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_and_unzip_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a decomposition matrix \n",
    "\n",
    "1. [Load healthy data & extract FFT](#Load-all-healthy-data-and-extract-STFT-and-PSD)\n",
    "2. [Convert to orders](#Order-transformation)\n",
    "\n",
    "> **Difference to industrial use case**: There is only one location --> matrix is 3 dimensional instead of 6 dimensional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all healthy data and convert to frequency domain.\n",
    "\n",
    "As the data is given in the time domain, we transform it to the frequency domain.\n",
    "Each individual measurement is transformed to a frequency spectrum with a short-term Fourier transform (STFT).\n",
    "\n",
    "**Short-term Fourier transform (STFT)**: Let $x(t)$ represent the original vibration signal in the time domain with the time index $t$.\n",
    "The **STFT** is applied to $x(t)$ to obtain a representation $X(f,\\tau)$ in the frequency domain, where $f$ is the frequency index and $\\tau$ is the time window index.\n",
    "\n",
    "\n",
    "**Welch's method**: Welch's method (also called the periodogram method) for estimating power spectra is carried out by dividing the time signal into successive blocks, forming the periodogram for each block, and averaging [source](https://ccrma.stanford.edu/~jos/sasp/Welch_s_Method.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nperseg = 10240\n",
    "noverlap = nperseg // 2\n",
    "nfft = None\n",
    "fs = 20480\n",
    "data_healthy, f = load_data(FILE_NAMES_HEALTHY, nperseg=nperseg, noverlap=noverlap, nfft=nfft, fs=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use most of the healthy data for training. 25% are held out for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1: randomly shuffle the data and split into train and test set once\n",
    "# V2: 4 different independent splits\n",
    "# V3: repeat N times: Sample equal amount of samples from healthy and faulty data\n",
    "# ADD_VALIDATION_AND_TEST: determines whether to add validation and test data from the challenge (used with 'V1')\n",
    "RANDOM_SPLIT = 'V3'\n",
    "ADD_VALIDATION_AND_TEST = True\n",
    "SPLIT = 0.75\n",
    "N = 100\n",
    "CACHE_RESULTS = False\n",
    "LOAD_CACHED_RESULTS = True\n",
    "CACHING_FOLDER_NAME = os.path.join('..', 'data', 'CACHED_RESULTS_300124')\n",
    "assert RANDOM_SPLIT in ['V1', 'V2', 'V3']\n",
    "assert CACHE_RESULTS != LOAD_CACHED_RESULTS\n",
    "\n",
    "data_healthy_train_folds = []\n",
    "data_healthy_test_folds = []\n",
    "if RANDOM_SPLIT == 'V1':\n",
    "    N=1\n",
    "    # randomly shuffle the data and split into train and test set once\n",
    "    split_id = int(len(data_healthy) * SPLIT)\n",
    "    random.Random(42).shuffle(data_healthy)   # !!!\n",
    "    data_healthy_train = data_healthy[:split_id]\n",
    "    data_healthy_test = data_healthy[split_id:]\n",
    "    data_healthy_train_folds = [data_healthy_train]\n",
    "    data_healthy_test_folds = [data_healthy_test]\n",
    "elif RANDOM_SPLIT == 'V2':\n",
    "    N=4\n",
    "    n_total = len(data_healthy)\n",
    "    for i in range(4):\n",
    "        split_id_start = (n_total * i) // 4\n",
    "        split_id_stop = (n_total * (i+1)) // 4\n",
    "        data_healthy_test_ = data_healthy[split_id_start:split_id_stop]\n",
    "        data_healthy_train_ = data_healthy[:split_id_start] + data_healthy[split_id_stop:]\n",
    "        data_healthy_test_folds.append(data_healthy_test_)\n",
    "        data_healthy_train_folds.append(data_healthy_train_)\n",
    "elif RANDOM_SPLIT == 'V3':\n",
    "    for i in range(N):\n",
    "        # randomly sample equal amount of samples from healthy and faulty data\n",
    "        split_id = int(len(data_healthy) * SPLIT)\n",
    "        random.Random(i).shuffle(data_healthy)\n",
    "        data_healthy_train_ = data_healthy[:split_id]\n",
    "        data_healthy_test_ = data_healthy[split_id:]\n",
    "        data_healthy_test_folds.append(data_healthy_test_)\n",
    "        data_healthy_train_folds.append(data_healthy_train_)\n",
    "\n",
    "len(data_healthy_train_folds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order transformation and binning\n",
    "\n",
    "In the order-tarnsformed domain, the frequency components are transformed to the number of rotations per minute (RPM) of the gears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = {'start': 0.5, 'stop': 100.5, 'n_windows': 50, 'window_steps': 2, 'window_size': 2}\n",
    "\n",
    "# load transformed data (if specified)\n",
    "if LOAD_CACHED_RESULTS:\n",
    "    df_orders_train_folds, meta_data_train_folds = load_cached_data()\n",
    "\n",
    "# load train data and transform to orders\n",
    "else:\n",
    "    df_vib_train_folds = []\n",
    "    df_orders_train_folds = []\n",
    "    meta_data_train_folds = []\n",
    "    for fold, data_healthy_train_ in enumerate(tqdm(data_healthy_train_folds, desc='Deriving orders on training set per fold')):\n",
    "        df_vib_train_folds.append(derive_df_vib(data_healthy_train_, f)) # f!!!\n",
    "        df_orders_train_, meta_data_train_ = derive_df_orders(df_vib_train_folds[-1], setup, f, verbose=False)\n",
    "        df_orders_train_[meta_data_train_.columns] = meta_data_train_\n",
    "        df_orders_train_folds.append(df_orders_train_)\n",
    "        meta_data_train_folds.append(meta_data_train_)\n",
    "        \"\"\"\n",
    "        fpath = os.path.join('df_nmf_models_folds_241023', f'df_orders_train_folds_{fold}.pkl')\n",
    "        with open(fpath, 'wb') as file:\n",
    "            pickle.dump(df_orders_train_, file)\n",
    "        fpath = os.path.join('df_nmf_models_folds_241023', f'meta_data_train_folds_{fold}.pkl')\n",
    "        with open(fpath, 'wb') as file:\n",
    "            pickle.dump(meta_data_train_, file)\n",
    "        \"\"\"\n",
    "    if CACHE_RESULTS:\n",
    "        # cache train data\n",
    "        with open(fpath_df_orders_train_folds, 'wb') as file:\n",
    "            pickle.dump(df_orders_train_folds, file)\n",
    "        # cache test data\n",
    "        with open(fpath_meta_data_train_folds, 'wb') as file:\n",
    "            pickle.dump(meta_data_train_folds, file)\n",
    "\n",
    "# plot effect of orders\n",
    "cols = df_orders_train_folds[-1].columns\n",
    "BAND_COLS = cols[cols.str.contains('band')].tolist()\n",
    "idx_cols = ['index', 'rotational speed [RPM]', 'torque [Nm]', 'direction',\n",
    "            'unique_sample_id', 'sample_id']\n",
    "cols = BAND_COLS + idx_cols\n",
    "df_ = df_orders_train_folds[-1].reset_index()[cols]\n",
    "df_ = pd.melt(df_, id_vars=idx_cols, var_name='frequency band', value_name='frequency band value')\n",
    "fig = px.line(df_, x='frequency band', y='frequency band value',\n",
    "              facet_row='direction', color='unique_sample_id',\n",
    "              hover_data=['rotational speed [RPM]', 'torque [Nm]'],\n",
    "              title='Frequency bands for healthy samples, before normalisation',\n",
    "              markers=True, width=1200, height=600)\n",
    "# draw verical line at band_39.5-40.5 in plotly express figure\n",
    "# for x in [39, 79]:\n",
    "#    fig.add_shape(type='line', x0=x, y0=0, x1=x, y1=2, line=dict(color='black', width=1, dash='dash'))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe **major peaks at 40 and 80 orders**. \n",
    "40 orders corresponds to the number of teeth of the driving gear (= **gear mesh frequency**), 80 orders corresponds to a **harmonic frequency**.\n",
    "The driven gear has 72 teeth which are not visible in the order spectrum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency-band normalization\n",
    "\n",
    "> **Observation**, ***if there are no other sensors (y, z) present***: Without normalisation much higher explained variance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V_train_normalized_folds = [normalize_1(df_orders_train_, BAND_COLS) for df_orders_train_ in df_orders_train_folds]\n",
    "idx_vars = ['rotational speed [RPM]', 'torque [Nm]', 'direction', 'unique_sample_id', 'sample_id']\n",
    "df_ = df_V_train_normalized_folds[-1].reset_index()\n",
    "df_[idx_vars] = df_orders_train_folds[-1][idx_vars]\n",
    "df_ = pd.melt(df_, id_vars=['index'] + idx_vars, \n",
    "    var_name='frequency band', value_name='frequency band value'\n",
    "    )\n",
    "fig = px.line(df_, x='frequency band', y='frequency band value',\n",
    "              facet_row='direction', color='unique_sample_id',\n",
    "            # hover_data=['rotational speed [RPM]', 'torque [Nm]'], \n",
    "              title='Frequency bands for healthy samples, after normalisation',\n",
    "              markers=True, width=1200, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V_train_folds = df_V_train_normalized_folds # df_V_train_not_normalized "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large are the folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_V = [len(V_) for V_ in df_V_train_folds]\n",
    "pd.Series(len_V).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â©, 2023, Sirris"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
