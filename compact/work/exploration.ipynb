{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHM North America challenge '23\n",
    "\n",
    "## Problem description: Gear pitting\n",
    "\n",
    "Gear pitting is a surface fatigue failure of the gear tooth. It occurs due to repeated loading of tooth surface and the contact stress exceeding the surface fatigue strength of the material. Material in the fatigue region gets removed and a pit is formed. The pit itself will cause stress concentration and soon the pitting spreads to adjacent region till the whole surface is covered [[source](https://gearsmechon.wordpress.com/pitting-of-gears/)].\n",
    "\n",
    "## Dataset description\n",
    "\n",
    "The **training** dataset includes measurements under varied operating conditions from a healthy state as well as six known fault levels. The **testing and validation** datasets contain data from eleven health levels. Data from some fault levels and operating conditions are excluded from the training datasets to mirror real-world conditions where data collection may only be available from a subset of full range of operation. The training data are collected from a range of different operating conditions under 15 different rotational speeds and 6 different torque levels. Test and validation data operating conditions span 18 different rotational speeds and 6 different torque levels.\n",
    "\n",
    "[[source](https://data.phmsociety.org/phm2023-conference-data-challenge/)]\n",
    "\n",
    "<img src=\"https://data.phmsociety.org/wp-content/uploads/sites/9/2023/06/PHM2023dc_fig1.png\" alt=\"MarineGEO circle logo\" style=\"height: 375px; width:800px;\"/>\n",
    "\n",
    "<img src=\"https://data.phmsociety.org/wp-content/uploads/sites/9/2023/06/PHM2023dc_fig2.png\" alt=\"MarineGEO circle logo\" style=\"height: 300px; width:800px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from conscious_engie_icare import distance_metrics\n",
    "from conscious_engie_icare.normalization import normalize_1\n",
    "from conscious_engie_icare.nmf_profiling import derive_df_orders, derive_df_vib, extract_nmf_per_number_of_component\n",
    "from conscious_engie_icare.util import calc_tpr_at_fpr_threshold, calc_fpr_at_tpr_threshold, calculate_roc_characteristics\n",
    "from conscious_engie_icare.viz.viz import illustrate_nmf_components_for_paper\n",
    "from conscious_engie_icare.data import phm_data_handler\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "from scipy.signal import stft\n",
    "import numpy as np\n",
    "from scipy.signal import welch, periodogram\n",
    "import glob\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "import string\n",
    "import pickle\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from matplotlib.colors import LogNorm\n",
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "\n",
    "We first load the data and examine the structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phm_data_handler.fetch_and_unzip_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vibration data\n",
    "\n",
    "First we load the vibration dataset and examine a single vibration entry. \n",
    "For each vibration measurement there are triaxial time-domain vibration measurements available (`x`, `y` and `z`) in addition to the actual rpm (`tachometer`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm = 100\n",
    "torque = 500\n",
    "run = 1\n",
    "df_example = load_train_data(rpm, torque, run)\n",
    "print(f\"A single sample (rpm={rpm}, torque={torque}, run={run}) has the following shape:\")\n",
    "print(df_example.shape)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for var, ax in zip(['x', 'y', 'z'], axes):\n",
    "    ax.plot(df_example[var], label=var)\n",
    "    ax.set_title(var)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STFT\n",
    "\n",
    "Vibration Sampling Frequency = 20480 Hz [[source](https://data.phmsociety.org/phm2023-conference-data-challenge/)].\n",
    "\n",
    "> **Difference to industrial use case**: we determine FFT parameters on ourselfes.\n",
    "\n",
    "The STFT divides the signal into overlapping segments and calculates a Fourier Transform for each segment.\n",
    "It provides a localized view on the signal which is particularly useful for signals where the frequency components change over the measurement period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stft(df, var, nperseg=256, noverlap=None, nfft=None, fs=1):\n",
    "    f, t, Zxx = stft(df[var], nperseg=nperseg, noverlap=noverlap, nfft=nfft, fs=fs)\n",
    "    plt.pcolormesh(t, f, np.abs(Zxx))\n",
    "    plt.title(f'STFT Magnitude {var}')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.show()\n",
    "\n",
    "plot_stft(df_example, 'z', nperseg=None, fs=20480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expect that within each measurement there are no changes in the frequency components, we also check the periodogram below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power density estimation\n",
    "\n",
    "A periodogram is an estimate of the spectral density of a signal [[source](https://en.wikipedia.org/wiki/Periodogram)].\n",
    "\n",
    "> periodogram returns array with NaN values.\n",
    "\n",
    "Besides the periodogram, we also use Welch's method.\n",
    "**The primary idea behind Welch's method is to divide the original signal into overlapping segments, calculate the periodogram for each segment, and then average these periodograms to obtain a more stable estimate of the PSD.** This approach helps reduce the variance and noise inherent in the standard periodogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_periodogram(df, var, fs=1):\n",
    "    f, Pxx = periodogram(df[var], fs=fs)\n",
    "    plt.semilogy(f, Pxx)\n",
    "    plt.title(f'Periodogram {var}')\n",
    "    plt.xlabel('frequency [Hz]')\n",
    "    plt.ylabel('PSD amplitude')\n",
    "    plt.show()\n",
    "\n",
    "def plot_welch(df, var, nperseg=256, noverlap=None, nfft=None, fs=1, ax=None, legend=None):\n",
    "    f, Pxx = welch(df[var], nperseg=nperseg, noverlap=noverlap, nfft=nfft, fs=fs)\n",
    "    plt.semilogy(f, Pxx)\n",
    "    plt.title(f'Welch Power Spectral Density {var}')\n",
    "    plt.xlabel('frequency [Hz]')\n",
    "    plt.ylabel('PSD amplitude')\n",
    "    # plt.show()\n",
    "\n",
    "# dimension = 'x'\n",
    "# plot_periodogram(df_example, dimension, fs=20480)\n",
    "\n",
    "rpm=200\n",
    "torque=300\n",
    "run=3\n",
    "df_example = load_train_data(rpm=rpm, torque=torque, run=run)\n",
    "plot_welch(df_example, 'x', nperseg=128, fs=20480)\n",
    "plot_welch(df_example, 'y', nperseg=128, fs=20480)\n",
    "plot_welch(df_example, 'z', nperseg=128, fs=20480)\n",
    "plt.title(f'Measurement {run} @ {rpm} rpm, {torque} Nm');\n",
    "plt.legend(['x', 'y', 'z'], title='Direction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process parameters\n",
    "\n",
    "In contrast to the industrial feedwater pump use case, **operating conditions are very stable in the given dataset**.\n",
    "Therefore, clustering of operating modes based on a separate set of process paramters is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob.glob(os.path.join(BASE_PATH_HEALTHY, '*.txt'))\n",
    "# extract rpm, torque, run from filename\n",
    "\n",
    "def extract_process_parameters(file_path, use_train_data_for_validation=True):\n",
    "    parts = file_path.split('/')\n",
    "    filename = parts[-1]  # Extract the filename from the path\n",
    "    if use_train_data_for_validation:\n",
    "        v_value, n_value, sample_number = filename.split('_')  # Extract V, N, and sample number\n",
    "        return int(v_value[1:]), int(n_value[:-1]), int(sample_number.split('.')[0])\n",
    "    else:\n",
    "        sample_number, v_value, n_value = filename.split('_')\n",
    "        return int(v_value[1:]), int(n_value.split('.')[0][:-1]), int(sample_number)\n",
    "\n",
    "data = []\n",
    "for file_path in fnames:\n",
    "    v_value, n_value, sample_number = extract_process_parameters(file_path)\n",
    "    data.append({\n",
    "        'V': v_value,  # Remove the 'V' prefix and convert to integer\n",
    "        'N': n_value,  # Remove the 'N' suffix and convert to integer\n",
    "        'SampleNumber': sample_number  # Remove the '.txt' extension and convert to integer\n",
    "    })\n",
    "\n",
    "df_process = pd.DataFrame(data)\n",
    "\n",
    "print(\"--- Healthy data (pitting level 0) ---\")\n",
    "print(f\"Number of samples: {len(df_process)}\")\n",
    "print(f\"Number of unique RPM values: {len(df_process['V'].unique())}\")\n",
    "print(f\"Number of unique torque values: {len(df_process['N'].unique())}\")\n",
    "print(f\"Number of unique sample numbers: {len(df_process['SampleNumber'].unique())}\")\n",
    "df_process.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 77 unique combinations of rotational speed and torque in the training dataset.\n",
    "Each combination has 1-5 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique number of combinations of RPM and torque\n",
    "df_runs = df_process.groupby(['V', 'N']).size().reset_index(name='counts')\n",
    "df_runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a decomposition matrix \n",
    "\n",
    "1. [Load healthy data & extract FFT](#Load-all-healthy-data-and-extract-STFT-and-PSD)\n",
    "2. [Convert to orders](#Order-transformation)\n",
    "\n",
    "> **Difference to industrial use case**: There is only one location --> matrix is 3 dimensional instead of 6 dimensional\n",
    "\n",
    "> - [ ] TODO: Build decomposition matrix for all fault levels\n",
    "> - [x] TODO: Build decomposition matrix for all directions (x, y and z) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all healthy data and convert to frequency domain.\n",
    "\n",
    "As the data is given in the time domain, we transform it to the frequency domain.\n",
    "Each individual measurement is transformed to a frequency spectrum with a short-term Fourier transform (STFT).\n",
    "\n",
    "**Short-term Fourier transform (STFT)**: Let $x(t)$ represent the original vibration signal in the time domain with the time index $t$.\n",
    "The **STFT** is applied to $x(t)$ to obtain a representation $X(f,\\tau)$ in the frequency domain, where $f$ is the frequency index and $\\tau$ is the time window index.\n",
    "\n",
    "\n",
    "**Welch's method**: Welch's method (also called the periodogram method) for estimating power spectra is carried out by dividing the time signal into successive blocks, forming the periodogram for each block, and averaging [source](https://ccrma.stanford.edu/~jos/sasp/Welch_s_Method.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob.glob(os.path.join(BASE_PATH_HEALTHY, '*.txt'))\n",
    "\n",
    "import signal\n",
    "\n",
    "class timeout:\n",
    "    def __init__(self, seconds=1, error_message='Timeout'):\n",
    "        self.seconds = seconds\n",
    "        self.error_message = error_message\n",
    "    def handle_timeout(self, signum, frame):\n",
    "        raise TimeoutError(self.error_message)\n",
    "    def __enter__(self):\n",
    "        signal.signal(signal.SIGALRM, self.handle_timeout)\n",
    "        signal.alarm(self.seconds)\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.alarm(0)\n",
    "\n",
    "def load_data(fnames, use_train_data_for_validation=True, base_path=BASE_PATH_HEALTHY, **kwargs):\n",
    "    \"\"\"train_data --> process parameters are known. (TODO: change later)\"\"\"\n",
    "    data = []\n",
    "    for fn in tqdm(fnames):\n",
    "        rpm, torque, run = extract_process_parameters(fn, use_train_data_for_validation=use_train_data_for_validation)\n",
    "        try:\n",
    "            with timeout(seconds=4):\n",
    "                df = load_train_data(rpm, torque, run, base_path=base_path) if use_train_data_for_validation else load_test_data(rpm, torque, run, base_path=base_path)\n",
    "        except TimeoutError:\n",
    "            print(f'timed out loading {fn}')\n",
    "        f, t, stft_x = stft(df['x'], **kwargs)\n",
    "        f, t, stft_y = stft(df['y'], **kwargs)\n",
    "        f, t, stft_z = stft(df['z'], **kwargs)\n",
    "        f, psd_x = welch(df['x'], **kwargs)\n",
    "        f, psd_y = welch(df['y'], **kwargs)\n",
    "        f, psd_z = welch(df['z'], **kwargs)\n",
    "        data.append({\n",
    "            'rpm': rpm,\n",
    "            'torque': torque, \n",
    "            'sample_id': run,\n",
    "            'unique_sample_id': f'{rpm}_{torque}_{run}',  # Remove the '.txt' extension and convert to integer\n",
    "            'vibration_time_domain': df, \n",
    "            'stft_x': stft_x,\n",
    "            'stft_y': stft_y,\n",
    "            'stft_z': stft_z,  # Remove the '.txt' extension and convert to integer\n",
    "            'psd_x': psd_x,\n",
    "            'psd_y': psd_y,\n",
    "            'psd_z': psd_z\n",
    "        })\n",
    "    return data, f\n",
    "\n",
    "nperseg = 10240\n",
    "noverlap = nperseg // 2\n",
    "nfft = None\n",
    "fs = 20480\n",
    "data_healthy, f = load_data(fnames, nperseg=nperseg, noverlap=noverlap, nfft=nfft, fs=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use most of the healthy data for training. 25% are held out for validation.\n",
    "\n",
    "> TODO: have all operating modes in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V1: randomly shuffle the data and split into train and test set once\n",
    "# V2: 4 different independent splits\n",
    "# V3: repeat N times: Sample equal amount of samples from healthy and faulty data\n",
    "# ADD_VALIDATION_AND_TEST: determines whether to add validation and test data from the challenge (used with 'V1')\n",
    "RANDOM_SPLIT = 'V3'\n",
    "ADD_VALIDATION_AND_TEST = True\n",
    "SPLIT = 0.75\n",
    "N = 100\n",
    "CACHE_RESULTS = False\n",
    "LOAD_CACHED_RESULTS = True\n",
    "CACHING_FOLDER_NAME = 'CACHED_RESULTS_300124'\n",
    "assert RANDOM_SPLIT in ['V1', 'V2', 'V3']\n",
    "assert CACHE_RESULTS != LOAD_CACHED_RESULTS\n",
    "\n",
    "data_healthy_train_folds = []\n",
    "data_healthy_test_folds = []\n",
    "if RANDOM_SPLIT == 'V1':\n",
    "    N=1\n",
    "    # randomly shuffle the data and split into train and test set once\n",
    "    split_id = int(len(data_healthy) * SPLIT)\n",
    "    random.Random(42).shuffle(data_healthy)   # !!!\n",
    "    data_healthy_train = data_healthy[:split_id]\n",
    "    data_healthy_test = data_healthy[split_id:]\n",
    "    data_healthy_train_folds = [data_healthy_train]\n",
    "    data_healthy_test_folds = [data_healthy_test]\n",
    "elif RANDOM_SPLIT == 'V2':\n",
    "    N=4\n",
    "    n_total = len(data_healthy)\n",
    "    for i in range(4):\n",
    "        split_id_start = (n_total * i) // 4\n",
    "        split_id_stop = (n_total * (i+1)) // 4\n",
    "        data_healthy_test_ = data_healthy[split_id_start:split_id_stop]\n",
    "        data_healthy_train_ = data_healthy[:split_id_start] + data_healthy[split_id_stop:]\n",
    "        data_healthy_test_folds.append(data_healthy_test_)\n",
    "        data_healthy_train_folds.append(data_healthy_train_)\n",
    "elif RANDOM_SPLIT == 'V3':\n",
    "    for i in range(N):\n",
    "        # randomly sample equal amount of samples from healthy and faulty data\n",
    "        split_id = int(len(data_healthy) * SPLIT)\n",
    "        random.Random(i).shuffle(data_healthy)\n",
    "        data_healthy_train_ = data_healthy[:split_id]\n",
    "        data_healthy_test_ = data_healthy[split_id:]\n",
    "        data_healthy_test_folds.append(data_healthy_test_)\n",
    "        data_healthy_train_folds.append(data_healthy_train_)\n",
    "\n",
    "len(data_healthy_train_folds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order transformation and binning\n",
    "\n",
    "In the order-tarnsformed domain, the frequency components are transformed to the number of rotations per minute (RPM) of the gears.\n",
    "\n",
    "> Contrast to industrial use case: trivial due to static RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_df_orders_train_folds = os.path.join(CACHING_FOLDER_NAME, f'df_orders_train_folds.pkl')\n",
    "fpath_meta_data_train_folds = os.path.join(CACHING_FOLDER_NAME, f'meta_data_train_folds.pkl')\n",
    "setup = {'start': 0.5, 'stop': 100.5, 'n_windows': 50, 'window_steps': 2, 'window_size': 2}\n",
    "\n",
    "# load transformed data (if specified)\n",
    "if LOAD_CACHED_RESULTS:\n",
    "    with open(fpath_df_orders_train_folds, 'rb') as file:\n",
    "        df_orders_train_folds = pickle.load(file)\n",
    "    with open(fpath_meta_data_train_folds, 'rb') as file:\n",
    "        meta_data_train_folds = pickle.load(file)\n",
    "\n",
    "# load train data and transform to orders\n",
    "else:\n",
    "    df_vib_train_folds = []\n",
    "    df_orders_train_folds = []\n",
    "    meta_data_train_folds = []\n",
    "    for fold, data_healthy_train_ in enumerate(tqdm(data_healthy_train_folds, desc='Deriving orders on training set per fold')):\n",
    "        df_vib_train_folds.append(derive_df_vib(data_healthy_train_, f)) # f!!!\n",
    "        df_orders_train_, meta_data_train_ = derive_df_orders(df_vib_train_folds[-1], setup, f, verbose=False)\n",
    "        df_orders_train_[meta_data_train_.columns] = meta_data_train_\n",
    "        df_orders_train_folds.append(df_orders_train_)\n",
    "        meta_data_train_folds.append(meta_data_train_)\n",
    "        \"\"\"\n",
    "        fpath = os.path.join('df_nmf_models_folds_241023', f'df_orders_train_folds_{fold}.pkl')\n",
    "        with open(fpath, 'wb') as file:\n",
    "            pickle.dump(df_orders_train_, file)\n",
    "        fpath = os.path.join('df_nmf_models_folds_241023', f'meta_data_train_folds_{fold}.pkl')\n",
    "        with open(fpath, 'wb') as file:\n",
    "            pickle.dump(meta_data_train_, file)\n",
    "        \"\"\"\n",
    "    if CACHE_RESULTS:\n",
    "        # cache train data\n",
    "        with open(fpath_df_orders_train_folds, 'wb') as file:\n",
    "            pickle.dump(df_orders_train_folds, file)\n",
    "        # cache test data\n",
    "        with open(fpath_meta_data_train_folds, 'wb') as file:\n",
    "            pickle.dump(meta_data_train_folds, file)\n",
    "\n",
    "# plot effect of orders\n",
    "cols = df_orders_train_folds[-1].columns\n",
    "BAND_COLS = cols[cols.str.contains('band')].tolist()\n",
    "idx_cols = ['index', 'rotational speed [RPM]', 'torque [Nm]', 'direction',\n",
    "            'unique_sample_id', 'sample_id']\n",
    "cols = BAND_COLS + idx_cols\n",
    "df_ = df_orders_train_folds[-1].reset_index()[cols]\n",
    "df_ = pd.melt(df_, id_vars=idx_cols, var_name='frequency band', value_name='frequency band value')\n",
    "fig = px.line(df_, x='frequency band', y='frequency band value',\n",
    "              facet_row='direction', color='unique_sample_id',\n",
    "              hover_data=['rotational speed [RPM]', 'torque [Nm]'],\n",
    "              title='Frequency bands for healthy samples, before normalisation',\n",
    "              markers=True, width=1200, height=600)\n",
    "# draw verical line at band_39.5-40.5 in plotly express figure\n",
    "# for x in [39, 79]:\n",
    "#    fig.add_shape(type='line', x0=x, y0=0, x1=x, y1=2, line=dict(color='black', width=1, dash='dash'))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe **major peaks at 40 and 80 orders**. \n",
    "40 orders corresponds to the number of teeth of the driving gear (= **gear mesh frequency**), 80 orders corresponds to a **harmonic frequency**.\n",
    "The driven gear has 72 teeth which are not visible in the order spectrum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency-band normalization\n",
    "\n",
    "> **Observation**, ***if there are no other sensors (y, z) present***: Without normalisation much higher explained variance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V_train_normalized_folds = [normalize_1(df_orders_train_, BAND_COLS) for df_orders_train_ in df_orders_train_folds]\n",
    "idx_vars = ['rotational speed [RPM]', 'torque [Nm]', 'direction', 'unique_sample_id', 'sample_id']\n",
    "df_ = df_V_train_normalized_folds[-1].reset_index()\n",
    "df_[idx_vars] = df_orders_train_folds[-1][idx_vars]\n",
    "df_ = pd.melt(df_, id_vars=['index'] + idx_vars, \n",
    "    var_name='frequency band', value_name='frequency band value'\n",
    "    )\n",
    "fig = px.line(df_, x='frequency band', y='frequency band value',\n",
    "              facet_row='direction', color='unique_sample_id',\n",
    "            # hover_data=['rotational speed [RPM]', 'torque [Nm]'], \n",
    "              title='Frequency bands for healthy samples, after normalisation',\n",
    "              markers=True, width=1200, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_V_train_folds = df_V_train_normalized_folds # df_V_train_not_normalized "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large are the folds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_V = [len(V_) for V_ in df_V_train_folds]\n",
    "pd.Series(len_V).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-negative matrix factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore convergence warnings (1000 iterations reached by NMF)\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore');\n",
    "\n",
    "# if LOAD_CACHED_RESULTS:\n",
    "if False:\n",
    "    with open(os.path.join(CACHING_FOLDER_NAME, f'df_nmf_models_folds.pkl'), 'rb') as file:\n",
    "        df_nmf_models_folds = pickle.load(file)\n",
    "if not LOAD_CACHED_RESULTS:\n",
    "    MAX_N_COMPONENTS = 40\n",
    "    # cache df_nmf_folds on the disk\n",
    "    # df_nmf_models_folds = []\n",
    "    for fold, df_V_train_ in enumerate(tqdm(df_V_train_folds, desc='Extracting NMF models per fold')):\n",
    "        fpath = os.path.join(CACHING_FOLDER_NAME, 'df_nmf_models_folds', f'df_nmf_models_folds_{fold}.pkl')\n",
    "        df_nmf_models_ = extract_nmf_per_number_of_component(\n",
    "            df_V_train_, n_components=MAX_N_COMPONENTS, timestamps=df_V_train_.index, verbose=False\n",
    "        )   #changed timestamps from df_V_train_normalized.index to df_V_train.index\n",
    "        # df_nmf_models_folds.append(df_nmf_models_)\n",
    "        fpath = os.path.join(CACHING_FOLDER_NAME, 'df_nmf_models_folds', f'df_nmf_models_folds_{fold}.pkl')\n",
    "        if CACHE_RESULTS:\n",
    "            pickle.dump(df_nmf_models_, open(fpath, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - If we use 10-fold cross-validation, we have to extract the NMF components for each fold individually. In some cases it is better to extract 4 in others 5\n",
    "> - There seems to be a bug in the decomposition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hyperparameters for NMF\n",
    "FOLD = 2\n",
    "QMIN = 0.001\n",
    "QMAX = 0.999\n",
    "MIN_EXPLAINED_VARIANCE = 95 # 99.9 # 95\n",
    "ORDER_COMPONENTS = None # list(range(15))\n",
    "\n",
    "df_nmf_models_folds = []\n",
    "for fold in tqdm(list(range(N)), desc='Loading NMF models per fold'):\n",
    "    # fpath = os.path.join('df_nmf_models_folds_301023', f'df_nmf_models_folds_{i}.pkl')\n",
    "    fpath = os.path.join(CACHING_FOLDER_NAME, 'df_nmf_models_folds', f'df_nmf_models_folds_{fold}.pkl')\n",
    "    models_ = pickle.load(open(fpath, 'rb'))\n",
    "    df_nmf_models_folds.append(models_)\n",
    "\n",
    "df_V_train_ = df_V_train_folds[FOLD]\n",
    "df_nmf_models_ = df_nmf_models_folds[FOLD]\n",
    "\n",
    "# get minimum and maximum for feature space\n",
    "vmin = df_V_train_.stack().quantile(q=QMIN)\n",
    "print(f'    - took {vmin} (=0.01 quantile) as vmin for plotting feature space')\n",
    "vmax = df_V_train_.stack().quantile(q=QMAX)\n",
    "print(f'    - took {vmax} (=0.99 quantile) as vmax for plotting feature space')\n",
    "\n",
    "# calculate explained variance\n",
    "print(f'- calculating explained variance...')\n",
    "pca = PCA(n_components=len(BAND_COLS), random_state=42)\n",
    "pca.fit(df_V_train_)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_.cumsum()\n",
    "explained_variance_ratio = explained_variance_ratio[:39]\n",
    "\n",
    "fig, _ = illustrate_nmf_components_for_paper(\n",
    "    df_V_train_, explained_variance_ratio, df_nmf_models_, pd.Series(BAND_COLS),\n",
    "    min_explained_variance=MIN_EXPLAINED_VARIANCE, order_components=ORDER_COMPONENTS,\n",
    "    vmin=vmin, vmax=vmax, xlims=(-1,101), plot_x_ticks=[0, 10, 20, 30, 40, 49]\n",
    ")\n",
    "\n",
    "fig.savefig(os.path.join('figs', 'nmf_exemplary_fold.pdf'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - TODO: SOME EMPTY FREQUENCY BANDS or just extreme outliers (set `QMIN=0.01` and `QMAX=0.99`)?\n",
    "> - after adding all directions (x, y, z): slightly less explained variance, still very high though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = 5\n",
    "COMPONENT_COLUMNS = list(range(N_COMPONENTS))  # used later\n",
    "\n",
    "model_folds = []\n",
    "for df_nmf_models_ in df_nmf_models_folds:\n",
    "    model_ = df_nmf_models_[(df_nmf_models_.n_components == N_COMPONENTS)].iloc[0]\n",
    "    model_folds.append(model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline vibration fingerprint extraction\n",
    "\n",
    "In contrast to the industrial dataset, in this dataset there are no timestamps. However, we know speed and torque for each measurement. Therefore, we merge the fingerprint with the operating mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_W_train_with_OM_folds = []\n",
    "\n",
    "for i, (model_, df_V_train_normalized_, meta_data_train_) in enumerate(zip(model_folds, df_V_train_normalized_folds, meta_data_train_folds)):\n",
    "    W_train_ = model_.W.reshape(-1, N_COMPONENTS)\n",
    "    df_W_train_ = pd.DataFrame(W_train_)\n",
    "    display(f'Fold {i}. Shape: {W_train_.shape}')\n",
    "    df_W_train_.index = df_V_train_normalized_.index\n",
    "    df_W_train_['direction'] = meta_data_train_['direction']\n",
    "\n",
    "    # add operating mode (OM)\n",
    "    df_W_train_with_OM_ = pd.merge(df_W_train_, meta_data_train_.drop(columns=['direction']), left_index=True, right_index=True)\n",
    "    df_W_train_with_OM_folds.append(df_W_train_with_OM_)\n",
    "\n",
    "df_W_train_with_OM_folds[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the weights of an individual measurement from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same measurement is in three of four training folds\n",
    "rpm=100\n",
    "torque=500\n",
    "run=1\n",
    "fold=0\n",
    "\n",
    "df_W_train_with_OM_ = df_W_train_with_OM_folds[fold]\n",
    "df_ = df_W_train_with_OM_[(df_W_train_with_OM_['rotational speed [RPM]']==rpm) &\n",
    "                          (df_W_train_with_OM_['torque [Nm]']==torque) &\n",
    "                          (df_W_train_with_OM_['sample_id']==run)]\n",
    "df_ = df_.set_index('direction')\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(df_[list(range(N_COMPONENTS))], annot=True, fmt=\".3f\", ax=ax, cmap='Blues', vmin=0, vmax=0.1, cbar=False)\n",
    "ax.set_title(f'Measurement {run} @ {rpm} rpm, {torque} Nm');\n",
    "ax.set_xlabel('component');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vibration fingerprint is the aggregation over all measurements of a given operating mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_W_train_with_OM_ = df_W_train_with_OM_folds[fold]\n",
    "df_ = df_W_train_with_OM_[(df_W_train_with_OM_['rotational speed [RPM]']==rpm) & (df_W_train_with_OM_['torque [Nm]']==torque)]\n",
    "df_ = df_[list(range(N_COMPONENTS)) + ['direction']].groupby('direction').mean()\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(df_, annot=True, fmt=\".3f\", ax=ax, cmap='Blues', vmin=0, vmax=0.1, cbar=False)\n",
    "ax.set_title(f'Vibration fingerprint @ {rpm} rpm, {torque} Nm');\n",
    "ax.set_xlabel('component');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating mode detection\n",
    "\n",
    "In this dataset, a large part of our previously constructed process pipeline it is not necessary for cluster operating modes.\n",
    "1. First, there are only two process parameters, removing the need to reduce the dimensionality of the data.\n",
    "2. Second, process parameters and vibration measurements are already associated, making it unnecessary to manually merge them based on timestamps.\n",
    "\n",
    "In this section we propose two methods to cluster the operating modes: \n",
    "\n",
    "1. Treating each unique combination of speed and torque as a separate operating mode.\n",
    "2. (Setting clusters based on differences in vibration profiles.) \n",
    "\n",
    "> The second one is an optional TODO atm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating each unique combination of speed and torque as a separate operating mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique combination of RPM and torque, assign a unique cluster label\n",
    "cluster_label_unique_name_mapping_folds = []\n",
    "for i, df_W_train_with_OM_ in enumerate(df_W_train_with_OM_folds):\n",
    "    df_W_train_with_OM_['cluster_label_unique'] = df_W_train_with_OM_.groupby(['rotational speed [RPM]', 'torque [Nm]']).ngroup()\n",
    "    df_W_train_with_OM_folds[i] = df_W_train_with_OM_\n",
    "    cluster_label_unique_name_mapping_folds.append(df_W_train_with_OM_.groupby('cluster_label_unique').first()[['rotational speed [RPM]', 'torque [Nm]']].reset_index())\n",
    "\n",
    "cluster_label_unique_name_mapping_folds[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we extract and illustrate the fingerprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_FINGERPRINTS = True\n",
    "\n",
    "# extract operating mode wise fingerprints\n",
    "grouping_vars = ['direction', 'cluster_label_unique']\n",
    "fingerprints_folds = []\n",
    "for i, df_W_train_with_OM_ in enumerate(df_W_train_with_OM_folds):\n",
    "    df_ = df_W_train_with_OM_[COMPONENT_COLUMNS + grouping_vars].copy()\n",
    "    fingerprints_ = {\n",
    "        om: om_group.groupby(['direction']).mean().drop(columns=['cluster_label_unique']) for om, om_group in df_.groupby('cluster_label_unique')\n",
    "    }\n",
    "    fingerprints_folds.append(fingerprints_)\n",
    "\n",
    "# illustrate fingerprints\n",
    "fingerprints_ = fingerprints_folds[fold]\n",
    "cluster_label_unique_name_mapping_ = cluster_label_unique_name_mapping_folds[fold]\n",
    "if SHOW_FINGERPRINTS:\n",
    "    nrows = math.ceil(len(fingerprints_) / 3)\n",
    "    fig, axes = plt.subplots(figsize=(18, 3*nrows), nrows=nrows, ncols=3, sharex=True, sharey=True)\n",
    "    for om, ax in tqdm(zip(fingerprints_, axes.flat), total=len(fingerprints_), desc='Plotting fingerprints'):\n",
    "        om_group = fingerprints_[om]\n",
    "        om_group.columns = om_group.columns.astype(str)\n",
    "        sns.heatmap(om_group, annot=True, fmt=\".3f\", ax=ax, cmap='Blues', vmin=0, vmax=0.1, cbar=False)\n",
    "        rpm = cluster_label_unique_name_mapping_[cluster_label_unique_name_mapping_.cluster_label_unique == om]['rotational speed [RPM]'].values[0]\n",
    "        Nm = cluster_label_unique_name_mapping_[cluster_label_unique_name_mapping_.cluster_label_unique == om]['torque [Nm]'].values[0]\n",
    "        ax.set_title(f'OM {om}, ({rpm} rpm, {Nm} Nm))')\n",
    "        ax.set_xlabel('component')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> OBSERVATION: OFTEN EITHER ONE OR THE OTHER COMPONENT ACTIVATET, IF PEAKS OVERLAPPING (e.g. component 1 and 2)\n",
    "> - --> local method? \n",
    "> - --> other decomposition method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot pairwise distance between operating modes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_distances = []\n",
    "fingerprints_ = fingerprints_folds[fold]\n",
    "for om1 in fingerprints_:\n",
    "    fp1 = fingerprints_[om1]\n",
    "    for om2 in fingerprints_:\n",
    "        fp2 = fingerprints_[om2]\n",
    "        dist_ = distance_metrics.cosine_distance(fp1, fp2)\n",
    "        pairwise_distances.append({'om1': om1, 'om2': om2, 'dist': dist_})\n",
    "df_pairwise_dist = pd.DataFrame(pairwise_distances)\n",
    "\n",
    "df_plot = df_pairwise_dist.pivot(\"om1\", \"om2\", \"dist\")\n",
    "fig, ax = plt.subplots(figsize=(20, 16))\n",
    "sns.heatmap(df_plot, ax=ax, cmap='Blues', annot=False, fmt=\".2f\")\n",
    "ax.set_title(f\"Cosine distance between fingerpints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regrouping vibration fingerprints (consensus operating modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprints_ = fingerprints_folds[fold]\n",
    "\n",
    "def plot_dendrogram(linkage_matrix, ax=None, **kwargs):\n",
    "    dendrogram(linkage_matrix, ax=ax, **kwargs)\n",
    "    ax.set_title('Hierarchical Clustering Dendrogram')\n",
    "    ax.set_xlabel('Samples')\n",
    "    ax.set_ylabel('Distance')\n",
    "    #xlbls = ax.get_xmajorticklabels()\n",
    "    #lbls = [replace_number_with_letter_(l.get_text()) for l in xlbls]\n",
    "    #ax.set_xticklabels(lbls)\n",
    "    return ax\n",
    "\n",
    "fingerprints_feature_space = np.vstack(pd.Series(fingerprints_).apply(lambda df: df.stack().values).to_numpy())\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 10), ncols=2, nrows=2, sharey=True)\n",
    "axes = axes.flatten()\n",
    "fig.suptitle('Hierarchical Clustering Dendrogram')\n",
    "\n",
    "# Single linkage clustering\n",
    "linkage_matrix_avg = linkage(pdist(fingerprints_feature_space, metric='cosine'), optimal_ordering=True, method='single')\n",
    "ax = plot_dendrogram(linkage_matrix_avg, ax=axes[0])\n",
    "ax.set_title('Single-link (nearest point)')\n",
    "\n",
    "# Complete linkage clustering\n",
    "linkage_matrix_ward = linkage(pdist(fingerprints_feature_space, metric='cosine'), optimal_ordering=True, method='complete')\n",
    "ax = plot_dendrogram(linkage_matrix_ward, ax=axes[1])\n",
    "ax.set_title('Complete-link (farthest point)')\n",
    "\n",
    "# Average linkage clustering: WPGMA\n",
    "linkage_matrix_avg = linkage(pdist(fingerprints_feature_space, metric='cosine'), optimal_ordering=True, method='weighted')\n",
    "ax = plot_dendrogram(linkage_matrix_avg, ax=axes[2])\n",
    "ax.set_title('Average-link (WPGMA)')\n",
    "\n",
    "# Average linkage clustering: UPGMA\n",
    "linkage_matrix_avg = linkage(pdist(fingerprints_feature_space, metric='cosine'), optimal_ordering=True, method='average')\n",
    "ax = plot_dendrogram(linkage_matrix_avg, ax=axes[3])\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Average-link (UPGMA): preferred method')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold to determine the number of clusters (you can adjust this threshold as needed)\n",
    "threshold = 0.5\n",
    "\n",
    "linkage_matrix_avg = linkage(pdist(fingerprints_feature_space, metric='cosine'), optimal_ordering=True, method='average')\n",
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "ax = plot_dendrogram(linkage_matrix_avg, ax=ax, color_threshold=threshold, above_threshold_color='k')\n",
    "ax.set_title('Average-link (UPGMA)')\n",
    "ax.axhline(y=threshold, c='k', ls='--', lw=1)\n",
    "\n",
    "# Get the cluster labels based on the threshold\n",
    "cluster_labels = fcluster(linkage_matrix_avg, threshold, criterion='distance')\n",
    "# generate dictionary where each operating mode is mapped to the respective group and save locally\n",
    "cluster_labels_dict = dict(zip(list(string.ascii_uppercase[0:len(cluster_labels)]), cluster_labels))\n",
    "#if CACHE_RESULTS:\n",
    "if False:\n",
    "    with open('cluster_labels_dict.pickle', 'wb') as fp:\n",
    "        pickle.dump(cluster_labels_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick_color = {1: 'blue', 2: 'red', 3: 'green', 4: 'orange', 5: 'purple', 6: 'brown', 7: 'pink', 8: 'gray', 9: 'olive', 10: 'cyan'}\n",
    "\n",
    "dfs_ = {om: fingerprints_[om].values.flatten() for om in fingerprints_}\n",
    "fig, ax = plt.subplots(figsize=(4, 18))\n",
    "ax.set_title('Fingerprinting featurespace with corresponding cluster', fontsize=32)\n",
    "\n",
    "df = pd.DataFrame(dfs_).T\n",
    "sns.heatmap(df, ax=ax, cmap='Blues', annot=False, fmt=\".2f\", norm=LogNorm())\n",
    "texts = []\n",
    "for tick, cluster_label_ in zip(ax.get_yticklabels(), cluster_labels):\n",
    "    tick.set_color(tick_color[cluster_label_])\n",
    "    texts.append(f'{tick.get_text()} ({cluster_label_})')\n",
    "ax.set_xlabel('Component', fontsize=24)\n",
    "ax.set_ylabel('Fingerprint (cluster-id)', fontsize=24)\n",
    "ax.set_yticklabels(texts, rotation=0, fontsize=16);\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online fingerprint extraction (C02)\n",
    "\n",
    "For the test set, we first load the process and vibration data that exhibit a high level of pitting and merge it with the healthy data that we previously held back.\n",
    "\n",
    "> Formerly we wrote: First we load the process data for the test set (which is formatted slightly different than the train data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test data\n",
    "\n",
    "At the moment, the test data consists of two different conditions:\n",
    "1. **Anomaly condition**: Pitting level 8\n",
    "2. **Anomaly condition**: Healthy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading anomalous test data\n",
    "\n",
    "There are 296 samples in the test set that exhibit a high level of pitting (pitting level 8) that were recorded at different speeds and torques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code cell is not essential for the notebook\n",
    "\n",
    "USE_TRAINING_SET_FOR_VALIDATION = True\n",
    "# PITTING_LEVEL = 1\n",
    "pitting_levels = [1, 2, 3, 4, 6, 8]\n",
    "\n",
    "if USE_TRAINING_SET_FOR_VALIDATION:\n",
    "    # BASE_PATH_TEST = os.path.join('Data_Challenge_PHM2023_training_data', f'Pitting_degradation_level_{PITTING_LEVEL}')\n",
    "    base_paths_test = [os.path.join('Data_Challenge_PHM2023_training_data', f'Pitting_degradation_level_{pitting_level}') for pitting_level in pitting_levels]\n",
    "else:\n",
    "    # BASE_PATH_TEST = os.path.join('Data_Challenge_PHM2023_test_data')\n",
    "    base_paths_test = [os.path.join('Data_Challenge_PHM2023_test_data')]\n",
    "\n",
    "df_process_test_dict_ = {}\n",
    "for lvl, path_ in zip(pitting_levels, base_paths_test):\n",
    "    fnames = glob.glob(os.path.join(path_, '*.txt'))\n",
    "    data_test_ = []\n",
    "    for file_path in fnames:\n",
    "        v_value, n_value, sample_number = extract_process_parameters(file_path, use_train_data_for_validation=USE_TRAINING_SET_FOR_VALIDATION)  # change train_data after restarting notebook\n",
    "        data_test_.append({\n",
    "            'V': v_value,  # Remove the 'V' prefix and convert to integer\n",
    "            'N': n_value,  # Remove the 'N' suffix and convert to integer\n",
    "            'SampleNumber': sample_number  # Remove the '.txt' extension and convert to integer\n",
    "        })\n",
    "\n",
    "    df_process_test_dict_[lvl] = pd.DataFrame(data_test_)\n",
    "\n",
    "    print(f\"--- Unhealthy data (pitting level {lvl}) ---\")\n",
    "    print(f\"Number of samples: {len(df_process_test_dict_[lvl])}\")\n",
    "    print(f\"Number of unique RPM values: {len(df_process_test_dict_[lvl]['V'].unique())},\",\n",
    "          f\"torque values: {len(df_process_test_dict_[lvl]['N'].unique())},\",\n",
    "          f\"sample numbers: {len(df_process_test_dict_[lvl]['SampleNumber'].unique())}\")\n",
    "\n",
    "df_process_test_dict_[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test vibration data and transform to orders.\n",
    "We normalize test vibration data with the same normalization parameters as the train data.\n",
    "In contrast to the original dataset, it is not necessary to select valid vibration measurement periods, as all measurements were taken at the same time.\n",
    "\n",
    "> TODO: operating mode detection based on vibration fingerprints\n",
    "> \n",
    "> For the moment we assign immediately the ground truth. Instead, we wish to train a classifier on the operating mode groups to predict the operating mode based on the vibration fingerprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data in original format\n",
    "df_orders_test_pitting_dict = {}\n",
    "meta_data_test_pitting_dict = {}\n",
    "for lvl, path in tqdm(zip(pitting_levels, base_paths_test), desc='Extracting test data', total=len(base_paths_test)):\n",
    "    fnames = glob.glob(os.path.join(path, '*.txt'))\n",
    "    data_test, f = load_data(fnames, nperseg=nperseg, noverlap=noverlap, nfft=nfft, fs=fs, base_path=path, \n",
    "                            use_train_data_for_validation=USE_TRAINING_SET_FOR_VALIDATION)  # !!! change train_data to use_train_data_for_validation after restarting notebook\n",
    "\n",
    "    # extract vibration data\n",
    "    df_vib_test_unhealthy = derive_df_vib(data_test, f)\n",
    "\n",
    "    # convert to orders and derive meta data\n",
    "    df_orders_test_pitting_, meta_data_test_pitting_ = derive_df_orders(df_vib_test_unhealthy, setup, f, verbose=False)\n",
    "    if USE_TRAINING_SET_FOR_VALIDATION:\n",
    "        print('transforming sample-id in test set')\n",
    "        # meta_data_test_pitting_8['test_sample_id'] = meta_data_test_pitting_8.groupby(['rotational speed [RPM]', 'torque [Nm]', 'sample_id']).ngroup() + 1   # !!! might not be necessary\n",
    "        rpm = meta_data_test_pitting_['rotational speed [RPM]']\n",
    "        torque = meta_data_test_pitting_['torque [Nm]']\n",
    "        run = meta_data_test_pitting_['sample_id']\n",
    "        meta_data_test_pitting_['unique_sample_id'] = rpm.astype(str) + '_' + torque.astype(str) + '_' + run.astype(str) + f'_pitting_level_{lvl}'\n",
    "\n",
    "    df_orders_test_pitting_['unique_sample_id'] = meta_data_test_pitting_['unique_sample_id'] # + f'_pitting_level_{lvl}'\n",
    "\n",
    "    df_orders_test_pitting_dict[lvl] = df_orders_test_pitting_\n",
    "    meta_data_test_pitting_dict[lvl] = meta_data_test_pitting_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the balanced train-test split we exclude all operating modes that are not present in the training set.\n",
    "# check if we can filter unrelated operating modes from df_orders_test_pitting_dict and meta_data_test_pitting_dict here\n",
    "# --> need to do this per healthy fold \n",
    "\"\"\"\n",
    "if SPLIT = 'V3':\n",
    "    print('Removing samples from test set that expose operating conditions not found in the training set')\n",
    "    for pitting_level in meta_data_test_pitting_dict:\n",
    "        # exclude entries that show rotational speed [RPM] and torque [Nm] that are not in the training set\n",
    "        old_meta_data_ = meta_data_test_pitting_dict[pitting_level]\n",
    "        new_meta_data_ = old_meta_data_[old_meta_data_.unique_sample_id.isin(df_process.unique_sample_id)]\n",
    "        meta_data_test_pitting_dict[pitting_level] = new_meta_data_\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "OOOOOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_df_orders_test_folds = os.path.join(CACHING_FOLDER_NAME, f'df_orders_test_folds.pkl')\n",
    "fpath_meta_data_test_folds = os.path.join(CACHING_FOLDER_NAME, f'meta_data_test_folds.pkl')\n",
    "\n",
    "# load transformed data (if specified)\n",
    "if LOAD_CACHED_RESULTS:\n",
    "    with open(fpath_df_orders_test_folds, 'rb') as file:\n",
    "        df_orders_test_folds = pickle.load(file)\n",
    "    with open(fpath_meta_data_test_folds, 'rb') as file:\n",
    "        meta_data_test_folds = pickle.load(file)\n",
    "# transform test data to orders\n",
    "else:\n",
    "    # convert healthy test samples to orders\n",
    "    meta_data_test_healthy_folds = []\n",
    "    df_orders_test_healthy_folds = []\n",
    "    for data_healthy_test_ in tqdm(data_healthy_test_folds, desc='convert healthy test samples to orders per fold'):\n",
    "        df_vib_test_healthy_ = derive_df_vib(data_healthy_test_, f)\n",
    "        df_orders_test_healthy_, meta_data_test_healthy_ = derive_df_orders(df_vib_test_healthy_, setup, f, verbose=False)\n",
    "        meta_data_test_healthy_['unique_sample_id'] = meta_data_test_healthy_['unique_sample_id'] + '_healthy'\n",
    "        df_orders_test_healthy_['unique_sample_id'] = meta_data_test_healthy_['unique_sample_id']\n",
    "        meta_data_test_healthy_folds.append(meta_data_test_healthy_)\n",
    "        df_orders_test_healthy_folds.append(df_orders_test_healthy_)\n",
    "\n",
    "    # concat all pitting levels samples\n",
    "    df_orders_test_pitting = pd.concat(list(df_orders_test_pitting_dict.values()))\n",
    "    meta_data_test_pitting = pd.concat(list(meta_data_test_pitting_dict.values()))\n",
    "\n",
    "    # merge healthy and unheathy samples for each fold\n",
    "    df_orders_test_folds = []\n",
    "    meta_data_test_folds = []\n",
    "    for i, (df_orders_test_healthy_, meta_data_test_healthy_) in enumerate(zip(df_orders_test_healthy_folds, meta_data_test_healthy_folds)):\n",
    "        if RANDOM_SPLIT=='V3':\n",
    "            # only use operating modes in the test set that are also in the training set\n",
    "            om_test_healthy = meta_data_test_healthy_['rotational speed [RPM]'].astype(str) + '_' + meta_data_test_healthy_['torque [Nm]'].astype(str)\n",
    "            om_test_pitting = meta_data_test_pitting['rotational speed [RPM]'].astype(str) + '_' + meta_data_test_pitting['torque [Nm]'].astype(str)\n",
    "            new_meta_data_test_pitting_without_missing_oms = meta_data_test_pitting[om_test_pitting.isin(om_test_healthy)]\n",
    "            new_df_orders_test_pitting_without_missing_oms = df_orders_test_pitting[om_test_pitting.isin(om_test_healthy)]\n",
    "\n",
    "            # sample equal amount of samples from healthy and faulty data\n",
    "            om_test_pitting_with_run = new_meta_data_test_pitting_without_missing_oms['rotational speed [RPM]'].astype(str) + '_' + new_meta_data_test_pitting_without_missing_oms['torque [Nm]'].astype(str) + '_' + new_meta_data_test_pitting_without_missing_oms['sample_id'].astype(str)\n",
    "            om_test_healthy_with_run = meta_data_test_healthy_['rotational speed [RPM]'].astype(str) + '_' + meta_data_test_healthy_['torque [Nm]'].astype(str) + '_' + meta_data_test_healthy_['sample_id'].astype(str)\n",
    "            n_samples = len(om_test_healthy_with_run.unique())\n",
    "            samples = new_df_orders_test_pitting_without_missing_oms['unique_sample_id'].sample(n_samples, random_state=i, replace=False)\n",
    "            new_meta_data_test_pitting = new_meta_data_test_pitting_without_missing_oms[new_meta_data_test_pitting_without_missing_oms['unique_sample_id'].isin(samples)]\n",
    "            new_df_orders_test_pitting = new_df_orders_test_pitting_without_missing_oms[new_df_orders_test_pitting_without_missing_oms['unique_sample_id'].isin(samples)]\n",
    "            df_orders_test_folds.append(pd.concat([df_orders_test_healthy_, new_df_orders_test_pitting]).reset_index(drop=True))\n",
    "            meta_data_test_folds.append(pd.concat([meta_data_test_healthy_, new_meta_data_test_pitting]).reset_index(drop=True))\n",
    "        else:\n",
    "            df_orders_test_folds.append(pd.concat([df_orders_test_healthy_, df_orders_test_pitting]).reset_index(drop=True))\n",
    "            meta_data_test_folds.append(pd.concat([meta_data_test_healthy_, meta_data_test_pitting]).reset_index(drop=True))\n",
    "\n",
    "    if CACHE_RESULTS:\n",
    "        # cache train data\n",
    "        with open(fpath_df_orders_test_folds, 'wb') as file:\n",
    "            pickle.dump(df_orders_test_folds, file)\n",
    "        # cache test data\n",
    "        with open(fpath_meta_data_test_folds, 'wb') as file:\n",
    "            pickle.dump(meta_data_test_folds, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! healthy samples != faulty samples\n",
    "display(meta_data_test_folds[-1].unique_sample_id.str.contains('healthy').sum())\n",
    "display(meta_data_test_folds[-1].unique_sample_id.str.contains('pitting').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop # 216 unique ids are missing, why?  --> because of the healthy samples --> issue fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop # meta_data_test has different types of unique_sample_id: <1200_50_3> for pitting and <1200_100_3_healthy> for no pitting \n",
    "# --> previously no issue as there was only one level of pitting\n",
    "# fixed this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xxxxxx\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we extract the vibration fingerprint for each measurement (***later, maybe: and assign the operating mode based on the previously trained classifier.***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract train vibration measurement periods\n",
    "train_vibration_measurement_periods_folds = []\n",
    "for df_V_train_normalized_, meta_data_train_ in zip(df_V_train_normalized_folds, meta_data_train_folds):\n",
    "    df_ = df_V_train_normalized_\n",
    "    #meta_data_train['sample_id_unique'] = meta_data_train.groupby(['sample_id', 'rotational speed [RPM]', 'torque [Nm]']).ngroup() + 1\n",
    "    df_[['unique_sample_id', 'direction']] = meta_data_train_[['unique_sample_id', 'direction']]   # !!! wrong? \n",
    "    train_vibration_measurement_periods = []\n",
    "    for sample_id, group in df_.groupby('unique_sample_id'):\n",
    "        measurement_period = {\n",
    "            'start': 'unknown', \n",
    "            'stop': 'unknown',\n",
    "            'group': group,\n",
    "            'sample_id': sample_id,\n",
    "            #'rpm': group['rotational speed [RPM]'].unique()[0],\n",
    "            #'torque': group['torque [Nm]'].unique()[0],\n",
    "        }\n",
    "        train_vibration_measurement_periods.append(group)\n",
    "    train_vibration_measurement_periods_folds.append(train_vibration_measurement_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOES IT REALLY WORK?\n",
    "\n",
    "# extract test vibration measurement periods\n",
    "test_vibration_measurement_periods_folds = []\n",
    "test_vibration_measurement_periods_meta_data_folds = []\n",
    "for df_orders_test_, meta_data_test_, cluster_label_unique_name_mapping_ in tqdm(zip(df_orders_test_folds, meta_data_test_folds, cluster_label_unique_name_mapping_folds), \n",
    "                                                                                 total=len(df_orders_test_folds)):\n",
    "    df_V_test_normalized = normalize_1(df_orders_test_, BAND_COLS)\n",
    "    df_ = df_V_test_normalized\n",
    "    df_[['sample_id', 'unique_sample_id', 'direction']] = meta_data_test_[['sample_id', 'unique_sample_id', 'direction']]\n",
    "    test_vibration_measurement_periods_ = []\n",
    "    test_vibration_measurement_periods_meta_data_ = []\n",
    "    n_index_errors = 0\n",
    "    for unique_sample_id, group in df_.groupby('unique_sample_id'):\n",
    "        rpm = meta_data_test_[meta_data_test_['unique_sample_id'] == unique_sample_id]['rotational speed [RPM]'].unique()[0]\n",
    "        torque = meta_data_test_[meta_data_test_['unique_sample_id'] == unique_sample_id]['torque [Nm]'].unique()[0]\n",
    "        try:\n",
    "            om = cluster_label_unique_name_mapping_[\n",
    "                (cluster_label_unique_name_mapping_['rotational speed [RPM]'] == rpm) & \n",
    "                (cluster_label_unique_name_mapping_['torque [Nm]'] == torque)\n",
    "            ]['cluster_label_unique'].iloc[0]\n",
    "        except IndexError:\n",
    "            n_index_errors += 1\n",
    "            om = -1\n",
    "        measurement_period = {\n",
    "            'start': 'unknown', \n",
    "            'stop': 'unknown',\n",
    "            'group': group,\n",
    "            'unique_sample_id': unique_sample_id,\n",
    "            'rpm': rpm,\n",
    "            'torque': torque,\n",
    "            'unique_cluster_label': om\n",
    "        }\n",
    "        test_vibration_measurement_periods_.append(group)\n",
    "        test_vibration_measurement_periods_meta_data_.append(measurement_period)\n",
    "    test_vibration_measurement_periods_folds.append(test_vibration_measurement_periods_)\n",
    "    test_vibration_measurement_periods_meta_data_folds.append(test_vibration_measurement_periods_meta_data_)\n",
    "\n",
    "    n_total = len(test_vibration_measurement_periods_)\n",
    "    #print(f'Total number of measurement periods: {n_total}')\n",
    "    #print(f'Number of measurement periods with unknown RPM and/or torque: {n_index_errors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract df_W_offline and df_W_online\n",
    "def extract_vibration_weights_per_measurement_period(measurement_periods, col_names, band_cols, normalization, model, verbose=False):\n",
    "    Ws = []\n",
    "    for period in tqdm(measurement_periods, disable=not verbose, desc='Extracting vibration weights per measurement period'):\n",
    "        assert len(period) == 3, 'should have exactly 3 directions per measurement period'\n",
    "        band_column_names = period.columns[period.columns.str.contains('band_')]\n",
    "        V = period.set_index(['direction'])[band_column_names]  # already normalized\n",
    "        # dim(W) = 6 x 16\n",
    "        W = model.nmf.transform(V)\n",
    "        W = pd.DataFrame(W, columns=col_names)  # !!!\n",
    "        Ws.append({\n",
    "            # 'Sample_id': period.sample_id.unique()[0],\n",
    "            'unique_sample_id': period.unique_sample_id.unique()[0],  # !!!\n",
    "            'V_normalized': V,\n",
    "            'W': W\n",
    "        })\n",
    "    return pd.DataFrame(Ws)\n",
    "\n",
    "df_W_offline_folds = []\n",
    "df_W_online_folds = []\n",
    "for train_vibration_measurement_periods_, test_vibration_measurement_periods_, fingerprints_, model_ in tqdm(zip(train_vibration_measurement_periods_folds, \n",
    "                         test_vibration_measurement_periods_folds,\n",
    "                         fingerprints_folds,\n",
    "                         model_folds),\n",
    "                         total=len(fingerprints_folds)):\n",
    "    df_W_offline_ = extract_vibration_weights_per_measurement_period(train_vibration_measurement_periods_, fingerprints_[0].columns, BAND_COLS, normalize_1, model_)\n",
    "    df_W_online_ = extract_vibration_weights_per_measurement_period(test_vibration_measurement_periods_, fingerprints_[0].columns, BAND_COLS, normalize_1, model_)\n",
    "    df_W_offline_folds.append(df_W_offline_)\n",
    "    df_W_online_folds.append(df_W_online_)\n",
    "\n",
    "df_W_online_folds[fold].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old code before cross-validation\n",
    "# extract train vibration measurement periods\n",
    "\"\"\"\n",
    "df_ = df_V_train_normalized\n",
    "#meta_data_train['sample_id_unique'] = meta_data_train.groupby(['sample_id', 'rotational speed [RPM]', 'torque [Nm]']).ngroup() + 1\n",
    "df_[['unique_sample_id', 'direction']] = meta_data_train[['unique_sample_id', 'direction']]   # !!! wrong? \n",
    "train_vibration_measurement_periods = []\n",
    "for sample_id, group in df_.groupby('unique_sample_id'):\n",
    "    measurement_period = {\n",
    "        'start': 'unknown', \n",
    "        'stop': 'unknown',\n",
    "        'group': group,\n",
    "        'sample_id': sample_id,\n",
    "        #'rpm': group['rotational speed [RPM]'].unique()[0],\n",
    "        #'torque': group['torque [Nm]'].unique()[0],\n",
    "    }\n",
    "    train_vibration_measurement_periods.append(group)\n",
    "\n",
    "# extract test vibration measurement periods\n",
    "df_V_test_normalized = normalize_1(df_orders_test, BAND_COLS)\n",
    "df_ = df_V_test_normalized\n",
    "df_[['sample_id', 'unique_sample_id', 'direction']] = meta_data_test[['sample_id', 'unique_sample_id', 'direction']]\n",
    "test_vibration_measurement_periods = []\n",
    "test_vibration_measurement_periods_meta_data = []\n",
    "n_index_errors = 0\n",
    "for unique_sample_id, group in df_.groupby('unique_sample_id'):\n",
    "    rpm = meta_data_test[meta_data_test['unique_sample_id'] == unique_sample_id]['rotational speed [RPM]'].unique()[0]\n",
    "    torque = meta_data_test[meta_data_test['unique_sample_id'] == unique_sample_id]['torque [Nm]'].unique()[0]\n",
    "    try:\n",
    "        om = cluster_label_unique_name_mapping[\n",
    "            (cluster_label_unique_name_mapping['rotational speed [RPM]'] == rpm) & \n",
    "            (cluster_label_unique_name_mapping['torque [Nm]'] == torque)\n",
    "        ]['cluster_label_unique'].iloc[0]\n",
    "    except IndexError:\n",
    "        n_index_errors += 1\n",
    "        om = -1\n",
    "    measurement_period = {\n",
    "        'start': 'unknown', \n",
    "        'stop': 'unknown',\n",
    "        'group': group,\n",
    "        'unique_sample_id': unique_sample_id,\n",
    "        'rpm': rpm,\n",
    "        'torque': torque,\n",
    "        'unique_cluster_label': om\n",
    "    }\n",
    "    test_vibration_measurement_periods.append(group)\n",
    "    test_vibration_measurement_periods_meta_data.append(measurement_period)\n",
    "\n",
    "n_total = len(test_vibration_measurement_periods)\n",
    "print(f'Total number of measurement periods: {n_total}')\n",
    "print(f'Number of measurement periods with unknown RPM and/or torque: {n_index_errors}')\n",
    "\n",
    "# extract df_W_offline and df_W_online\n",
    "def extract_vibration_weights_per_measurement_period(measurement_periods, col_names, band_cols, normalization, model):\n",
    "    Ws = []\n",
    "    for period in tqdm(measurement_periods):\n",
    "        assert len(period) == 3, 'should have exactly 3 directions per measurement period'\n",
    "        band_column_names = period.columns[period.columns.str.contains('band_')]\n",
    "        V = period.set_index(['direction'])[band_column_names]  # already normalized\n",
    "        # dim(W) = 6 x 16\n",
    "        W = model.nmf.transform(V)\n",
    "        W = pd.DataFrame(W, columns=col_names)  # !!!\n",
    "        Ws.append({\n",
    "            # 'Sample_id': period.sample_id.unique()[0],\n",
    "            'unique_sample_id': period.unique_sample_id.unique()[0],  # !!!\n",
    "            'V_normalized': V,\n",
    "            'W': W\n",
    "        })\n",
    "    return pd.DataFrame(Ws)\n",
    "\n",
    "df_W_offline = extract_vibration_weights_per_measurement_period(train_vibration_measurement_periods, fingerprints[0].columns, BAND_COLS, normalize_1, model)\n",
    "df_W_online = extract_vibration_weights_per_measurement_period(test_vibration_measurement_periods, fingerprints[0].columns, BAND_COLS, normalize_1, model)\n",
    "df_W_online\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrate a derived weight matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 10\n",
    "df_W_online_ = df_W_online_folds[fold]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.heatmap(df_W_online_['W'][period], annot=True, fmt=\".6f\", ax=ax, cmap='Blues', vmin=0, vmax=0.05, cbar=False)\n",
    "ax.set_title(f'Derived weights for measurements period {period}');\n",
    "# set y tick labels to x, y and z\n",
    "ax.set_yticklabels(['x', 'y', 'z'], rotation=0);\n",
    "# set x  tick labels to component_0, component_1, etc.\n",
    "ax.set_xticklabels([f'frequency_component_{x}' for x in range(N_COMPONENTS)], rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we illustrate all measurement periods.\n",
    "We start with a U-MAP embedding of the vectorized measurement matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old code before cross-validation\n",
    "\"\"\"\n",
    "feature_space = pd.DataFrame(df_W_online['W'].apply(lambda df: df.stack().values).to_list())\n",
    "X_umap = UMAP(random_state=42).fit_transform(X=feature_space.to_numpy())\n",
    "df_umap = pd.DataFrame(data=X_umap, index=feature_space.index, columns=['umap_1', 'umap_2'])\n",
    "df_umap['unique_sample_id'] = df_W_online['unique_sample_id']\n",
    "df_info_ = pd.DataFrame(test_vibration_measurement_periods_meta_data)\n",
    "# plot unique cluster name\n",
    "# px.scatter(df_umap.reset_index(), x='umap_1', y='umap_2', color=df_info_['unique_cluster_label'].astype(str), hover_data=['index'], width=800, height=600)\n",
    "# plot rpm\n",
    "px.scatter(df_umap.reset_index(), x='umap_1', y='umap_2', color=df_info_['rpm'], hover_data=['index', 'unique_sample_id'], width=800, height=600)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance to fingerprints\n",
    "\n",
    "Calculate distances on test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `df_W_train` != `df_W_offline` --> make sure that this is not a bug in the industrial dataset!\n",
    "> `df_W_train` has only components per direction, should have components per measurement period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell takes around 60 minutes to run (!) --> going to cache the results\n",
    "SHOW_DISTANCES = False\n",
    "\n",
    "def calculate_distances_per_measurement_period(measurement_period, fingerprints, verbose=False):\n",
    "    # pointwise Mahalanobis distance\n",
    "    fingerprint_matrix = np.array([fingerprints[om].to_numpy().flatten() for om in fingerprints])\n",
    "    # calculate covariance matrix\n",
    "    fingerprint_S = np.cov(fingerprint_matrix.T)\n",
    "    # calculate inverse\n",
    "    fingerprint_SI = np.linalg.inv(fingerprint_S)\n",
    "    # calculate mu\n",
    "    fingerprint_mu = fingerprint_matrix.mean(axis=0)\n",
    "    df_dist_ = []\n",
    "    for idx, row in tqdm(measurement_period.iterrows(), total=len(measurement_period), disable=not verbose):\n",
    "        for om in fingerprints:\n",
    "            weights = row['W']\n",
    "            fingerprint = fingerprints[om]\n",
    "            tmp = {\n",
    "                'idx': idx,\n",
    "                'data': row, \n",
    "                'om': om, \n",
    "                'frobenius_norm': distance_metrics.frobenius_norm(weights, fingerprint),\n",
    "                'frobenius_norm_pow2': distance_metrics.frobenius_norm_v2(weights, fingerprint),\n",
    "                'frobenius_norm_sqrt': distance_metrics.frobenius_norm_v3(weights, fingerprint),\n",
    "                'cosine_distance': distance_metrics.cosine_distance(weights, fingerprint),\n",
    "                'manhattan_distance': distance_metrics.manhattan_distance(weights, fingerprint),\n",
    "            }\n",
    "            df_dist_.append(tmp)\n",
    "    df_dist_ = pd.DataFrame(df_dist_)\n",
    "    df_dist_['frobenius_norm_minmax'] = MinMaxScaler().fit_transform(df_dist_['frobenius_norm'].to_numpy().reshape(-1, 1))\n",
    "    return df_dist_\n",
    "\n",
    "\n",
    "df_dist_offline_folds = []\n",
    "df_dist_online_folds = []\n",
    "for i, (df_W_offline_, df_W_online_, fingerprints_) in tqdm(enumerate(zip(df_W_offline_folds,\n",
    "                                                                     df_W_online_folds,\n",
    "                                                                     fingerprints_folds)),\n",
    "                                                                     desc='Calculating distances per fold'):\n",
    "    fpath_offline = os.path.join(CACHING_FOLDER_NAME, 'distance_folds', f'df_dist_offline_fold_{i}.pkl')\n",
    "    fpath_online = os.path.join(CACHING_FOLDER_NAME, 'distance_folds', f'df_dist_online_fold_{i}.pkl')\n",
    "    if LOAD_CACHED_RESULTS:\n",
    "        df_dist_offline_folds.append(pickle.load(open(fpath_offline, 'rb')))\n",
    "        df_dist_online_folds.append(pickle.load(open(fpath_online, 'rb')))\n",
    "    else:\n",
    "        df_dist_offline_ = calculate_distances_per_measurement_period(df_W_offline_, fingerprints=fingerprints_)\n",
    "        if CACHE_RESULTS:\n",
    "            pickle.dump(df_dist_offline_, open(fpath_offline, 'wb'))\n",
    "        df_dist_online_ = calculate_distances_per_measurement_period(df_W_online_, fingerprints=fingerprints_)\n",
    "        if CACHE_RESULTS:\n",
    "            pickle.dump(df_dist_online_, open(fpath_online, 'wb'))\n",
    "        df_dist_offline_folds.append(df_dist_offline_)\n",
    "        df_dist_online_folds.append(df_dist_online_)\n",
    "\n",
    "if SHOW_DISTANCES:\n",
    "    g = sns.displot(data=df_dist_offline_folds[fold], \n",
    "                    x=\"cosine_distance\", col=\"om\", col_wrap=3, height=2, aspect=4, bins=20, kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observation: In contrast to industrial use case, the cosine distance is spread out for almost any operating mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection \n",
    "\n",
    "Because the measurements are not timestamped, it is not possible to order the measurements in time.\n",
    "Instead, we perform an anomaly detection. \n",
    "Per given operating mode, we check the distances of the derived weights to the fingerprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist_online_folds[fold].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each measurement period (row), get the distance to each operating mode (column)\n",
    "df_cosine_folds = []\n",
    "for df_dist_online_, test_vibration_measurement_periods_meta_data_ in zip(df_dist_online_folds, test_vibration_measurement_periods_meta_data_folds):\n",
    "    df_cosine_ = df_dist_online_[['idx', 'om', 'cosine_distance']].pivot(index='idx', columns='om', values='cosine_distance')\n",
    "    # assign the corresponding operating mode to the given row (if known), else, assign -1\n",
    "    # unique cluster label is wrong!!! (might be correct)\n",
    "    df_cosine_[['rpm', 'torque', 'unique_cluster_label']] = pd.DataFrame(test_vibration_measurement_periods_meta_data_)[['rpm', 'torque', 'unique_cluster_label']]\n",
    "    df_cosine_folds.append(df_cosine_)\n",
    "\n",
    "df_cosine_folds[fold].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already aw before, there are 658 measurements in the test set where the cluster label is known and 142 measurements where the cluster label is unknown. (later we will implent a classifier to predict the cluster label for all measurements. We will add it as additional column and check whether the classification is correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (df_cosine_, df_W_online_) in enumerate(zip(df_cosine_folds, df_W_online_folds)):\n",
    "    distance_to_own_cluster_center_ = []\n",
    "    for idx, row in df_cosine_.iterrows():\n",
    "        om = row['unique_cluster_label']\n",
    "        if om != -1:\n",
    "            distance_to_own_cluster_center_.append(row[om])\n",
    "        else:\n",
    "            distance_to_own_cluster_center_.append(np.nan)\n",
    "    df_cosine_['distance_to_own_cluster_center'] = distance_to_own_cluster_center_\n",
    "    df_cosine_['pitting'] = df_W_online_['unique_sample_id'].str.contains(f'pitting_level_')\n",
    "    df_cosine_['pitting_level'] = df_W_online_['unique_sample_id'].str.extract(r'pitting_level_(\\d)')\n",
    "    df_cosine_['pitting_level'] = df_cosine_['pitting_level'].fillna(0).astype(int)\n",
    "    df_cosine_folds[i] = df_cosine_\n",
    "\n",
    "df_cosine_folds[fold].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot distance to own cluster center vs. distance to other cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine_ = df_cosine_folds[fold]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(16, 8), ncols=2)\n",
    "\n",
    "ax = df_cosine_['distance_to_own_cluster_center'].plot(kind='hist', bins=20, ax=axes[0], alpha=0.5, legend=False)\n",
    "ax.set_title('Distance to own cluster centers')\n",
    "ax.set_xlabel('Cosine distance')\n",
    "\n",
    "# plot distance to other cluster centers\n",
    "ax = df_cosine_.drop(columns=['rpm', 'torque', 'unique_cluster_label', 'distance_to_own_cluster_center', 'pitting', 'pitting_level']).melt()['value'].plot(kind='hist', bins=20, ax=axes[1], alpha=0.5, legend=False)\n",
    "ax.set_title('Distance to other cluster centers')\n",
    "ax.set_xlabel('Cosine distance')\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: Set threshold based on distance in training set. If distance to own cluster center exceeds threshold, then anomaly.\n",
    "> - TODO: if OM unknonw, then anomaly --> drop unknown cluster labels\n",
    "> - TODO: anomaly detection per operating mode group, not per operating mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many anomalies when there is pitting\n",
    "# However, the cosine distance threshold is set manually to 0.01 (in a next step we need to set it based on the observed cosine distances in the training set)\n",
    "anomaly_ = df_cosine_['distance_to_own_cluster_center'] > 0.01   # TODO: setting threshold to 0.01 as first test, later set threshold based on distance in training set\n",
    "display(anomaly_.value_counts())\n",
    "ax = sns.boxplot(data=df_cosine_, y='distance_to_own_cluster_center', x='pitting_level')\n",
    "ax.set_title(f'Distance to own cluster center per pitting level (Fold {fold})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating ROC-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating single ROC-curve\n",
    "# --> now in util module\n",
    "\"\"\"\n",
    "def calculate_roc_characteristics(df_):\n",
    "    df_ = df_.sort_values(by='distance_to_own_cluster_center', ascending=True)\n",
    "\n",
    "    # Initialize variables to store ROC curve values\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for threshold in df_['distance_to_own_cluster_center']:\n",
    "        df_['predicted_anomaly'] = df_['distance_to_own_cluster_center'] >= threshold\n",
    "\n",
    "        # Calculate True Positive Rate (TPR) and False Positive Rate (FPR)\n",
    "        true_positives = df_[(df_['pitting'] == 1) & (df_['predicted_anomaly'] == 1)].shape[0]\n",
    "        false_positives = df_[(df_['pitting'] == 0) & (df_['predicted_anomaly'] == 1)].shape[0]\n",
    "        true_negatives = df_[(df_['pitting'] == 0) & (df_['predicted_anomaly'] == 0)].shape[0]\n",
    "        false_negatives = df_[(df_['pitting'] == 1) & (df_['predicted_anomaly'] == 0)].shape[0]\n",
    "\n",
    "        tpr.append(true_positives / (true_positives + false_negatives))\n",
    "        fpr.append(false_positives / (false_positives + true_negatives))\n",
    "\n",
    "    # Calculate the area under the ROC curve (AUC)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    return fpr, tpr, roc_auc\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# plot individual ROC curves\n",
    "linestyles = ['-', '--', ':', '-', '--', ':']\n",
    "for lvl, style in zip(pitting_levels, linestyles):\n",
    "    df_ = df_cosine[(~df_cosine['pitting']) | (df_cosine['pitting_level'] == lvl)]\n",
    "    fpr, tpr, roc_auc = calculate_roc_characteristics(df_)\n",
    "    ax.plot(fpr, tpr, lw=1, linestyle=style, alpha=0.66, label=f'level {lvl} (area = {roc_auc:.3f})')\n",
    "    ax.set_xlim(0.0, 1.0)\n",
    "    ax.set_ylim(0.0, 1.05)\n",
    "\n",
    "# Plot the general ROC curve\n",
    "fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine)\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'Receiver Operating Characteristic (ROC) Curve')\n",
    "\n",
    "ax.legend(loc='lower right', title='Pitting severity level');\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False \n",
    "\n",
    "if PLOT:\n",
    "    for fold in range(N):\n",
    "        # why does the individual ROC curve not go until FP = 1 (?)\n",
    "        df_cosine_ = df_cosine_folds[fold]\n",
    "        df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        # plot individual ROC curves\n",
    "        linestyles = ['-', '--', ':', '-', '--', ':']\n",
    "        for lvl, style in zip(pitting_levels, linestyles):\n",
    "            df_ = df_cosine_[(~df_cosine_['pitting']) | (df_cosine_['pitting_level'] == lvl)]\n",
    "            fpr, tpr, roc_auc = calculate_roc_characteristics(df_)\n",
    "            ax.plot(fpr, tpr, lw=1, linestyle=style, alpha=0.66, label=f'level {lvl} (area = {roc_auc:.3f})')\n",
    "            ax.set_xlim(0.0, 1.0)\n",
    "            ax.set_ylim(0.0, 1.05)\n",
    "\n",
    "        # Plot the general ROC curve\n",
    "        fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "        ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "        ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "        ax.set_xlim(0.0, 1.0)\n",
    "        ax.set_ylim(0.0, 1.05)\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title(f'ROC Curve (trial {fold})')\n",
    "        n_total = len(df_cosine_)\n",
    "        n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "        n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])\n",
    "        text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy)\"\n",
    "        ax.annotate(xy=(0.1, 0.025), text=text)\n",
    "        ax.legend(loc='lower right', title='Pitting severity level');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "threshold = 0.1\n",
    "\n",
    "# --> now in module\n",
    "\"\"\"\n",
    "def calc_tpr_at_fpr_threshold(tpr, fpr, threshold=0.1):\n",
    "    # sort tpr and fpr such that they are in ascending order\n",
    "    if (fpr[0] > fpr[-1]) or (tpr[0] > tpr[-1]):\n",
    "        assert(tpr[0] > tpr[-1] and fpr[0] > fpr[-1])\n",
    "        tpr = list(reversed(tpr))\n",
    "        fpr = list(reversed(fpr))\n",
    "    try:\n",
    "        idx = next(i for i, value in enumerate(fpr) if value > threshold)\n",
    "    except StopIteration:\n",
    "        idx = 0\n",
    "    tpr_at_fpr = tpr[idx]\n",
    "    return tpr_at_fpr\n",
    "\"\"\"\n",
    "\n",
    "# why does the individual ROC curve not go until FP = 1 (?)\n",
    "df_cosine_ = df_cosine_folds[fold]\n",
    "df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot the general ROC curve\n",
    "fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "tpr_at_fpr = calc_tpr_at_fpr_threshold(tpr, fpr, threshold=threshold)\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.plot([0, threshold], [tpr_at_fpr, tpr_at_fpr], color='red', lw=2, linestyle='--', label=f'TPR@FPR={threshold:.2f} = {tpr_at_fpr:.2f}')\n",
    "ax.plot([threshold, threshold], [0, tpr_at_fpr], color='red', lw=2, linestyle='--')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {fold})')\n",
    "n_total = len(df_cosine_)\n",
    "n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy)\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text)\n",
    "\n",
    "ax.legend(loc='lower right', title='Pitting severity level');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> now in module\n",
    "\"\"\"\n",
    "def calc_fpr_at_tpr_threshold(tpr, fpr, threshold=0.1):\n",
    "    return calc_tpr_at_fpr_threshold(tpr=fpr, fpr=tpr, threshold=threshold)\n",
    "\"\"\"\n",
    "\n",
    "fold = 0\n",
    "df_cosine_ = df_cosine_folds[fold]\n",
    "df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "threshold = 0.90\n",
    "\n",
    "# Plot the general ROC curve\n",
    "fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=threshold)\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.plot([fpr_at_tpr, fpr_at_tpr], [0, threshold], color='green', lw=2, linestyle='--', label=f'FPR@TPR={threshold:.2f} = {fpr_at_tpr:.2f}')\n",
    "ax.plot([0, fpr_at_tpr], [threshold, threshold], color='green', lw=2, linestyle='--')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {fold})')\n",
    "n_total = len(df_cosine_)\n",
    "n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy)\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text)\n",
    "\n",
    "ax.legend(loc='lower right', title='Pitting severity level');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = list(range(N))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "threshold = 0.90\n",
    "\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "#text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy)\"\n",
    "#ax.annotate(xy=(0.1, 0.025), text=text)\n",
    "#ax.legend(loc='lower right', title='Pitting severity level');\n",
    "\n",
    "for fold in tqdm(trials):\n",
    "    df_cosine_ = df_cosine_folds[fold]\n",
    "    df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "\n",
    "    # Plot the general ROC curve\n",
    "    fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "    fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=threshold)\n",
    "    ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.05)\n",
    "    ax.plot([fpr_at_tpr, fpr_at_tpr], [0, threshold], color='green', lw=2, linestyle='--', label=f'FPR@TPR={threshold:.2f} = {fpr_at_tpr:.2f}', alpha=0.05)\n",
    "    ax.plot([0, fpr_at_tpr], [threshold, threshold], color='green', lw=2, linestyle='--', alpha=0.05)\n",
    "    #ax.set_xlim(0.0, 1.0)\n",
    "    ax.set_xlim(-0.01, 0.5)\n",
    "    #ax.set_ylim(0.0, 1.05)\n",
    "    ax.set_ylim(0.5, 1.01)\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'ROC Curve (all trials)')\n",
    "    n_total = len(df_cosine_)\n",
    "    n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "    n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "threshold = 0.90\n",
    "\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "#text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy)\"\n",
    "#ax.annotate(xy=(0.1, 0.025), text=text)\n",
    "#ax.legend(loc='lower right', title='Pitting severity level');\n",
    "\n",
    "for fold in tqdm(trials):\n",
    "    df_cosine_ = df_cosine_folds[fold]\n",
    "    df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "\n",
    "    # Plot the general ROC curve\n",
    "    fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "    fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=threshold)\n",
    "    ax.plot(fpr, tpr, color=None, lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.2)\n",
    "    ax.plot([fpr_at_tpr, fpr_at_tpr], [0, threshold], color='green', lw=2, linestyle='--', label=f'FPR@TPR={threshold:.2f} = {fpr_at_tpr:.2f}', alpha=0.2)\n",
    "    ax.plot([0, fpr_at_tpr], [threshold, threshold], color='green', lw=2, linestyle='--', alpha=0.2)\n",
    "    ax.set_xlim(-0.025, 1.0)\n",
    "    #ax.set_xlim(-0.01, 0.5)\n",
    "    ax.set_ylim(0.0, 1.025)\n",
    "    #ax.set_ylim(0.5, 1.01)\n",
    "    ax.set_xlabel('False Positive Rate [FPR]')\n",
    "    ax.set_ylabel('True Positive Rate [TPR]')\n",
    "    ax.set_title(f'ROC Curves')\n",
    "    n_total = len(df_cosine_)\n",
    "    n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "    n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "trials = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 20]\n",
    "zoom = {'x': (-0.01, 0.2), 'y': (0.8, 1.01)}\n",
    "cmap = plt.get_cmap('tab20').colors\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(7, 3), ncols=2)\n",
    "threshold = 0.90\n",
    "\n",
    "#text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy)\"\n",
    "#ax.annotate(xy=(0.1, 0.025), text=text)\n",
    "#ax.legend(loc='lower right', title='Pitting severity level');\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "rect = patches.Rectangle((zoom['x'][0], zoom['y'][0]), zoom['x'][1], zoom['y'][1], linewidth=5, edgecolor='r', facecolor='none', label='zoomed area')\n",
    "ax.add_patch(rect)\n",
    "for i, fold in enumerate(tqdm(trials)):\n",
    "    df_cosine_ = df_cosine_folds[fold]\n",
    "    df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "\n",
    "    # Plot the general ROC curve\n",
    "    fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "    fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=threshold)\n",
    "    label=f'trial {fold}'\n",
    "    ax.plot(fpr, tpr, color=cmap[i], lw=4, label=label, alpha=0.2)\n",
    "    #label=f'FPR@TPR={threshold:.2f} = {fpr_at_tpr:.2f}'\n",
    "    ax.plot([fpr_at_tpr, fpr_at_tpr], [0, threshold], color=cmap[i], lw=2, linestyle='dotted', alpha=0.2)\n",
    "    ax.plot([0, fpr_at_tpr], [threshold, threshold], color=cmap[i], lw=2, linestyle='dotted', alpha=0.2)\n",
    "    ax.set_xlim(-0.05, 1.0)\n",
    "    #ax.set_xlim(-0.01, 0.5)\n",
    "    ax.set_ylim(0.0, 1.05)\n",
    "    #ax.set_ylim(0.5, 1.01)\n",
    "    ax.set_xlabel('False Positive Rate [FPR]')\n",
    "    ax.set_ylabel('True Positive Rate [TPR]')\n",
    "    ax.set_title(f'ROC Curves')\n",
    "    n_total = len(df_cosine_)\n",
    "    n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "    n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])\n",
    "    # create rectangle for zoomed in plot\n",
    "\n",
    "ax = axes[1]\n",
    "# ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "for i, fold in enumerate(tqdm(trials)):\n",
    "    df_cosine_ = df_cosine_folds[fold]\n",
    "    df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "\n",
    "    # Plot the general ROC curve\n",
    "    fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "    fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=threshold)\n",
    "    ax.plot(fpr, tpr, color=cmap[i], lw=4, label=None, alpha=0.25)\n",
    "    ax.plot([fpr_at_tpr, fpr_at_tpr], [0, threshold], color=cmap[i], lw=2, linestyle='dotted', label=None, alpha=0.25)\n",
    "    ax.plot([0, fpr_at_tpr], [threshold, threshold], color=cmap[i], lw=2, linestyle='dotted', alpha=0.25)\n",
    "    ax.set_xlim(zoom['x'])\n",
    "    ax.set_ylim(zoom['y'])\n",
    "    ax.set_xlabel('False Positive Rate [FPR]')\n",
    "    ax.set_ylabel('True Positive Rate [TPR]')\n",
    "    ax.set_title(f'ROC Curves (zoomed in)')\n",
    "    n_total = len(df_cosine_)\n",
    "    n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "    n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])\n",
    "\n",
    "fig.legend(ncol=6, fontsize=9.5, loc='lower center', bbox_to_anchor=(0.5, -0.15))\n",
    "fig.tight_layout()\n",
    "#fig.savefig(os.path.join('figs', 'roc_curves.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Isolation Forest\n",
    "\n",
    "Isolation Forests are a machine learning anomaly detection algorithm that works by isolating instances in a dataset. Developed based on the concept of randomly partitioning data points, the algorithm identifies anomalies by measuring the ease with which a data point can be separated from the rest of the dataset, making it particularly effective for detecting outliers in large and complex datasets.\n",
    "\n",
    "- Need to set **contamination** (expected amount of outliers in the dataset) to 0, as there are no anomalies in the training set.\n",
    "- Has scoring function\n",
    "\n",
    "Variables:\n",
    "- $X = V$\n",
    "- train_vibration_measurement_periods_folds = $X_{train}$\n",
    "\n",
    "Preliminary results: \n",
    "- Low performance (AUC $\\approx$ 0.6)\n",
    "- Reducing feature space (with PCA) barerly improces performance\n",
    "\n",
    "Notes: \n",
    "- More extensive hyperparameter tuning?\n",
    "- Unfair comparison, as process parameters are not taken into account. Train model per operating mode? --> issue with feature space size\n",
    "- Train per sensor instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "exemplary_fold = 0\n",
    "binned_vibrations_train = train_vibration_measurement_periods_folds[exemplary_fold]\n",
    "binned_vibrations_test = test_vibration_measurement_periods_folds[exemplary_fold]\n",
    "df_cosine_test = df_cosine_folds[exemplary_fold]\n",
    "\n",
    "#clf = IsolationForest(contamination=0)\n",
    "#clf.fit(X)\n",
    "#y_pred_train = clf.predict(X) \n",
    "\n",
    "# frequency band columns are all columns that contain the string 'band_'\n",
    "# --> there are 50 frequency bands per sensor\n",
    "exemplary_vibration_column_names = binned_vibrations_train[0].columns\n",
    "frequency_band_column_names = exemplary_vibration_column_names[exemplary_vibration_column_names.str.contains('band_')]\n",
    "\n",
    "# create a matrix representation of the feature space for the train set,\n",
    "# where the three different sensors are stacked to a single vector with 150 features\n",
    "# (50 frequency bands per sensor)\n",
    "# --> this is the feature space for the clustering algorithm\n",
    "flatten_df = lambda df_: df_.to_numpy().flatten()\n",
    "X_train = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_train])\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "\n",
    "# Fit Isolation Forest (without preprocessing the data)\n",
    "clf = IsolationForest(contamination=0)\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(f'Number of outliers detected in training set: {np.sum(y_pred_train == -1)} (should be 0)')\n",
    "\n",
    "# create a matrix representation for the test set\n",
    "X_test = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_test])\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "\n",
    "# predict outliers in test set\n",
    "y_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_score_test = clf.score_samples(X_test)  # the lower, the more abnormal\n",
    "print(f'Number of outliers detected in test set with default parameters: {np.sum(y_pred_test == -1)} (should be {np.sum(y_test == -1)})')\n",
    "\n",
    "# create ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'AUC: {roc_auc:.3f}')\n",
    "\n",
    "# plot ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {exemplary_fold})')\n",
    "n_total = len(df_cosine_test)\n",
    "n_healthy = len(df_cosine_test[df_cosine_test['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_test[df_cosine_test['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy), AUC={round(roc_auc, 3)}\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text);\n",
    "fig.suptitle(f'Isolation Forest', color='blue', size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single trial (+ PCA)\n",
    "\n",
    "--> Feature size not an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "exemplary_fold = 4\n",
    "binned_vibrations_train = train_vibration_measurement_periods_folds[exemplary_fold]\n",
    "binned_vibrations_test = test_vibration_measurement_periods_folds[exemplary_fold]\n",
    "df_cosine_test = df_cosine_folds[exemplary_fold]\n",
    "\n",
    "#clf = IsolationForest(contamination=0)\n",
    "#clf.fit(X)\n",
    "#y_pred_train = clf.predict(X) \n",
    "\n",
    "# frequency band columns are all columns that contain the string 'band_'\n",
    "# --> there are 50 frequency bands per sensor\n",
    "exemplary_vibration_column_names = binned_vibrations_train[0].columns\n",
    "frequency_band_column_names = exemplary_vibration_column_names[exemplary_vibration_column_names.str.contains('band_')]\n",
    "\n",
    "# create a matrix representation of the feature space for the train set,\n",
    "# where the three different sensors are stacked to a single vector with 150 features\n",
    "# (50 frequency bands per sensor)\n",
    "# --> this is the feature space for the clustering algorithm\n",
    "flatten_df = lambda df_: df_.to_numpy().flatten()\n",
    "X_train = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_train])\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "\n",
    "# Fit Isolation Forest (without preprocessing the data)\n",
    "clf = Pipeline([('pca', PCA(n_components=10)), ('clf', IsolationForest(contamination=0))])\n",
    "clf = clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(f'Number of outliers detected in training set: {np.sum(y_pred_train == -1)} (should be 0)')\n",
    "\n",
    "# create a matrix representation for the test set\n",
    "X_test = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_test])\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "\n",
    "# predict outliers in test set\n",
    "y_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_score_test = clf.score_samples(X_test)  # the lower, the more abnormal\n",
    "print(f'Number of outliers detected in test set with default parameters: {np.sum(y_pred_test == -1)} (should be {np.sum(y_test == -1)})')\n",
    "\n",
    "# create ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'AUC: {roc_auc:.3f}')\n",
    "\n",
    "# plot ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {exemplary_fold})')\n",
    "n_total = len(df_cosine_test)\n",
    "n_healthy = len(df_cosine_test[df_cosine_test['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_test[df_cosine_test['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy), AUC={round(roc_auc, 3)}\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text);\n",
    "fig.suptitle(f'Isolation Forest + PCA (n_components=10)', color='blue', size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single trial on NMF weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "exemplary_fold = 4\n",
    "W_train = df_W_offline_folds[exemplary_fold]['W']\n",
    "W_test = df_W_online_folds[exemplary_fold]['W']\n",
    "df_cosine_test = df_cosine_folds[exemplary_fold]\n",
    "\n",
    "#clf = IsolationForest(contamination=0)\n",
    "#clf.fit(X)\n",
    "#y_pred_train = clf.predict(X) \n",
    "\n",
    "# create a matrix representation of the feature space for the train set,\n",
    "# where the three different sensors are stacked to a single vector with 150 features\n",
    "# (50 frequency bands per sensor)\n",
    "# --> this is the feature space for the clustering algorithm\n",
    "flatten_df = lambda df_: df_.to_numpy().flatten()\n",
    "X_train = np.array([flatten_df(individual_measurements) for individual_measurements in W_train])\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "\n",
    "# Fit Isolation Forest (without preprocessing the data)\n",
    "clf = IsolationForest(contamination=0)\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(f'Number of outliers detected in training set: {np.sum(y_pred_train == -1)} (should be 0)')\n",
    "\n",
    "# create a matrix representation for the test set\n",
    "X_test = np.array([flatten_df(individual_measurements) for individual_measurements in W_test])\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "\n",
    "# predict outliers in test set\n",
    "y_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_score_test = clf.score_samples(X_test)  # the lower, the more abnormal\n",
    "print(f'Number of outliers detected in test set with default parameters: {np.sum(y_pred_test == -1)} (should be {np.sum(y_test == -1)})')\n",
    "\n",
    "# create ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'AUC: {roc_auc:.3f}')\n",
    "\n",
    "# plot ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {exemplary_fold})')\n",
    "n_total = len(df_cosine_test)\n",
    "n_healthy = len(df_cosine_test[df_cosine_test['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_test[df_cosine_test['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy), AUC={round(roc_auc, 3)}\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text);\n",
    "fig.suptitle(f'Isolation Forest + NMF', color='blue', size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest on Vibration + Process Parameters (speed, torque)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO: WHY DF_COSINE_FOLDS HAS NOT THE SAME DIMENSIONALITY AS DF_W_FOLDS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "exemplary_fold = 4\n",
    "W_train = df_W_offline_folds[exemplary_fold]['W']\n",
    "meta_data_train = pd.DataFrame({\n",
    "    'rpm': df_W_offline_folds[exemplary_fold]['unique_sample_id'].str.extract(r'^(\\d+)_')[0],\n",
    "    'torque': df_W_offline_folds[exemplary_fold]['unique_sample_id'].str.extract(r'_(\\d+)_')[0],\n",
    "})\n",
    "W_test = df_W_online_folds[exemplary_fold]['W']\n",
    "df_cosine_test = df_cosine_folds[exemplary_fold]\n",
    "meta_data_test = pd.DataFrame({\n",
    "    'rpm': df_W_online_folds[exemplary_fold]['unique_sample_id'].str.extract(r'^(\\d+)_')[0],\n",
    "    'torque': df_W_online_folds[exemplary_fold]['unique_sample_id'].str.extract(r'_(\\d+)_')[0],\n",
    "})\n",
    "\n",
    "#clf = IsolationForest(contamination=0)\n",
    "#clf.fit(X)\n",
    "#y_pred_train = clf.predict(X) \n",
    "\n",
    "# create a matrix representation of the feature space for the train set,\n",
    "# where the three different sensors are stacked to a single vector with 150 features\n",
    "# (50 frequency bands per sensor)\n",
    "# --> this is the feature space for the clustering algorithm\n",
    "flatten_df = lambda df_: df_.to_numpy().flatten()\n",
    "X_train = np.array([flatten_df(individual_measurements) for individual_measurements in W_train])\n",
    "X_train = np.hstack((X_train, meta_data_train.to_numpy()))\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "\n",
    "# Fit Isolation Forest (without preprocessing the data)\n",
    "clf = IsolationForest(contamination=0)\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(f'Number of outliers detected in training set: {np.sum(y_pred_train == -1)} (should be 0)')\n",
    "\n",
    "# create a matrix representation for the test set\n",
    "X_test = np.array([flatten_df(individual_measurements) for individual_measurements in W_test])\n",
    "X_test = np.hstack((X_test, meta_data_test.to_numpy()))\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "\n",
    "# predict outliers in test set\n",
    "y_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_score_test = clf.score_samples(X_test)  # the lower, the more abnormal\n",
    "print(f'Number of outliers detected in test set with default parameters: {np.sum(y_pred_test == -1)} (should be {np.sum(y_test == -1)})')\n",
    "\n",
    "# create ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'AUC: {roc_auc:.3f}')\n",
    "\n",
    "# plot ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {exemplary_fold})')\n",
    "n_total = len(df_cosine_test)\n",
    "n_healthy = len(df_cosine_test[df_cosine_test['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_test[df_cosine_test['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy), AUC={round(roc_auc, 3)}\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text);\n",
    "fig.suptitle(f'Isolation Forest + NMF + MetaData', color='blue', size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: 1-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "exemplary_fold = 1\n",
    "binned_vibrations_train = train_vibration_measurement_periods_folds[exemplary_fold]\n",
    "binned_vibrations_test = test_vibration_measurement_periods_folds[exemplary_fold]\n",
    "df_cosine_test = df_cosine_folds[exemplary_fold]\n",
    "\n",
    "#clf = IsolationForest(contamination=0)\n",
    "#clf.fit(X)\n",
    "#y_pred_train = clf.predict(X) \n",
    "\n",
    "# frequency band columns are all columns that contain the string 'band_'\n",
    "# --> there are 50 frequency bands per sensor\n",
    "exemplary_vibration_column_names = binned_vibrations_train[0].columns\n",
    "frequency_band_column_names = exemplary_vibration_column_names[exemplary_vibration_column_names.str.contains('band_')]\n",
    "\n",
    "# create a matrix representation of the feature space for the train set,\n",
    "# where the three different sensors are stacked to a single vector with 150 features\n",
    "# (50 frequency bands per sensor)\n",
    "# --> this is the feature space for the clustering algorithm\n",
    "flatten_df = lambda df_: df_.to_numpy().flatten()\n",
    "X_train = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_train])\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "\n",
    "# Fit Isolation Forest (without preprocessing the data)\n",
    "clf = OneClassSVM(kernel='linear', gamma='auto')\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(f'Number of outliers detected in training set: {np.sum(y_pred_train == -1)} (should be 0)')\n",
    "\n",
    "# create a matrix representation for the test set\n",
    "X_test = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_test])\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "\n",
    "# predict outliers in test set\n",
    "y_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_score_test = clf.score_samples(X_test)  # the lower, the more abnormal\n",
    "print(f'Number of outliers detected in test set with default parameters: {np.sum(y_pred_test == -1)} (should be {np.sum(y_test == -1)})')\n",
    "\n",
    "# create ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'AUC: {roc_auc:.3f}')\n",
    "\n",
    "# plot ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {exemplary_fold})')\n",
    "n_total = len(df_cosine_test)\n",
    "n_healthy = len(df_cosine_test[df_cosine_test['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_test[df_cosine_test['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy), AUC={round(roc_auc, 3)}\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text);\n",
    "fig.suptitle(f'1-class SVM', color='blue', size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplary_fold = 1\n",
    "binned_vibrations_train = train_vibration_measurement_periods_folds[exemplary_fold]\n",
    "binned_vibrations_test = test_vibration_measurement_periods_folds[exemplary_fold]\n",
    "df_cosine_test = df_cosine_folds[exemplary_fold]\n",
    "\n",
    "#clf = IsolationForest(contamination=0)\n",
    "#clf.fit(X)\n",
    "#y_pred_train = clf.predict(X) \n",
    "\n",
    "# frequency band columns are all columns that contain the string 'band_'\n",
    "# --> there are 50 frequency bands per sensor\n",
    "exemplary_vibration_column_names = binned_vibrations_train[0].columns\n",
    "frequency_band_column_names = exemplary_vibration_column_names[exemplary_vibration_column_names.str.contains('band_')]\n",
    "\n",
    "# create a matrix representation of the feature space for the train set,\n",
    "# where the three different sensors are stacked to a single vector with 150 features\n",
    "# (50 frequency bands per sensor)\n",
    "# --> this is the feature space for the clustering algorithm\n",
    "flatten_df = lambda df_: df_.to_numpy().flatten()\n",
    "X_train = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_train])\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "\n",
    "# Fit Isolation Forest (without preprocessing the data)\n",
    "clf = Pipeline([('pca', PCA(n_components=0.9)), ('clf', OneClassSVM(kernel='rbf', gamma='auto'))])\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(f'Number of outliers detected in training set: {np.sum(y_pred_train == -1)} (should be 0)')\n",
    "\n",
    "# create a matrix representation for the test set\n",
    "X_test = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_test])\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "\n",
    "# predict outliers in test set\n",
    "y_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_score_test = clf.score_samples(X_test)  # the lower, the more abnormal\n",
    "print(f'Number of outliers detected in test set with default parameters: {np.sum(y_pred_test == -1)} (should be {np.sum(y_test == -1)})')\n",
    "\n",
    "# create ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'AUC: {roc_auc:.3f}')\n",
    "\n",
    "# plot ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {exemplary_fold})')\n",
    "n_total = len(df_cosine_test)\n",
    "n_healthy = len(df_cosine_test[df_cosine_test['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_test[df_cosine_test['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy), AUC={round(roc_auc, 3)}\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text);\n",
    "fig.suptitle(f'1-class SVM + PCA', color='blue', size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot U-Map embedding of X_train\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "umap = UMAP(n_neighbors=5, min_dist=0.3, metric='cosine', random_state=42)\n",
    "X_train_umap = umap.fit_transform(X_train)\n",
    "ax.scatter(X_train_umap[:, 0], X_train_umap[:, 1], c=y_pred_train, cmap='coolwarm', s=1)\n",
    "ax.set_title('U-Map embedding of X_train');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# plot U-Map embedding of X_train\n",
    "umap = UMAP(n_neighbors=5, min_dist=0.3, metric='cosine', random_state=42)\n",
    "X_train_umap = umap.fit_transform(X_train)\n",
    "\n",
    "# plot U-Map embedding of X_train\n",
    "fig = px.scatter(x=X_train_umap[:, 0], y=X_train_umap[:, 1], color=None, width=800, height=600)\n",
    "fig.update_layout(title='U-Map embedding of X_train')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# plot U-Map embedding of X_train\n",
    "umap = UMAP(n_neighbors=5, min_dist=0.3, metric='cosine', random_state=42)\n",
    "X_test_umap = umap.fit_transform(X_test)\n",
    "\n",
    "# plot U-Map embedding of X_train\n",
    "fig = px.scatter(x=X_test_umap[:, 0], y=X_test_umap[:, 1], color=df_cosine_test['unique_cluster_label'].astype(str), width=800, height=600)\n",
    "fig.update_layout(title='U-Map embedding of X_test')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "accuracy = np.sum(y_pred_test == y_test) / len(y_test)\n",
    "print(f'Accuracy: {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "exemplary_fold = 0\n",
    "W_train = df_W_offline_folds[exemplary_fold]['W']\n",
    "W_test = df_W_online_folds[exemplary_fold]['W']\n",
    "df_cosine_test = df_cosine_folds[exemplary_fold]\n",
    "\n",
    "#clf = IsolationForest(contamination=0)\n",
    "#clf.fit(X)\n",
    "#y_pred_train = clf.predict(X) \n",
    "\n",
    "# create a matrix representation of the feature space for the train set,\n",
    "# where the three different sensors are stacked to a single vector with 150 features\n",
    "# (50 frequency bands per sensor)\n",
    "# --> this is the feature space for the clustering algorithm\n",
    "flatten_df = lambda df_: df_.to_numpy().flatten()\n",
    "X_train = np.array([flatten_df(individual_measurements) for individual_measurements in W_train])\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "\n",
    "# Fit Isolation Forest (without preprocessing the data)\n",
    "clf = OneClassSVM(kernel='rbf', gamma='auto')\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(f'Number of outliers detected in training set: {np.sum(y_pred_train == -1)} (should be 0)')\n",
    "\n",
    "# create a matrix representation for the test set\n",
    "X_test = np.array([flatten_df(individual_measurements) for individual_measurements in W_test])\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "\n",
    "# predict outliers in test set\n",
    "y_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_score_test = clf.score_samples(X_test)  # the lower, the more abnormal\n",
    "print(f'Number of outliers detected in test set with default parameters: {np.sum(y_pred_test == -1)} (should be {np.sum(y_test == -1)})')\n",
    "\n",
    "# create ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'AUC: {roc_auc:.3f}')\n",
    "\n",
    "# plot ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {exemplary_fold})')\n",
    "n_total = len(df_cosine_test)\n",
    "n_healthy = len(df_cosine_test[df_cosine_test['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_test[df_cosine_test['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy), AUC={round(roc_auc, 3)}\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text);\n",
    "fig.suptitle(f'1-class SVM + NMF', color='blue', size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "exemplary_fold = 4\n",
    "W_train = df_W_offline_folds[exemplary_fold]['W']\n",
    "meta_data_train = pd.DataFrame({\n",
    "    'rpm': df_W_offline_folds[exemplary_fold]['unique_sample_id'].str.extract(r'^(\\d+)_')[0],\n",
    "    'torque': df_W_offline_folds[exemplary_fold]['unique_sample_id'].str.extract(r'_(\\d+)_')[0],\n",
    "})\n",
    "W_test = df_W_online_folds[exemplary_fold]['W']\n",
    "df_cosine_test = df_cosine_folds[exemplary_fold]\n",
    "meta_data_test = pd.DataFrame({\n",
    "    'rpm': df_W_online_folds[exemplary_fold]['unique_sample_id'].str.extract(r'^(\\d+)_')[0],\n",
    "    'torque': df_W_online_folds[exemplary_fold]['unique_sample_id'].str.extract(r'_(\\d+)_')[0],\n",
    "})\n",
    "\n",
    "#clf = IsolationForest(contamination=0)\n",
    "#clf.fit(X)\n",
    "#y_pred_train = clf.predict(X) \n",
    "\n",
    "# create a matrix representation of the feature space for the train set,\n",
    "# where the three different sensors are stacked to a single vector with 150 features\n",
    "# (50 frequency bands per sensor)\n",
    "# --> this is the feature space for the clustering algorithm\n",
    "flatten_df = lambda df_: df_.to_numpy().flatten()\n",
    "X_train = np.array([flatten_df(individual_measurements) for individual_measurements in W_train])\n",
    "X_train = np.hstack((X_train, meta_data_train.to_numpy()))\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "\n",
    "# Fit Isolation Forest (without preprocessing the data)\n",
    "clf = OneClassSVM(kernel='linear', gamma='auto')\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(f'Number of outliers detected in training set: {np.sum(y_pred_train == -1)} (should be 0)')\n",
    "\n",
    "# create a matrix representation for the test set\n",
    "X_test = np.array([flatten_df(individual_measurements) for individual_measurements in W_test])\n",
    "X_test = np.hstack((X_test, meta_data_test.to_numpy()))\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "\n",
    "# predict outliers in test set\n",
    "y_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_score_test = clf.score_samples(X_test)  # the lower, the more abnormal\n",
    "print(f'Number of outliers detected in test set with default parameters: {np.sum(y_pred_test == -1)} (should be {np.sum(y_test == -1)})')\n",
    "\n",
    "# create ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'AUC: {roc_auc:.3f}')\n",
    "\n",
    "# plot ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {exemplary_fold})')\n",
    "n_total = len(df_cosine_test)\n",
    "n_healthy = len(df_cosine_test[df_cosine_test['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_test[df_cosine_test['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy), AUC={round(roc_auc, 3)}\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text);\n",
    "fig.suptitle(f'Isolation Forest + NMF + MetaData', color='blue', size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Reconstruction error for NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Reconstruction error based on PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplary_fold = 0\n",
    "explained_variance_ratio = 0.999\n",
    "binned_vibrations_train = train_vibration_measurement_periods_folds[exemplary_fold]\n",
    "binned_vibrations_test = test_vibration_measurement_periods_folds[exemplary_fold]\n",
    "df_cosine_test = df_cosine_folds[exemplary_fold]\n",
    "\n",
    "# frequency band columns are all columns that contain the string 'band_'\n",
    "# --> there are 50 frequency bands per sensor\n",
    "exemplary_vibration_column_names = binned_vibrations_train[0].columns\n",
    "frequency_band_column_names = exemplary_vibration_column_names[exemplary_vibration_column_names.str.contains('band_')]\n",
    "\n",
    "# create a matrix representation of the feature space for the train set,\n",
    "# where the three different sensors are stacked to a single vector with 150 features\n",
    "# (50 frequency bands per sensor)\n",
    "# --> this is the feature space for the clustering algorithm\n",
    "flatten_df = lambda df_: df_.to_numpy().flatten()\n",
    "X_train = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_train])\n",
    "print(f'Shape of X_train: {X_train.shape}')\n",
    "\n",
    "# Fit Isolation Forest (without preprocessing the data)\n",
    "clf = PCA(n_components=explained_variance_ratio)\n",
    "X_train_reconstructed = clf.fit_transform(X_train)\n",
    "reconstrucion_error_train = np.sum((X_train - clf.inverse_transform(X_train_reconstructed))**2, axis=1)\n",
    "print(f'Reconstruction error train')\n",
    "print(pd.Series(reconstrucion_error_train).describe())\n",
    "\n",
    "# create a matrix representation for the test set\n",
    "X_test = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_test])\n",
    "print(f'Shape of X_test: {X_test.shape}')\n",
    "\n",
    "# predict outliers in test set\n",
    "y_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "X_test_reconstructed = clf.transform(X_test)\n",
    "reconstrucion_error_test = np.sum((X_test - clf.inverse_transform(X_test_reconstructed))**2, axis=1)\n",
    "y_score_test = max(reconstrucion_error_test) - reconstrucion_error_test  # the higher, the more abnormal\n",
    "print(f'Reconstruction error test')\n",
    "print(pd.Series(reconstrucion_error_test).describe())\n",
    "\n",
    "# create ROC curve for test set\n",
    "fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'AUC: {roc_auc:.3f}')\n",
    "\n",
    "# plot ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, color='blue', lw=4, label=f'overall (area = {roc_auc:.3f})', alpha=0.66)\n",
    "ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title(f'ROC Curve (trial {exemplary_fold})')\n",
    "n_total = len(df_cosine_test)\n",
    "n_healthy = len(df_cosine_test[df_cosine_test['pitting'] == False])\n",
    "n_unhealthy = len(df_cosine_test[df_cosine_test['pitting'] == True])\n",
    "text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy), AUC={round(roc_auc, 3)}\"\n",
    "ax.annotate(xy=(0.1, 0.025), text=text);\n",
    "fig.suptitle(f'PCA ({100*explained_variance_ratio}% explained variance)', color='blue', size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: KNN anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare multiple trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conscious_engie_icare.supervised_benchmarking import Benchmarking\n",
    "\n",
    "CALCULATE = False\n",
    "\n",
    "if CALCULATE:\n",
    "    benchmarking = Benchmarking(\n",
    "        train_vibration_measurement_periods_folds=train_vibration_measurement_periods_folds,\n",
    "        test_vibration_measurement_periods_folds=test_vibration_measurement_periods_folds,\n",
    "        df_cosine_folds=df_cosine_folds,\n",
    "        df_W_offline_folds=df_W_offline_folds,\n",
    "        df_W_online_folds=df_W_online_folds,\n",
    "    )\n",
    "    df_roc_curves = benchmarking.run_all_approaches()\n",
    "    df_roc_curves.to_pickle('df_roc_curves.pkl')\n",
    "else:\n",
    "    df_roc_curves = pd.read_pickle('df_roc_curves.pkl')\n",
    "df_roc_curves.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roc_curves['approach'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roc_curves['approach (renamed)'] = df_roc_curves['approach'].replace({\n",
    "    'Isolation Forest+ PCA+ Meta Data': 'IForest+ PCA+ Meta Data',\n",
    "    'IForest+ Meta Data': 'IForest+ Meta',\n",
    "    'Isolation Forest+ PCA+ Meta Data': 'IForest+ PCA+ Meta',\n",
    "    'IForest+ Hyperparameter tuning': 'IForest+ Hyperparam',\n",
    "    '1cSVM+ Hyperparameter tuning': '1cSVM+ Hyperparam',\n",
    "    '1cSVM+ Meta Data': '1cSVM+ Meta',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.boxplot(x='approach (renamed)', y='roc_auc', data=df_roc_curves, ax=ax);\n",
    "# ax.set_title('ROC AUC');\n",
    "# before each '+' in each tick label, create a new line for the label\n",
    "ax.set_xticklabels([label.get_text().replace('+', '\\n+') for label in ax.get_xticklabels()])\n",
    "# rotate x-axis labels\n",
    "#for tick in ax.get_xticklabels():\n",
    "#    tick.set_rotation(10)\n",
    "# ax.set_title('Performance comparison (100 trials)', size=18);\n",
    "# make the last tick red\n",
    "ax.get_xticklabels()[-1].set_color('red');\n",
    "ax.set_ylabel('ROC AUC', size=14);\n",
    "ax.set_xlabel(None);\n",
    "# 90 degree rotation of x-axis labels\n",
    "plt.xticks(rotation=45);\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join('figs', 'performance_comparison.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roc_curves_test_pca = benchmarking.run_test()\n",
    "display(df_roc_curves_test_pca.head())\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "sns.boxplot(x='approach', y='roc_auc', data=df_roc_curves_test_pca, ax=ax);\n",
    "# ax.set_title('ROC AUC');\n",
    "# before each '+' in each tick label, create a new line for the label\n",
    "ax.set_xticklabels([label.get_text().replace('+', '\\n+') for label in ax.get_xticklabels()])\n",
    "# rotate x-axis labels\n",
    "#for tick in ax.get_xticklabels():\n",
    "#    tick.set_rotation(10)\n",
    "ax.set_title('TEST RUN NEW PCA: Performance comparison (100 trials)', size=18);\n",
    "# make the last tick red\n",
    "ax.get_xticklabels()[-1].set_color('red');\n",
    "ax.set_ylabel('ROC AUC', size=14);\n",
    "ax.set_xlabel('Approach', size=14);\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_roc_curves_test_pca[df_roc_curves_test_pca['approach'] == 'PCA + Crossvalidation']\n",
    "df_ = pd.DataFrame(df_.cv_results.tolist())\n",
    "# all split0_test_scores the same?\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['split0_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roc_curves_test_pca['approach'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_roc_curves_test_pca[df_roc_curves_test_pca['approach'] == '1cSVM+ Crossvalidation']\n",
    "df_ = pd.DataFrame(df_.cv_results.tolist())\n",
    "# all split0_test_scores the same?\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "\n",
    "def train_isolation_forest(fold_nr, **kwargs):\n",
    "    pipeline = IsolationForest(contamination=0)\n",
    "    return train_standard_anomaly_detection(fold_nr, pipeline=pipeline, **kwargs)\n",
    "\n",
    "def train_isolation_forest_with_crossvalidation(fold_nr, **kwargs):\n",
    "    pipeline = IsolationForest()\n",
    "    param_grid = {\n",
    "        'n_estimators' : [10, 100, 200, 500], \n",
    "        'max_samples' : [0.1, 0.5, 1.0, 'auto'], \n",
    "        'max_features': [0.1, 0.5, 1.0, 10, 100]\n",
    "    }\n",
    "    return train_standard_anomaly_detection_with_crossvalidation(fold_nr, pipeline=pipeline, param_grid=param_grid, **kwargs)\n",
    "\n",
    "def train_isolation_forest_with_metadata(fold_nr, verbose=False):\n",
    "    return train_isolation_forest(fold_nr, verbose=verbose, use_meta_data=True)\n",
    "\n",
    "def train_isolation_forest_with_pca(fold_nr, **kwargs):\n",
    "    pipeline = Pipeline([('pca', PCA(n_components=0.999)), ('clf', IsolationForest(contamination=0))])\n",
    "    return train_standard_anomaly_detection(fold_nr, pipeline=pipeline, **kwargs)\n",
    "\n",
    "def train_isolation_forest_with_pca_and_metadata(fold_nr, verbose=False):\n",
    "    return train_isolation_forest_with_pca(fold_nr, verbose=verbose, use_meta_data=True)\n",
    "\n",
    "def train_one_class_svm(fold_nr, **kwargs):\n",
    "    pipeline = OneClassSVM(kernel='rbf', gamma='auto')\n",
    "    return train_standard_anomaly_detection(fold_nr, pipeline=pipeline, **kwargs)\n",
    "\n",
    "def train_one_class_svm_with_crossvalidation(fold_nr, **kwargs):\n",
    "    pipeline = OneClassSVM()\n",
    "    param_grid = {\n",
    "        'kernel' : ['linear', 'poly', 'rbf'], \n",
    "        'gamma' : [0.0001, 0.001, 0.01, 0.1, 1, 'scale', 'auto'], \n",
    "        'nu': [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    }\n",
    "    return train_standard_anomaly_detection_with_crossvalidation(fold_nr, pipeline=pipeline, param_grid=param_grid, **kwargs)\n",
    "\n",
    "def train_one_class_svm_with_metadata(fold_nr, verbose=False):\n",
    "    return train_one_class_svm(fold_nr, verbose=verbose, use_meta_data=True)\n",
    "\n",
    "def train_one_class_svm_with_pca(fold_nr, **kwargs):\n",
    "    pipeline = Pipeline([('pca', PCA(n_components=0.999)), ('clf', OneClassSVM(kernel='linear', gamma='auto'))])\n",
    "    return train_standard_anomaly_detection(fold_nr, pipeline=pipeline, **kwargs)\n",
    "\n",
    "def train_standard_anomaly_detection(fold_nr, pipeline, use_meta_data=False, verbose=False):\n",
    "    binned_vibrations_train = train_vibration_measurement_periods_folds[fold_nr]\n",
    "    binned_vibrations_test = test_vibration_measurement_periods_folds[fold_nr]\n",
    "    df_cosine_test = df_cosine_folds[fold_nr]\n",
    "\n",
    "    # frequency band columns are all columns that contain the string 'band_'\n",
    "    # --> there are 50 frequency bands per sensor\n",
    "    exemplary_vibration_column_names = binned_vibrations_train[0].columns\n",
    "    frequency_band_column_names = exemplary_vibration_column_names[exemplary_vibration_column_names.str.contains('band_')]\n",
    "\n",
    "    # create a matrix representation of the feature space for the train set,\n",
    "    # where the three different sensors are stacked to a single vector with 150 features\n",
    "    # (50 frequency bands per sensor)\n",
    "    # --> this is the feature space for the clustering algorithm\n",
    "    X_train = create_matrix_representation_train_set(binned_vibrations_train, fold_nr, frequency_band_column_names,\n",
    "                                                     use_meta_data=use_meta_data, verbose=verbose)\n",
    "\n",
    "    # Fit Pipeline (without preprocessing the data)\n",
    "    pipeline.fit(X_train)\n",
    "    y_pred_train = pipeline.predict(X_train)\n",
    "    if verbose:\n",
    "        print(f'Number of outliers detected in training set: {np.sum(y_pred_train == -1)} (should be 0)')\n",
    "\n",
    "    # create a matrix representation for the test set\n",
    "    X_test = create_matrix_representation_test_set(binned_vibrations_test, fold_nr, frequency_band_column_names, \n",
    "                                                   use_meta_data=use_meta_data, verbose=verbose)\n",
    "\n",
    "    # predict outliers in test set\n",
    "    y_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "    y_pred_test = pipeline.predict(X_test)\n",
    "    y_score_test = pipeline.score_samples(X_test)  # the lower, the more abnormal\n",
    "    if verbose:\n",
    "        print(f'Number of outliers detected in test set with default parameters: {np.sum(y_pred_test == -1)} (should be {np.sum(y_test == -1)})')\n",
    "\n",
    "    # create ROC curve for test set\n",
    "    results = calc_metrics_(y_test, y_score_test, verbose=verbose)\n",
    "    return results\n",
    "\n",
    "def train_standard_anomaly_detection_with_crossvalidation(fold_nr, pipeline, param_grid, validation_ratio=0.2, use_meta_data=False, verbose=False):\n",
    "    # TODO: crossvalidation does not work with roc_auc\n",
    "    binned_vibrations_train = train_vibration_measurement_periods_folds[fold_nr]\n",
    "    binned_vibrations_test = test_vibration_measurement_periods_folds[fold_nr]\n",
    "    df_cosine_test = df_cosine_folds[fold_nr]\n",
    "\n",
    "    # frequency band columns are all columns that contain the string 'band_'\n",
    "    # --> there are 50 frequency bands per sensor\n",
    "    exemplary_vibration_column_names = binned_vibrations_train[0].columns\n",
    "    frequency_band_column_names = exemplary_vibration_column_names[exemplary_vibration_column_names.str.contains('band_')]\n",
    "\n",
    "    # create a matrix representation of the feature space for the train set,\n",
    "    # where the three different sensors are stacked to a single vector with 150 features\n",
    "    # (50 frequency bands per sensor)\n",
    "    # --> this is the feature space for the clustering algorithm\n",
    "    X_train = create_matrix_representation_train_set(binned_vibrations_train, fold_nr, frequency_band_column_names,\n",
    "                                                     use_meta_data=use_meta_data, verbose=verbose)\n",
    "\n",
    "    # create a matrix representation for the validation/test set\n",
    "    X_val_test = create_matrix_representation_test_set(binned_vibrations_test, fold_nr, frequency_band_column_names, \n",
    "                                                       use_meta_data=use_meta_data, verbose=verbose)\n",
    "    X_val = X_val_test[:int(validation_ratio * len(X_val_test))]\n",
    "    X_test = X_val_test[int(validation_ratio * len(X_val_test)):]\n",
    "    y_val_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "    y_val = y_val_test[:int(validation_ratio * len(y_val_test))]\n",
    "    y_test = y_val_test[int(validation_ratio * len(y_val_test)):]\n",
    "\n",
    "    # Gridsearch\n",
    "    X_train_val = np.vstack((X_train, X_val))\n",
    "    y_train_val = np.concatenate((np.ones(len(X_train)), y_val)).astype(int)\n",
    "    assert len(X_train_val) == len(y_train_val)\n",
    "    #train_ind = list(range(len(X_train)))\n",
    "    #val_ind = list(range(len(X_train), len(X_train_val)))\n",
    "    train_ind = np.ones(len(X_train), dtype=int) * -1\n",
    "    val_ind = np.zeros(len(X_val), dtype=int)\n",
    "    assert len(train_ind) + len(val_ind) == len(X_train_val)\n",
    "    ind = np.concatenate((train_ind, val_ind))\n",
    "    assert len(ind) == len(X_train_val)\n",
    "    predefined_split = PredefinedSplit(test_fold=ind)\n",
    "    assert predefined_split.get_n_splits() == 1\n",
    "    # debugging code for scoring = 'roc_auc' (which did not work, but making a custom scorer did work)\n",
    "    #split_ = next(predefined_split.split())\n",
    "    #print(f'train set in predefined_split should only contain non-anomalous data: {split_}')\n",
    "    #X_train_ = X_train_val[split_[0]]\n",
    "    #X_val_ = X_train_val[split_[1]]\n",
    "    #y_train_ = y_train_val[split_[0]]\n",
    "    #y_val_ = y_train_val[split_[1]]\n",
    "    #print(\"y_train_:\", y_train_)\n",
    "    #print(\"y_val_:\", y_val_)\n",
    "    #pipeline_ = pipeline\n",
    "    #pipeline_.fit(X_train_val, y=y_train_val)\n",
    "    #y_pred_train_ = pipeline_.predict(X_train_)\n",
    "    #y_pred_val_ = pipeline_.predict(X_val_)\n",
    "    #roc_auc_train_ = roc_auc_score(y_train_, y_pred_train_)\n",
    "    #print(\"roc_auc_train_:\", roc_auc_train_)\n",
    "    #roc_auc_val_ = roc_auc_score(y_val_, y_pred_val_)\n",
    "    #print(\"roc_auc_val_:\", roc_auc_val_)\n",
    "    # assert True, 'validation set in predefined_split should contain anomalous and non-anomalous data'\n",
    "    roc_auc_scorer = make_scorer(roc_auc_score)\n",
    "    grid_search_clf = GridSearchCV(pipeline, param_grid=param_grid, cv=predefined_split, scoring=roc_auc_scorer, error_score=\"raise\")\n",
    "    grid_search_clf.fit(X_train_val, y=y_train_val)\n",
    "    cv_results = {'cv_results': grid_search_clf.cv_results_}\n",
    "\n",
    "    # Fit pipeline (without preprocessing the data)\n",
    "    y_pred_train = grid_search_clf.predict(X_train)\n",
    "    if verbose:\n",
    "        print(f'Number of outliers detected in training set: {np.sum(y_pred_train == -1)} (should be 0)')\n",
    "\n",
    "    # predict outliers in test set\n",
    "    y_pred_test = grid_search_clf.predict(X_test)\n",
    "    y_score_test = grid_search_clf.score_samples(X_test)  # the lower, the more abnormal\n",
    "    if verbose:\n",
    "        print(f'Number of outliers detected in test set with default parameters: {np.sum(y_pred_test == -1)} (should be {np.sum(y_test == -1)})')\n",
    "\n",
    "    # create ROC curve for test set\n",
    "    results = calc_metrics_(y_test, y_score_test, verbose=verbose)\n",
    "    results.update(cv_results)\n",
    "    return results\n",
    "\n",
    "def train_reconstruction_error_based_approach(fold_nr, pipeline, use_meta_data=False, verbose=False):\n",
    "    binned_vibrations_train = train_vibration_measurement_periods_folds[fold_nr]\n",
    "    binned_vibrations_test = test_vibration_measurement_periods_folds[fold_nr]\n",
    "    df_cosine_test = df_cosine_folds[fold_nr]\n",
    "\n",
    "    # frequency band columns are all columns that contain the string 'band_'\n",
    "    # --> there are 50 frequency bands per sensor\n",
    "    exemplary_vibration_column_names = binned_vibrations_train[0].columns\n",
    "    frequency_band_column_names = exemplary_vibration_column_names[exemplary_vibration_column_names.str.contains('band_')]\n",
    "\n",
    "    # create a matrix representation of the feature space for the train set,\n",
    "    # where the three different sensors are stacked to a single vector with 150 features\n",
    "    # (50 frequency bands per sensor)\n",
    "    # --> this is the feature space for the clustering algorithm\n",
    "    X_train = create_matrix_representation_train_set(binned_vibrations_train, fold_nr, frequency_band_column_names,\n",
    "                                                     use_meta_data=use_meta_data, verbose=verbose)\n",
    "\n",
    "    # Fit Isolation Forest (without preprocessing the data)\n",
    "    X_train_reconstructed = pipeline.fit_transform(X_train)\n",
    "    reconstrucion_error_train = np.sum((X_train - pipeline.inverse_transform(X_train_reconstructed))**2, axis=1)\n",
    "    if verbose:\n",
    "        print(f'Reconstruction error train')\n",
    "        print(pd.Series(reconstrucion_error_train).describe())\n",
    "\n",
    "    # create a matrix representation for the test set\n",
    "    X_test = create_matrix_representation_test_set(binned_vibrations_test, fold_nr, frequency_band_column_names, \n",
    "                                                   use_meta_data=use_meta_data, verbose=verbose)\n",
    "\n",
    "    # predict outliers in test set\n",
    "    y_test = df_cosine_test['pitting'].replace({True: -1, False: 1}).to_numpy()\n",
    "    X_test_reconstructed = pipeline.transform(X_test)\n",
    "    reconstrucion_error_test = np.sum((X_test - pipeline.inverse_transform(X_test_reconstructed))**2, axis=1)\n",
    "    y_score_test = max(reconstrucion_error_test) - reconstrucion_error_test  # the higher, the more abnormal\n",
    "    if verbose:\n",
    "        print(f'Reconstruction error test')\n",
    "        print(pd.Series(reconstrucion_error_test).describe())\n",
    "\n",
    "    # create ROC curve for test set\n",
    "    results = calc_metrics_(y_test, y_score_test, verbose=verbose)\n",
    "    return results\n",
    "\n",
    "def train_reconstruction_error_based_approach_with_crossvalidation(fold_nr, pipeline, param_grid, validation_ratio=0.2, use_meta_data=False, verbose=False):\n",
    "    pass\n",
    "\n",
    "def train_pca_old(fold_nr, use_meta_data=False, verbose=False):\n",
    "    pipeline = PCA(n_components=0.999)\n",
    "    return train_reconstruction_error_based_approach(fold_nr, pipeline, use_meta_data=use_meta_data, verbose=verbose)\n",
    "\n",
    "def train_pca_new(fold_nr, use_meta_data=False, verbose=False):\n",
    "    pipeline = PCA_ANOMALY_DETECTOR(n_components=0.999)\n",
    "    return train_standard_anomaly_detection(fold_nr, pipeline=pipeline, **kwargs)\n",
    "\n",
    "def flatten_df(df_):\n",
    "    return df_.to_numpy().flatten()\n",
    "\n",
    "def create_matrix_representation_train_set(binned_vibrations_train, fold_nr, frequency_band_column_names, use_meta_data=False, verbose=False):\n",
    "    X_train = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_train])\n",
    "    if use_meta_data:\n",
    "        meta_data_train = pd.DataFrame({\n",
    "            'rpm': df_W_offline_folds[fold_nr]['unique_sample_id'].str.extract(r'^(\\d+)_')[0],\n",
    "            'torque': df_W_offline_folds[fold_nr]['unique_sample_id'].str.extract(r'_(\\d+)_')[0],\n",
    "        })\n",
    "        X_train = np.hstack((X_train, meta_data_train.to_numpy()))\n",
    "    if verbose:\n",
    "        print(f'Shape of X_train: {X_train.shape}')\n",
    "    return X_train\n",
    "\n",
    "def create_matrix_representation_test_set(binned_vibrations_test, fold_nr, frequency_band_column_names, use_meta_data=False, verbose=False):\n",
    "    X_test = np.array([flatten_df(individual_measurements[frequency_band_column_names]) for individual_measurements in binned_vibrations_test])\n",
    "    if use_meta_data:\n",
    "        meta_data_test = pd.DataFrame({\n",
    "            'rpm': df_W_online_folds[fold_nr]['unique_sample_id'].str.extract(r'^(\\d+)_')[0],\n",
    "            'torque': df_W_online_folds[fold_nr]['unique_sample_id'].str.extract(r'_(\\d+)_')[0],\n",
    "        })\n",
    "        X_test = np.hstack((X_test, meta_data_test.to_numpy()))\n",
    "    if verbose:\n",
    "        print(f'Shape of X_test: {X_test.shape}')\n",
    "    return X_test\n",
    "\n",
    "def calc_metrics_(y_test, y_score_test, verbose=False):\n",
    "    # create ROC curve for test set\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_score_test)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=0.9)\n",
    "    if verbose:\n",
    "        print(f'AUC: {roc_auc:.3f}')\n",
    "\n",
    "    results = {\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'fpr_at_tpr': fpr_at_tpr,\n",
    "        'thresholds': thresholds,\n",
    "        'roc_auc': roc_auc,\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def get_results_of_our_method(fold_nr):\n",
    "    df_cosine_ = df_cosine_folds[fold_nr]\n",
    "    df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "\n",
    "    # Plot the general ROC curve\n",
    "    fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "    fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=0.9)\n",
    "    results = {\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'fpr_at_tpr': fpr_at_tpr,\n",
    "        'thresholds': thresholds,\n",
    "        'roc_auc': roc_auc,\n",
    "    }\n",
    "    return results\n",
    "    \n",
    "\n",
    "approaches = [\n",
    "    {'name': 'IForest', 'function': train_isolation_forest},\n",
    "    {'name': 'IForest+ Meta Data', 'function': train_isolation_forest_with_metadata},\n",
    "    {'name': 'IForest+ PCA', 'function': train_isolation_forest_with_pca},\n",
    "    {'name': 'Isolation Forest+ PCA+ Meta Data', 'function': train_isolation_forest_with_pca_and_metadata},\n",
    "    {'name': 'IForest+ Crossvalidation', 'function': train_isolation_forest_with_crossvalidation},\n",
    "    {'name': '1cSVM', 'function': train_one_class_svm},\n",
    "    {'name': '1cSVM+ Crossvalidation', 'function': train_one_class_svm_with_crossvalidation},\n",
    "    {'name': '1cSVM+ Meta Data', 'function': train_one_class_svm_with_metadata},\n",
    "    {'name': '1cSVM+ PCA', 'function': train_one_class_svm_with_pca},\n",
    "    # {'name': '1-class SVM+ PCA+ Meta Data', 'function': train_one_class_svm_with_pca_and_metadata},   # interrupts the kernel\n",
    "    {'name': 'PCA', 'function': train_pca},\n",
    "    {'name': 'Our method', 'function': get_results_of_our_method}\n",
    "]\n",
    "\n",
    "trials = []\n",
    "for approach in approaches:\n",
    "    for trial in tqdm(list(range(N)), desc=f'Approach: {approach[\"name\"]}'):\n",
    "        # calculate results\n",
    "        results = approach['function'](trial)\n",
    "        # add meta info\n",
    "        results = dict({'trial': trial, 'approach': approach['name']}, **results)\n",
    "        trials.append(results)\n",
    "df_roc_curves = pd.DataFrame(trials)\n",
    "df_roc_curves.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump as pickle\n",
    "#with open('df_roc_curves.pkl', 'wb') as f:\n",
    "#    pickle.dump(df_roc_curves, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_roc_curves[df_roc_curves.approach == '1cSVM+ Crossvalidation']\n",
    "df_.cv_results.iloc[10].keys()\n",
    "df_.cv_results.iloc[10]['split0_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_roc_curves[df_roc_curves.approach == '1cSVM+ Crossvalidation']\n",
    "df_.cv_results.iloc[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.cv_results.iloc[0]['split0_test_score'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.cv_results.iloc[0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.cv_results.iloc[0]['rank_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrate results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "sns.boxplot(x='approach', y='roc_auc', data=df_roc_curves, ax=ax);\n",
    "# ax.set_title('ROC AUC');\n",
    "# before each '+' in each tick label, create a new line for the label\n",
    "ax.set_xticklabels([label.get_text().replace('+', '\\n+') for label in ax.get_xticklabels()])\n",
    "# rotate x-axis labels\n",
    "#for tick in ax.get_xticklabels():\n",
    "#    tick.set_rotation(10)\n",
    "ax.set_title('Performance comparison (100 trials)', size=18);\n",
    "# make the last tick red\n",
    "ax.get_xticklabels()[-1].set_color('red');\n",
    "ax.set_ylabel('ROC AUC', size=14);\n",
    "ax.set_xlabel('Approach', size=14);\n",
    "fig.tight_layout()\n",
    "fig.savefig('performance_comparison_on_supervised_test_setup.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.boxplot(x='approach', y='roc_auc', data=df_roc_curves, ax=ax);\n",
    "# ax.set_title('ROC AUC');\n",
    "# before each '+' in each tick label, create a new line for the label\n",
    "ax.set_xticklabels([label.get_text().replace('+', '\\n+') for label in ax.get_xticklabels()])\n",
    "# rotate x-axis labels\n",
    "#for tick in ax.get_xticklabels():\n",
    "#    tick.set_rotation(10)\n",
    "ax.set_title('Performance comparison (100 trials)', size=18);\n",
    "# make the last tick red\n",
    "ax.get_xticklabels()[-1].set_color('red');\n",
    "ax.set_ylabel('ROC AUC', size=14);\n",
    "ax.set_xlabel('Approach', size=14);\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join('figs', 'performance_comparison_on_supervised_test_setup.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.boxplot(x='approach', y='fpr_at_tpr', data=df_roc_curves, ax=ax);\n",
    "# ax.set_title('ROC AUC');\n",
    "# before each '+' in each tick label, create a new line for the label\n",
    "ax.set_xticklabels([label.get_text().replace('+', '\\n+') for label in ax.get_xticklabels()])\n",
    "# rotate x-axis labels\n",
    "#for tick in ax.get_xticklabels():\n",
    "#    tick.set_rotation(10)\n",
    "ax.set_title('Performance comparison (100 trials)', size=18);\n",
    "# make the last tick red\n",
    "ax.get_xticklabels()[-1].set_color('red');\n",
    "ax.set_ylabel('FPR@TPR=0.9', size=14);\n",
    "ax.set_xlabel('Approach', size=14);\n",
    "fig.tight_layout()\n",
    "# fig.savefig('performance_comparison_on_supervised_test_setup.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig, axes = plt.subplots(figsize=(6, 4), ncols=2)\n",
    "\n",
    "# left subfigure (ROC AUC)\n",
    "sns.boxplot(x='approach', y='fpr_at_tpr', data=df_roc_curves, ax=ax);\n",
    "# ax.set_title('ROC AUC');\n",
    "# before each '+' in each tick label, create a new line for the label\n",
    "ax.set_xticklabels([label.get_text().replace('+', '\\n+') for label in ax.get_xticklabels()])\n",
    "# rotate x-axis labels\n",
    "#for tick in ax.get_xticklabels():\n",
    "#    tick.set_rotation(10)\n",
    "ax.set_title('Performance comparison (100 trials)', size=18);\n",
    "# make the last tick red\n",
    "ax.get_xticklabels()[-1].set_color('red');\n",
    "ax.set_ylabel('FPR@TPR=0.9', size=14);\n",
    "ax.set_xlabel('Approach', size=14);\n",
    "\n",
    "# right subfigure ()\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig('performance_comparison_on_supervised_test_setup.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.boxplot(x='approach', y='roc_auc', data=df_roc_curves, ax=ax);\n",
    "ax.set_title('ROC AUC');\n",
    "# before each '+' in each tick label, create a new line for the label\n",
    "ax.set_xticklabels([label.get_text().replace('+', '\\n+') for label in ax.get_xticklabels()])\n",
    "# rotate x-axis labels\n",
    "#for tick in ax.get_xticklabels():\n",
    "#    tick.set_rotation(10)\n",
    "fig.suptitle('Performance comparison on supervised test setup', color='blue', size=16);\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.boxplot(x='approach', y='roc_auc', data=df_roc_curves, ax=ax);\n",
    "ax.set_title('ROC AUC');\n",
    "# before each '+' in each tick label, create a new line for the label\n",
    "ax.set_xticklabels([label.get_text().replace('+', '\\n+') for label in ax.get_xticklabels()])\n",
    "# rotate x-axis labels\n",
    "#for tick in ax.get_xticklabels():\n",
    "#    tick.set_rotation(10)\n",
    "fig.suptitle('Performance comparison on supervised test setup', color='blue', size=16);\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze samples without labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_set, f = load_data(fnames, nperseg=nperseg,\n",
    "\n",
    "_no_labels = data_validation_set + data_test_set\n",
    "del data_validation_set\n",
    "data_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import sys\n",
    "\n",
    "# Create a function to get the size of all variables\n",
    "def get_size_of_all_variables():\n",
    "    variable_sizes = [(var, sys.getsizeof(globals()[var]) / (1024 * 1024)) for var in tqdm(globals())]\n",
    "    total_size_mb = sum(size for _, size in variable_sizes)\n",
    "    return total_size_mb, variable_sizes\n",
    "\n",
    "# Call the function and print the results\n",
    "total_size, variable_sizes = get_size_of_all_variables()\n",
    "print(f\"Total size of all variables: {total_size:.2f} MB\")\n",
    "\n",
    "# Print the sizes of individual variables\n",
    "for var, size in variable_sizes:\n",
    "    print(f\"{var}: {size:.2f} MB\")\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract vibration data\n",
    "df_vib_test_no_labels = derive_df_vib(data_no_labels, f)\n",
    "\n",
    "# convert to orders and derive meta data\n",
    "df_orders_no_labels, meta_data_no_labels = derive_df_orders(df_vib_test_no_labels, setup, f, verbose=False)\n",
    "\"\"\"\n",
    "if USE_TRAINING_SET_FOR_VALIDATION:\n",
    "    print('transforming sample-id in test set')\n",
    "    # meta_data_test_pitting_8['test_sample_id'] = meta_data_test_pitting_8.groupby(['rotational speed [RPM]', 'torque [Nm]', 'sample_id']).ngroup() + 1   # !!! might not be necessary\n",
    "    rpm = meta_data_test_pitting_['rotational speed [RPM]']\n",
    "    torque = meta_data_test_pitting_['torque [Nm]']\n",
    "    run = meta_data_test_pitting_['sample_id']\n",
    "    meta_data_test_pitting_['unique_sample_id'] = rpm.astype(str) + '_' + torque.astype(str) + '_' + run.astype(str) + f'_pitting_level_{lvl}'\n",
    "\"\"\"\n",
    "\n",
    "df_orders_no_labels['unique_sample_id'] = meta_data_no_labels['unique_sample_id'] # + f'_pitting_level_{lvl}'\n",
    "\n",
    "#df_orders_test_pitting_dict[lvl] = df_orders_test_pitting_\n",
    "#meta_data_test_pitting_dict[lvl] = meta_data_test_pitting_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprints_ = fingerprints_folds[0]  # there is only one fold\n",
    "cluster_label_unique_name_mapping = cluster_label_unique_name_mapping_folds[0]\n",
    "\n",
    "# normalize data\n",
    "print('normalizing data')\n",
    "df_V_no_labels_normalized = normalize_1(df_orders_no_labels, BAND_COLS)\n",
    "\n",
    "# extract vibration measurement periods\n",
    "print('extracting vibration measurement periods')\n",
    "df_ = df_V_no_labels_normalized\n",
    "#meta_data_train['sample_id_unique'] = meta_data_train.groupby(['sample_id', 'rotational speed [RPM]', 'torque [Nm]']).ngroup() + 1\n",
    "df_[['unique_sample_id', 'direction']] = meta_data_no_labels[['unique_sample_id', 'direction']]   # !!! wrong? \n",
    "no_labels_vibration_measurement_periods_ = []\n",
    "no_labels_vibration_measurement_periods_meta_data_ = []\n",
    "for sample_id, group in df_.groupby('unique_sample_id'):\n",
    "    # TODO: there are duplicate names between validation and test set!\n",
    "    # for the moment we exclude those samples (since it only concerns 5 measurement periods)\n",
    "    #  --> fix this later if time left\n",
    "    # assert len(group) == 3, f'should have exactly 3 directions per measurement period, had {len(group)} instead for sample_id {sample_id}'\n",
    "    rpm = meta_data_no_labels[meta_data_no_labels['unique_sample_id'] == sample_id]['rotational speed [RPM]'].unique()[0]\n",
    "    torque = meta_data_no_labels[meta_data_no_labels['unique_sample_id'] == sample_id]['torque [Nm]'].unique()[0]\n",
    "    try:\n",
    "        om = cluster_label_unique_name_mapping_[\n",
    "            (cluster_label_unique_name_mapping_['rotational speed [RPM]'] == rpm) & \n",
    "            (cluster_label_unique_name_mapping_['torque [Nm]'] == torque)\n",
    "        ]['cluster_label_unique'].iloc[0]\n",
    "    except IndexError:\n",
    "        n_index_errors += 1\n",
    "        om = -1\n",
    "    if len(group) == 3:\n",
    "        # append measurement period\n",
    "        measurement_period = {\n",
    "            'start': 'unknown',\n",
    "            'stop': 'unknown',\n",
    "            'group': group,\n",
    "            'sample_id': sample_id,\n",
    "            'rpm': rpm,\n",
    "            'torque': torque,\n",
    "            'unique_cluster_label': om\n",
    "        }\n",
    "        no_labels_vibration_measurement_periods_meta_data_.append(measurement_period)\n",
    "        no_labels_vibration_measurement_periods_.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  derive weights for measurement periods\n",
    "print('deriving weights for measurement periods')\n",
    "df_W_no_labels_ = extract_vibration_weights_per_measurement_period(no_labels_vibration_measurement_periods_, fingerprints_[0].columns, BAND_COLS, normalize_1, model_)\n",
    "\n",
    "# calculate distances\n",
    "print('calculating distances')\n",
    "df_dist_no_labels_ = calculate_distances_per_measurement_period(df_W_no_labels_, fingerprints=fingerprints_)\n",
    "#if CACHE_RESULTS:\n",
    "if False:\n",
    "    pickle.dump(df_dist_no_labels_, open(os.path.join('distances_no_labels', f'df_dist_no_labels.pkl'), 'wb'))\n",
    "df_dist_no_labels_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine_with_labels = df_cosine_folds[fold]\n",
    "\n",
    "df_cosine_no_labels = df_dist_no_labels_[['idx', 'om', 'cosine_distance']].pivot(index='idx', columns='om', values='cosine_distance')\n",
    "# assign the corresponding operating mode to the given row (if known), else, assign -1\n",
    "# unique cluster label is wrong!!! (might be correct)\n",
    "df_cosine_no_labels[['rpm', 'torque', 'unique_cluster_label']] = pd.DataFrame(no_labels_vibration_measurement_periods_meta_data_)[['rpm', 'torque', 'unique_cluster_label']]\n",
    "\n",
    "distance_to_own_cluster_center_ = []\n",
    "for idx, row in df_cosine_.iterrows():\n",
    "    om = row['unique_cluster_label']\n",
    "    if om != -1:\n",
    "        distance_to_own_cluster_center_.append(row[om])\n",
    "    else:\n",
    "        distance_to_own_cluster_center_.append(np.nan)\n",
    "df_cosine_no_labels['distance_to_own_cluster_center'] = distance_to_own_cluster_center_\n",
    "df_cosine_no_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_density = False\n",
    "\n",
    "# plot distribution of cosine distances to own cluster center\n",
    "fig, axes = plt.subplots(figsize=(15, 10), nrows=3)\n",
    "\n",
    "min_ = -0.001\n",
    "max_ = 0.8\n",
    "bins = np.arange(min_, max_, 0.0025)\n",
    "\n",
    "df_cosine_healthy = df_cosine_with_labels[df_cosine_with_labels.pitting == False]\n",
    "ax = df_cosine_healthy['distance_to_own_cluster_center'].plot(kind='hist', density=plot_density, bins=bins, ax=axes[0], alpha=0.5, legend=False)\n",
    "ax.set_title('healthy samples')\n",
    "\n",
    "df_cosine_anomalous = df_cosine_with_labels[df_cosine_with_labels.pitting == True]\n",
    "ax = df_cosine_anomalous['distance_to_own_cluster_center'].plot(kind='hist', density=plot_density, bins=bins, ax=axes[1], alpha=0.5, legend=False)\n",
    "ax.set_title('anomalous samples')\n",
    "\n",
    "ax = df_cosine_no_labels['distance_to_own_cluster_center'].plot(kind='hist', density=plot_density, bins=bins, ax=axes[2], alpha=0.5, legend=False)\n",
    "ax.set_title('unknown labels')\n",
    "ax.set_xlabel('Cosine distance');\n",
    "\n",
    "fig.suptitle('Cosine distance to vibration fingerprint');\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine_healthy['distance_to_own_cluster_center'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_cosine_no_labels[df_cosine_no_labels.distance_to_own_cluster_center < 0.3]\n",
    "fig, ax = plt.subplots(figsize=(15, 4))\n",
    "ax = df_['distance_to_own_cluster_center'].plot(kind='hist', density=plot_density, bins=100, ax=ax, alpha=0.5, legend=False)\n",
    "ax.set_title('unknown labels (with distance < 0.3)')\n",
    "ax.axvline(x=0.005, color='red', linestyle='--', label='distance threshold')\n",
    "ax.set_xlabel('Cosine distance');\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_density = False\n",
    "\n",
    "# plot distribution of cosine distances to own cluster center\n",
    "fig, axes = plt.subplots(figsize=(15, 10), nrows=3)\n",
    "\n",
    "min_ = -0.00001\n",
    "max_ = 0.30001\n",
    "bins = np.arange(min_, max_, 0.002)\n",
    "\n",
    "df_cosine_healthy = df_cosine_with_labels[df_cosine_with_labels.pitting == False][df_cosine_with_labels.distance_to_own_cluster_center < 0.3]\n",
    "ax = df_cosine_healthy['distance_to_own_cluster_center'].plot(kind='hist', density=plot_density, bins=bins, ax=axes[0], alpha=0.5, legend=False)\n",
    "ax.axvline(x=0.004, color='red', linestyle='--', label='distance threshold')\n",
    "tp = len(df_cosine_healthy[df_cosine_with_labels[df_cosine_with_labels.pitting == False].distance_to_own_cluster_center < 0.004])\n",
    "fn = len(df_cosine_healthy[df_cosine_with_labels[df_cosine_with_labels.pitting == False].distance_to_own_cluster_center >= 0.004])\n",
    "ax.text(x=0.1, y=0.1, s=f'TP={tp}, FN={fn}', transform=ax.transAxes)\n",
    "ax.set_title('healthy samples')\n",
    "\n",
    "df_cosine_anomalous = df_cosine_with_labels[df_cosine_with_labels.pitting == True][df_cosine_with_labels.distance_to_own_cluster_center < 0.3]\n",
    "ax = df_cosine_anomalous['distance_to_own_cluster_center'].plot(kind='hist', density=plot_density, bins=bins, ax=axes[1], alpha=0.5, legend=False)\n",
    "ax.axvline(x=0.004, color='red', linestyle='--', label='distance threshold')\n",
    "fp = len(df_cosine_anomalous[df_cosine_with_labels[df_cosine_with_labels.pitting == True].distance_to_own_cluster_center < 0.004])\n",
    "tn = len(df_cosine_anomalous[df_cosine_with_labels[df_cosine_with_labels.pitting == True].distance_to_own_cluster_center >= 0.004])\n",
    "ax.text(x=0.1, y=0.1, s=f'FP={fp}, TN={tn}', transform=ax.transAxes)\n",
    "ax.set_title('anomalous samples')\n",
    "\n",
    "df_ = df_cosine_no_labels[df_cosine_no_labels.distance_to_own_cluster_center < 0.3]\n",
    "ax = df_['distance_to_own_cluster_center'].plot(kind='hist', density=plot_density, bins=bins, ax=axes[2], alpha=0.5, legend=False)\n",
    "ax.axvline(x=0.004, color='red', linestyle='--', label='distance threshold')\n",
    "ax.set_title('unknown labels')\n",
    "healthy = len(df_cosine_no_labels[df_cosine_no_labels.distance_to_own_cluster_center < 0.004])\n",
    "anomalies = len(df_cosine_no_labels[df_cosine_no_labels.distance_to_own_cluster_center >= 0.004])\n",
    "perc_a = round(anomalies / (healthy + anomalies) * 100, 2)\n",
    "perc_h = round(healthy / (healthy + anomalies) * 100, 2)\n",
    "ax.text(x=0.1, y=0.1, s=f'no anomalies={healthy} ({perc_h}%), anomalies={anomalies} ({perc_a}%)', transform=ax.transAxes)\n",
    "ax.legend()\n",
    "ax.set_xlabel('Cosine distance');\n",
    "\n",
    "fig.suptitle('Cosine distance to vibration fingerprint');\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine_combined = pd.concat([df_cosine_healthy, df_cosine_anomalous, df_cosine_no_labels])\n",
    "df_cosine_combined['pitting'] = df_cosine_combined['pitting'].fillna('unknown')\n",
    "fig, ax = plt.subplots(figsize=(18, 4))\n",
    "ax = sns.boxplot(data=df_cosine_combined, x='distance_to_own_cluster_center', y='pitting', ax=ax)\n",
    "ax.set_title(f'Distance to own cluster center per pitting level');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine_combined = pd.concat([df_cosine_healthy, df_cosine_anomalous, df_cosine_no_labels])\n",
    "df_cosine_combined['pitting'] = df_cosine_combined['pitting'].fillna('unknown')\n",
    "fig, ax = plt.subplots(figsize=(18, 18))\n",
    "ax = sns.swarmplot(data=df_cosine_combined, x='distance_to_own_cluster_center', y='pitting', ax=ax)\n",
    "ax.set_title(f'Distance to own cluster center per pitting level');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine_combined = pd.concat([df_cosine_healthy, df_cosine_anomalous, df_cosine_no_labels])\n",
    "df_cosine_combined['pitting_level'] = df_cosine_combined['pitting_level'].fillna(-1.0).astype(int).astype(str)\n",
    "# df_cosine_combined['pitting_level'] = df_cosine_combined['pitting_level'].replace({'unknown': -1})\n",
    "fig, ax = plt.subplots(figsize=(18, 4))\n",
    "ax = sns.boxplot(data=df_cosine_combined, x='distance_to_own_cluster_center', y='pitting_level', ax=ax)\n",
    "ax.set_title(f'Distance to own cluster center per pitting level');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating anomaly score:\n",
    "- lower distance --> lower score\n",
    "- higher distance --> higher score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize distance\n",
    "min_ = df_cosine_combined.distance_to_own_cluster_center.min()\n",
    "max_ = df_cosine_combined.distance_to_own_cluster_center.max()\n",
    "\n",
    "df_cosine_combined['distance_to_own_cluster_center_normalized'] = (df_cosine_combined.distance_to_own_cluster_center - min_) / (max_ - min_)\n",
    "fig, ax = plt.subplots(figsize=(18, 4))\n",
    "df_cosine_combined['distance_to_own_cluster_center_normalized'].plot.hist(bins=100, ax=ax)\n",
    "ax.set_title(f'anomaly score distribution (normalized distance to own cluster center $d_n$)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ = np.sqrt(np.sqrt((df_cosine_combined.distance_to_own_cluster_center - min_) / (max_ - min_)))\n",
    "fig, ax = plt.subplots(figsize=(18, 4))\n",
    "score_.plot.hist(bins=100, ax=ax)\n",
    "ax.set_title(f'anomaly score distribution (4th sqrt of $d_n$)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing (only important for V3)\n",
    "\n",
    "source: https://statistics.laerd.com/spss-tutorials/binomial-test-using-spss-statistics.php \n",
    "\n",
    "## Hypothesis 1\n",
    "Idea: Formulate Bernoulli experiment (exactly two prossible outcomes per trial) for anomaly detection in order to test whether a statistical significance can be observed with respect to a predetermined successful experiment.\n",
    "In this case statistical significance can be tested with a binomial test.\n",
    "\n",
    "- ***$H_0$=\"The FPR@TPR=90% is larger than 10%\"***\n",
    "- $H_A$: In order to achieve a TPR of at least 90%, the FPR is no more than 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "ALPHA = 0.05  # 5% significance level\n",
    "THRESHOLD = 0.90\n",
    "\n",
    "# calculate TPR@FPR=X% for each fold\n",
    "fpr_at_tpr_folds = []\n",
    "for fold in tqdm(range(N), total=N):\n",
    "    df_cosine_ = df_cosine_folds[fold]\n",
    "    df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "    fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "    fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=THRESHOLD)\n",
    "    fpr_at_tpr_folds.append(fpr_at_tpr)\n",
    "fpr_at_tpr_folds = pd.Series(fpr_at_tpr_folds)\n",
    "\n",
    "# calclate how many of the samples fall below the expected proportion\n",
    "EXPECTED_PROPORTION = 0.1  # null hypothesis value as a decimal\n",
    "observed_successes = (fpr_at_tpr_folds > EXPECTED_PROPORTION).sum()  # actual TPR@FPR=X% value as a decimal\n",
    "\n",
    "# Perform the one-sample binomial test\n",
    "test_result = stats.binomtest(k=observed_successes, n=N, p=EXPECTED_PROPORTION, alternative='less')   # need to increase the number of samples to get a significant result\n",
    "print(f\"Observed samples where FPR@TPR={THRESHOLD*100}% > {EXPECTED_PROPORTION*100}%: {observed_successes} out of {N}\")\n",
    "if test_result.pvalue < ALPHA:\n",
    "    print(f\"Reject the null hypothesis. The FPR@TPR={THRESHOLD*100}% is statistically significantly smaller than {EXPECTED_PROPORTION*100}%.\")\n",
    "else:\n",
    "    print(f\"Fail to reject the null hypothesis. There isn't enough evidence to conclude that FPR@TPR={THRESHOLD*100}% is statistically significaficantly smaller than {EXPECTED_PROPORTION*100}%.\")\n",
    "print(\"p-value:\", test_result.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ***$H_0$=\"The FPR@TPR=95% is larger than 10%\"***\n",
    "- $H_A$: In order to achieve a TPR of at least 95%, the FPR is no more than 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.05  # 5% significance level\n",
    "THRESHOLD = 0.95\n",
    "\n",
    "# calculate TPR@FPR=X% for each fold\n",
    "fpr_at_tpr_folds = []\n",
    "for fold in tqdm(range(N), total=N):\n",
    "    df_cosine_ = df_cosine_folds[fold]\n",
    "    df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "    fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "    fpr_at_tpr = calc_fpr_at_tpr_threshold(tpr, fpr, threshold=THRESHOLD)\n",
    "    fpr_at_tpr_folds.append(fpr_at_tpr)\n",
    "fpr_at_tpr_folds = pd.Series(fpr_at_tpr_folds)\n",
    "\n",
    "# calclate how many of the samples fall below the expected proportion\n",
    "EXPECTED_PROPORTION = 0.1  # null hypothesis value as a decimal\n",
    "observed_successes = (fpr_at_tpr_folds > EXPECTED_PROPORTION).sum()  # actual TPR@FPR=X% value as a decimal\n",
    "\n",
    "# Perform the one-sample binomial test\n",
    "test_result = stats.binomtest(k=observed_successes, n=N, p=EXPECTED_PROPORTION, alternative='less')   # need to increase the number of samples to get a significant result\n",
    "print(f\"Observed samples where FPR@TPR={THRESHOLD*100}% > {EXPECTED_PROPORTION*100}%: {observed_successes} out of {N}\")\n",
    "if test_result.pvalue < ALPHA:\n",
    "    print(f\"Reject the null hypothesis. The FPR@TPR={THRESHOLD*100}% is statistically significantly smaller than {EXPECTED_PROPORTION*100}%.\")\n",
    "else:\n",
    "    print(f\"Fail to reject the null hypothesis. There isn't enough evidence to conclude that FPR@TPR={THRESHOLD*100}% is statistically significaficantly smaller than {EXPECTED_PROPORTION*100}%.\")\n",
    "print(\"p-value:\", test_result.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hypothesis 2 (draft)\n",
    "- We claim that in more than 95% of the cases, the TPR@FPR=10% is higher than 85%.\n",
    "- ***$H_0$=\"The TPR@FPR=10% is less or equal than 80%\"***\n",
    "- ***$H_A$=\"The TPR@FPR=10% is more than 80%\"***\n",
    "- (*) Our null hypothesis is ***$H_0$=\"The TPR@FPR=10% is less than 85%\"***, hence my alternative thesis would be that ***$H_A$=\"The TPR@FPR=10% is equal or more than 85%\"***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "ALPHA = 0.05  # 5% significance level\n",
    "FPR_THRESHOLD = 0.1  # FPR threshold to calculate TPR@FPR=<FPR_THRESHOLD>%\n",
    "\n",
    "# calculate TPR@FPR=X% for each fold\n",
    "tpr_at_fpr_folds = []\n",
    "for fold in tqdm(range(N), total=N):\n",
    "    df_cosine_ = df_cosine_folds[fold]\n",
    "    fpr, tpr, roc_auc = calculate_roc_characteristics(df_cosine_)\n",
    "    tpr_at_fpr = calc_tpr_at_fpr_threshold(tpr, fpr, threshold=FPR_THRESHOLD)\n",
    "    tpr_at_fpr_folds.append(tpr_at_fpr)\n",
    "tpr_at_fpr_folds = pd.Series(tpr_at_fpr_folds)\n",
    "\n",
    "# calclate how many of the samples fall below the expected proportion\n",
    "EXPECTED_PROPORTION = 0.8  # null hypothesis value as a decimal\n",
    "observed_successes = (tpr_at_fpr_folds <= EXPECTED_PROPORTION).sum()  # actual TPR@FPR=X% value as a decimal\n",
    "\n",
    "# Perform the one-sample binomial test\n",
    "test_result = stats.binomtest(k=observed_successes, n=N, p=EXPECTED_PROPORTION, alternative='less')\n",
    "print(f\"Observed samples where TPR@FPR={FPR_THRESHOLD*100}% < {EXPECTED_PROPORTION}: {observed_successes}\")\n",
    "if test_result.pvalue < ALPHA:\n",
    "    print(f\"Reject the null hypothesis. The TPR@FPR={FPR_THRESHOLD*100}% is statistically significantly greater than or equal to {EXPECTED_PROPORTION*100}%.\")\n",
    "else:\n",
    "    print(f\"Fail to reject the null hypothesis. There isn't enough evidence to conclude that TPR@FPR={FPR_THRESHOLD*100}% is greater than or equal to {EXPECTED_PROPORTION*100}%.\")\n",
    "print(\"p-value:\", test_result.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.binomtest(k=35, n=100, p=0.25, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average ROC curve\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: Precision & Recall:\n",
    "- **Precision** is the fraction of relevant instances among the retrieved instances: `true_positives / (true_positives + false_positives)`\n",
    "- **Recall** is the fraction of relevant instances that have been retrieved over the total amount of relevant instances: `true_positives / (true_positives + false_negatives)`\n",
    "\n",
    "Why is a precision-recall curve better for imbalanced problems?\n",
    "- Precision-recall curves are more sensitive to the performance of the model on the minority class.\n",
    "- In imbalanced problems, it's often more critical to correctly identify the positive class instances (high recall) and minimize false positives (high precision) rather than worrying about true negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR-curve with anomaly as minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot precision-recall curve\n",
    "def calculate_pr_characteristics(df_):\n",
    "    df_ = df_.sort_values(by='distance_to_own_cluster_center', ascending=True)\n",
    "\n",
    "    # Initialize variables to store ROC curve values\n",
    "    precision = []\n",
    "    recall = []\n",
    "\n",
    "    for threshold in df_['distance_to_own_cluster_center']:\n",
    "        df_['predicted_anomaly'] = df_['distance_to_own_cluster_center'] >= threshold\n",
    "        positive = 1\n",
    "        negative = 1 - positive\n",
    "\n",
    "        # Calculate True Positive Rate (TPR) and False Positive Rate (FPR)\n",
    "        true_positives = df_[(df_['pitting'] == positive) & (df_['predicted_anomaly'] == positive)].shape[0]\n",
    "        false_positives = df_[(df_['pitting'] == negative) & (df_['predicted_anomaly'] == positive)].shape[0]\n",
    "        true_negatives = df_[(df_['pitting'] == negative) & (df_['predicted_anomaly'] == negative)].shape[0]\n",
    "        false_negatives = df_[(df_['pitting'] == positive) & (df_['predicted_anomaly'] == negative)].shape[0]\n",
    "\n",
    "        # Precision = fraction of positive predictions that actually belong to the positive class.\n",
    "        precision.append(true_positives / (true_positives + false_positives))\n",
    "        # Recall = fraction of positive predictions out of all positive instances in the data set.\n",
    "        recall.append(true_positives / (true_positives + false_negatives))\n",
    "\n",
    "    # Calculate the area under the ROC curve (AUC)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    #pr_auc = 0\n",
    "\n",
    "    return precision, recall, pr_auc\n",
    "\n",
    "for fold in range(min([4, len(df_cosine_folds)])):\n",
    "    # why does the individual ROC curve not go until FP = 1 (?)\n",
    "    df_cosine_ = df_cosine_folds[fold]\n",
    "    df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # plot individual ROC curves\n",
    "    linestyles = ['-', '--', ':', '-', '--', ':']\n",
    "    for lvl, style in zip(pitting_levels, linestyles):\n",
    "        df_ = df_cosine_[(~df_cosine_['pitting']) | (df_cosine_['pitting_level'] == lvl)]\n",
    "        precision, recall, pr_auc = calculate_pr_characteristics(df_)\n",
    "        ax.plot(precision, recall, lw=1, linestyle=style, alpha=0.66, label=f'level {lvl} (area = {pr_auc:.3f})')\n",
    "        ax.set_xlim(0.0, 1.0)\n",
    "        ax.set_ylim(0.0, 1.05)\n",
    "\n",
    "    # Plot the general ROC curve\n",
    "    precision, recall, pr_auc = calculate_pr_characteristics(df_cosine_)\n",
    "    ax.plot(recall, precision, color='blue', lw=4, label=f'overall (area = {pr_auc:.3f})', alpha=0.66)\n",
    "    # plot baseline that goes from x=0, y=0.5 to x=1, y=0.5\n",
    "    ax.plot([0, 1], [0.5, 0.5], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "    # ax.plot([0, 0.5], [1, 0.5], color='navy', lw=2, linestyle='--')\n",
    "    ax.set_xlim(0.0, 1.0)\n",
    "    ax.set_ylim(0.0, 1.05)\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title(f'Precision-recall Curve (fold {fold})')\n",
    "    n_total = len(df_cosine_)\n",
    "    n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "    n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])\n",
    "    text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy)\"\n",
    "    ax.annotate(xy=(0.1, 0.025), text=text)\n",
    "    ax.legend(loc='lower right', title='Pitting severity level');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> WHAT IS THE MAJORITY CLASS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR-curve with healthy as minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot precision-recall curve\n",
    "def calculate_pr_characteristics(df_):\n",
    "    df_ = df_.sort_values(by='distance_to_own_cluster_center', ascending=True)\n",
    "\n",
    "    # Initialize variables to store ROC curve values\n",
    "    precision = []\n",
    "    recall = []\n",
    "\n",
    "    for threshold in df_['distance_to_own_cluster_center']:\n",
    "        df_['predicted_anomaly'] = df_['distance_to_own_cluster_center'] >= threshold\n",
    "        positive = 1\n",
    "        negative = 1 - positive\n",
    "\n",
    "        # Calculate True Positive Rate (TPR) and False Positive Rate (FPR)\n",
    "        # correctly identified healthy samples\n",
    "        true_positives = df_[(df_['pitting'] == False) & (df_['predicted_anomaly'] == False)].shape[0]\n",
    "        # incorrectly identified samples as healthy\n",
    "        false_positives = df_[(df_['pitting'] == True) & (df_['predicted_anomaly'] == False)].shape[0]\n",
    "        # correctly identified unhealthy samples\n",
    "        true_negatives = df_[(df_['pitting'] == True) & (df_['predicted_anomaly'] == True)].shape[0]\n",
    "        # incorrectly identified samples as unhealthy\n",
    "        false_negatives = df_[(df_['pitting'] == False) & (df_['predicted_anomaly'] == True)].shape[0]\n",
    "\n",
    "        # Precision = fraction of positive predictions that actually belong to the positive class.\n",
    "        try:\n",
    "            precision.append(true_positives / (true_positives + false_positives))\n",
    "        except ZeroDivisionError:\n",
    "            precision.append(1)\n",
    "        # Recall = fraction of positive predictions out of all positive instances in the data set.\n",
    "        try:\n",
    "            recall.append(true_positives / (true_positives + false_negatives))\n",
    "        except ZeroDivisionError:\n",
    "            recall.append(1)\n",
    "\n",
    "    # Calculate the area under the ROC curve (AUC)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    #pr_auc = 0\n",
    "\n",
    "    return precision, recall, pr_auc\n",
    "\n",
    "for fold in range(min([4, len(df_cosine_folds)])):\n",
    "    # why does the individual ROC curve not go until FP = 1 (?)\n",
    "    df_cosine_ = df_cosine_folds[fold]\n",
    "    df_cosine_ = df_cosine_[df_cosine_.unique_cluster_label != -1]  # QUICK FIX !!! : removed unknown cluster labels\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # plot individual ROC curves\n",
    "    linestyles = ['-', '--', ':', '-', '--', ':']\n",
    "    for lvl, style in zip(pitting_levels, linestyles):\n",
    "        df_ = df_cosine_[(~df_cosine_['pitting']) | (df_cosine_['pitting_level'] == lvl)]\n",
    "        precision, recall, pr_auc = calculate_pr_characteristics(df_)\n",
    "        ax.plot(precision, recall, lw=1, linestyle=style, alpha=0.66, label=f'level {lvl} (area = {pr_auc:.3f})')\n",
    "        ax.set_xlim(0.0, 1.0)\n",
    "        ax.set_ylim(0.0, 1.05)\n",
    "\n",
    "    # Plot the general ROC curve\n",
    "    precision, recall, pr_auc = calculate_pr_characteristics(df_cosine_)\n",
    "    ax.plot(recall, precision, color='blue', lw=4, label=f'overall (area = {pr_auc:.3f})', alpha=0.66)\n",
    "    # plot baseline that goes from x=0, y=0.5 to x=1, y=0.5\n",
    "    ax.plot([0, 1], [0.5, 0.5], color='navy', lw=2, linestyle='--', label='baseline')\n",
    "    # ax.plot([0, 0.5], [1, 0.5], color='navy', lw=2, linestyle='--')\n",
    "    ax.set_xlim(0.0, 1.0)\n",
    "    ax.set_ylim(0.0, 1.05)\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title(f'Precision-recall Curve (fold {fold})')\n",
    "    n_total = len(df_cosine_)\n",
    "    n_healthy = len(df_cosine_[df_cosine_['pitting'] == False])\n",
    "    n_unhealthy = len(df_cosine_[df_cosine_['pitting'] == True])\n",
    "    text = f\"n={n_total} ({n_healthy} healthy, {n_unhealthy} unhealthy)\"\n",
    "    ax.annotate(xy=(0.1, 0.025), text=text)\n",
    "    ax.legend(loc='lower right', title='Pitting severity level');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_cosine_folds[0]\n",
    "df_sorted_ = df_.sort_values(by='distance_to_own_cluster_center', ascending=True).dropna(subset=['distance_to_own_cluster_center'])\n",
    "df_sorted_.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted_no_pitting_ = df_sorted_[df_sorted_['pitting'] == False]\n",
    "df_sorted_pitting_ = df_sorted_[df_sorted_['pitting'] == True]\n",
    "df_sorted_no_pitting_.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16, 4), ncols=2)\n",
    "df_sorted_no_pitting_['distance_to_own_cluster_center'].plot(kind='hist', bins=100, ax=axes[0], title='No pitting')\n",
    "df_sorted_pitting_['distance_to_own_cluster_center'].plot(kind='hist', bins=100, ax=axes[1], title='Pitting')\n",
    "dist_ = 0.0075\n",
    "axes[0].axvline(x=dist_, color='red', linestyle='--');\n",
    "axes[0].text(dist_+0.25*dist_, 10, 'FP', color='red', verticalalignment='top')\n",
    "axes[0].text(dist_-0.35*dist_, 10, 'TN', color='red', verticalalignment='top')\n",
    "axes[1].axvline(x=dist_, color='red', linestyle='--');\n",
    "axes[1].text(0.05, 5, 'TP', color='red', verticalalignment='top')\n",
    "axes[1].text(-0.02, 5, 'FN', color='red', verticalalignment='top')\n",
    "TP = len(df_sorted_pitting_[df_sorted_pitting_['distance_to_own_cluster_center'] >= dist_])\n",
    "FP = len(df_sorted_no_pitting_[df_sorted_no_pitting_['distance_to_own_cluster_center'] >= dist_])\n",
    "TN = len(df_sorted_no_pitting_[df_sorted_no_pitting_['distance_to_own_cluster_center'] < dist_])\n",
    "FN = len(df_sorted_pitting_[df_sorted_pitting_['distance_to_own_cluster_center'] < dist_])\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "TNR = TN / (TN + FP)\n",
    "FNR = FN / (FN + TP)\n",
    "print(f'TP: {TP} (TPR = {round(100 * TPR, 1)}%)')\n",
    "print(f'FP: {FP} (FPR = {round(100 * FPR, 1)}%)')\n",
    "print(f'TN: {TN} (TNR = {round(100 * TNR, 1)}%)')\n",
    "print(f'FN: {FN} (FNR = {round(100 * FNR, 1)}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.scatter(x=df_sorted_no_pitting_['rpm'], y=df_sorted_no_pitting_['distance_to_own_cluster_center'], label='No pitting')\n",
    "ax.set_xlabel('RPM')\n",
    "ax.set_ylabel('Cosine distance')\n",
    "ax.set_title('Cosine distance to own cluster center per RPM for healthy samples')\n",
    "ax.axhline(y=dist_, color='red', linestyle='--');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.scatter(x=df_sorted_no_pitting_['torque'], y=df_sorted_no_pitting_['distance_to_own_cluster_center'], label='No pitting')\n",
    "ax.set_xlabel('Torque')\n",
    "ax.set_ylabel('Cosine distance')\n",
    "ax.set_title('Cosine distance to own cluster center per RPM for healthy samples')\n",
    "ax.axhline(y=dist_, color='red', linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on merged validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH_VALIDATION = os.path.join('Data_Challenge_PHM2023_validation_data')\n",
    "BASE_PATH_TEST = os.path.join('Data_Challenge_PHM2023_test_data')\n",
    "\n",
    "nperseg = 10240\n",
    "noverlap = nperseg // 2\n",
    "nfft = None\n",
    "fs = 20480\n",
    "\n",
    "def load_test_data(rpm, torque, run, path=BASE_PATH_HEALTHY):\n",
    "    df = pd.read_csv(path, names=['x', 'y', 'z', 'tachometer'], delimiter=' ')\n",
    "    return df\n",
    "\n",
    "def load_data(fnames, use_train_data_for_validation=True, base_path=BASE_PATH_HEALTHY, **kwargs):\n",
    "    \"\"\"train_data --> process parameters are known. (TODO: change later)\"\"\"\n",
    "    data = []\n",
    "    for fn in tqdm(fnames):\n",
    "        rpm, torque, run = extract_process_parameters(fn, use_train_data_for_validation=use_train_data_for_validation)\n",
    "        try:\n",
    "            with timeout(seconds=2):\n",
    "                df = load_train_data(rpm, torque, run, base_path=base_path) if use_train_data_for_validation else load_test_data(rpm, torque, run, path=fn)\n",
    "        except TimeoutError:\n",
    "            print(f\"timed out: {fn}\")\n",
    "        f, t, stft_x = stft(df['x'], **kwargs)\n",
    "        f, t, stft_y = stft(df['y'], **kwargs)\n",
    "        f, t, stft_z = stft(df['z'], **kwargs)\n",
    "        f, psd_x = welch(df['x'], **kwargs)\n",
    "        f, psd_y = welch(df['y'], **kwargs)\n",
    "        f, psd_z = welch(df['z'], **kwargs)\n",
    "        data.append({\n",
    "            'rpm': rpm,\n",
    "            'torque': torque, \n",
    "            'sample_id': run,\n",
    "            'unique_sample_id': f'{rpm}_{torque}_{run}',  # Remove the '.txt' extension and convert to integer\n",
    "            'vibration_time_domain': df, \n",
    "            'stft_x': stft_x,\n",
    "            'stft_y': stft_y,\n",
    "            'stft_z': stft_z,  # Remove the '.txt' extension and convert to integer\n",
    "            'psd_x': psd_x,\n",
    "            'psd_y': psd_y,\n",
    "            'psd_z': psd_z\n",
    "        })\n",
    "    return data, f\n",
    "\n",
    "fnames = glob.glob(os.path.join(BASE_PATH_VALIDATION, '*.txt'))\n",
    "data_validation_set, f = load_data(fnames, nperseg=nperseg,\n",
    "                                   noverlap=noverlap, nfft=nfft, fs=fs,\n",
    "                                   use_train_data_for_validation=False)\n",
    "\n",
    "\"\"\"\n",
    "fnames = glob.glob(os.path.join(BASE_PATH_TEST, '*.txt'))\n",
    "data_test_set, f = load_data(fnames, nperseg=nperseg,\n",
    "                                   noverlap=noverlap, nfft=nfft, fs=fs,\n",
    "                                   use_train_data_for_validation=False)\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse size of variables (with possibility to filter out variables with high memory consumption)\n",
    "\n",
    "import sys\n",
    "\n",
    "# Create a function to get the size of all variables\n",
    "def get_size_of_all_variables():\n",
    "    variable_sizes = [(var, sys.getsizeof(globals()[var]) / (1024 * 1024)) for var in globals()]\n",
    "    total_size_mb = sum(size for _, size in variable_sizes)\n",
    "    return total_size_mb, variable_sizes\n",
    "\n",
    "# Call the function and print the results\n",
    "total_size, variable_sizes = get_size_of_all_variables()\n",
    "print(f\"Total size of all variables: {total_size:.2f} MB\")\n",
    "\n",
    "# Print the sizes of individual variables\n",
    "for var, size in variable_sizes:\n",
    "    print(f\"{var}: {size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract vibration data\n",
    "df_vib_test_unhealthy = derive_df_vib(data_test, f)\n",
    "\n",
    "# convert to orders and derive meta data\n",
    "df_orders_test_pitting_, meta_data_test_pitting_ = derive_df_orders(df_vib_test_unhealthy, setup, f, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine_.distance_to_own_cluster_center.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we iterate over all operating modes and check the distances to the fingerprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vib_test_healthy = derive_df_vib(data_healthy_test, f)\n",
    "df_orders_test_healthy, meta_data_test_healthy = derive_df_orders(df_vib_test_healthy, setup, f)\n",
    "df_V_test_normalized_healthy = normalize_1(df_orders_test_healthy, BAND_COLS)\n",
    "df_ = df_V_test_normalized_healthy\n",
    "# meta_data_test_healthy['sample_id'] = meta_data_test_healthy.groupby(['rotational speed [RPM]', 'torque [Nm]', 'sample_id']).ngroup() + 1\n",
    "df_[['unique_sample_id', 'direction']] = meta_data_test_healthy[['unique_sample_id', 'direction']]\n",
    "test_vibration_measurement_periods = []\n",
    "test_vibration_measurement_periods_meta_data = []\n",
    "n_index_errors = 0\n",
    "for unique_sample_id, group in df_.groupby('unique_sample_id'):\n",
    "    rpm = meta_data_test_healthy[meta_data_test_healthy['unique_sample_id'] == unique_sample_id]['rotational speed [RPM]'].unique()[0]\n",
    "    torque = meta_data_test_healthy[meta_data_test_healthy['unique_sample_id'] == unique_sample_id]['torque [Nm]'].unique()[0]\n",
    "    try:\n",
    "        om = cluster_label_unique_name_mapping[\n",
    "            (cluster_label_unique_name_mapping['rotational speed [RPM]'] == rpm) & \n",
    "            (cluster_label_unique_name_mapping['torque [Nm]'] == torque)\n",
    "        ]['cluster_label_unique']\n",
    "        assert len(om.unique()) <= 1, f'should have maximum one unique cluster label, got instead: {om}'\n",
    "        om = om.iloc[0]\n",
    "        \"\"\"\n",
    "        if len(oms.unique()) == 1:\n",
    "            om = oms.iloc[0]\n",
    "        elif len(oms.unique()) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            print(oms)\n",
    "            raise ValueError(f'Found more than one unique cluster label for RPM={rpm} and torque={torque}')\n",
    "        \"\"\"\n",
    "    except IndexError:\n",
    "        n_index_errors += 1\n",
    "        om = -1\n",
    "    measurement_period = {\n",
    "        'start': 'unknown', \n",
    "        'stop': 'unknown',\n",
    "        'group': group,\n",
    "        'sample_id': sample_id,\n",
    "        'rpm': rpm,\n",
    "        'torque': torque,\n",
    "        'unique_cluster_label': om\n",
    "    }\n",
    "    test_vibration_measurement_periods.append(group)\n",
    "    test_vibration_measurement_periods_meta_data.append(measurement_period)\n",
    "\n",
    "n_total = len(test_vibration_measurement_periods)\n",
    "print(f'Total number of measurement periods: {n_total}')\n",
    "print(f'Number of measurement periods with unknown RPM and/or torque: {n_index_errors}')\n",
    "\n",
    "df_W_online = extract_vibration_weights_per_measurement_period(test_vibration_measurement_periods, fingerprints[0].columns, BAND_COLS, normalize_1, model)\n",
    "df_dist_online = calculate_distances_per_measurement_period(df_W_online)\n",
    "\n",
    "# for each measurement period (row), get the distance to each operating mode (column)\n",
    "df_cosine = df_dist_online[['idx', 'om', 'cosine_distance']].pivot(index='idx', columns='om', values='cosine_distance')\n",
    "# assign the corresponding operating mode to the given row (if known), else, assign -1\n",
    "# unique cluster label is wrong!!! (might be correct)\n",
    "df_cosine[['rpm', 'torque', 'unique_cluster_label']] = pd.DataFrame(test_vibration_measurement_periods_meta_data)[['rpm', 'torque', 'unique_cluster_label']]\n",
    "\n",
    "distance_to_own_cluster_center = []\n",
    "for idx, row in df_cosine.iterrows():\n",
    "    om = row['unique_cluster_label']\n",
    "    if om != -1:\n",
    "        distance_to_own_cluster_center.append(row[om])\n",
    "    else:\n",
    "        distance_to_own_cluster_center.append(np.nan)\n",
    "df_cosine['distance_to_own_cluster_center'] = distance_to_own_cluster_center\n",
    "df_cosine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are almost no anomalies when there is no pitting\n",
    "anomaly = df_cosine['distance_to_own_cluster_center'] > 0.01   # TODO: setting threshold to 0.01 as first test, later set threshold based on distance in training set\n",
    "anomaly.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16, 8), ncols=2)\n",
    "\n",
    "ax = df_cosine['distance_to_own_cluster_center'].plot(kind='hist', bins=20, ax=axes[0], alpha=0.5, legend=False)\n",
    "ax.set_title('Distance to own cluster centers')\n",
    "ax.set_xlabel('Cosine distance')\n",
    "\n",
    "# plot distance to other cluster centers\n",
    "ax = df_cosine.drop(columns=['rpm', 'torque', 'unique_cluster_label', 'distance_to_own_cluster_center']).melt()['value'].plot(kind='hist', bins=20, ax=axes[1], alpha=0.5, legend=False)\n",
    "ax.set_title('Distance to other cluster centers')\n",
    "ax.set_xlabel('Cosine distance')\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting an anomaly threshold with an ROC-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES & TODOS\n",
    "\n",
    "- [x] change test set --> use train set with and without pitting\n",
    "- [ ] experiment with normalisation\n",
    "- [ ] ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", 2023, Sirris"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
